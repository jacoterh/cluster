#!/usr/bin/env python3
global continue_run
NLO_plus_loop_induced = True
#continue_run = False
#continue_run = True

# hard-code subtraction scheme for NLO gg to be CS for public MATRIX v2
global NLOgg_subtraction
NLOgg_subtraction = "CS"
#NLOgg_subtraction = "QT"

#{{{ global definitions

global python3
global process_dir
global run_dir
global munich_dir
global start_dir
global no_run_folder
global out
global run_folder
global unique_parameters
global ordered_parameters
global renamed_parameters
global new_parameters
global special_parameters
global default_parameters
global mandatory_parameters
global MATRIX_parameters
global ord_params_keywords
global model_mappings_to_MUNICH
global channel_assignment
global ckm_processes
global ckm_EW_processes
global LO_photon_induced_processes
global verbose
global run_modes
global run_mode
global parameter_list
global model_list
global nr_cores
global process_name
global config_list
global run # only needed for exit handler
global pre_run_settings
global resummation_map_NLO
global resummation_map_NNLO

#}}}
#{{{ general imports
import os
import glob
import atexit
import copy
import time
import datetime
import sys
import shutil
import multiprocessing
import subprocess
import select
import fnmatch
import tarfile
import math
import signal
import argparse
from os.path import join as pjoin
from collections import defaultdict
from random import randint
# no need anymore for numpy
#import numpy as np 
#}}}

python3 = sys.version_info >= (3, 0) # set whether using python3 (or 2) version

#{{{ hard-coded lists and inputs before imports

# list of proper processes, that have been implemented and tested
script_link_dir = os.path.dirname(os.path.abspath(__file__)) # needed to determine process from name
process_dir = os.path.dirname(script_link_dir) # needed to determine existing runs
no_run_folder = ["default.grid.final","default.grid.final.tar","default.MATRIX","default.MATRIX.tar","batch","input","log","result","output","bin"]
proper_process_names = ["pph21","ppz01","ppeexa03","ppaa02","ppaaa03","ppeex02","ppnenexa03","ppeeexex04","ppemexmx04","ppemxnmnex04","ppexnea03","ppenexa03","ppnenex02","ppexne02nockm","ppenex02nockm","ppexne02","ppenex02","ppemexnmx04","ppeexmxnm04","pphh22","ppeexexne04","ppeeexnex04","ppeexnenex04", "ppeexnmnmx04","ppzz02","ppw01nockm","ppwx01nockm","ppw01","ppwx01","ppwxw02","ppttx20","ppbbx20","pphjj41heft"]
#}}}
#{{{ import own modules
sys.path.append(pjoin(os.path.dirname(os.path.realpath(__file__)),"modules"))
from handle_cluster import *
from handle_lhapdf import lhapdf
from handle_output import banner,output_saver
from handle_folder import which
# import instances of different classes
from initialize_classes import out, prc, log, run_name, edit_input, fold, res, Tee, cite
#import combine_distributions
from handle_gnuplot import gnuplot

#{{{ def: exit_handler(signal,frame)
def exit_handler(signal,frame):
    try:
        if run.runmode == "cluster" and run.jobs_started:
            open(pjoin(fold.run_folder_path,"cluster","job_ids_started.list"), 'a').close() # make sure this file exists (is at least empty)
            out.print_error_no_stop('Terminating all runs...')
            cluster.terminate_cluster_runs()
    except:
        pass
    try:
        # this removes the file that prevents running two instances at the same time
        out.print_error_no_stop('Removing lock file...')
        log.code_running_remove()
    except:
        pass
    out.print_error_no_stop('Exiting...')
    sys.exit(0)
#}}}
#{{{ def: atexit_handler()
def atexit_handler():
    try:
        if run.runmode == "cluster" and run.jobs_started:
            open(pjoin(fold.run_folder_path,"cluster","job_ids_started.list"), 'a').close() # make sure this file exists (is at least empty)
            cluster.terminate_cluster_runs()
    except:
        pass
    try:
        # this removes the file that prevents running two instances at the same time
        log.code_running_remove()
    except:
        pass
#}}}
#{{{ def control_c_handler(signal,frame)
def control_c_handler(signal,frame):
    # this is to kill cluster jobs which are still running 
    # when stopping the main code with ctrl-c
    print('You pressed ctrl-c!')
    exit_handler(signal,frame)
    sys.exit(0)
#}}}
signal.signal(signal.SIGINT,control_c_handler)
signal.signal(signal.SIGTERM,exit_handler)
atexit.register(atexit_handler)
#{{{ def multidim_dict(n)

def multidim_dict(n):
# extremely flexible multidimensional dictionary
  """ Creates an n-dimension dictionary where the n-th dimension is of type 'type'
  """  
  return defaultdict(lambda:multidim_dict(n-1))

#}}}
#from blessings import Terminal

#}}}
#{{{ initial parameters and paths set
# hard-coded switch to turn on verbose mode
verbose = False
# important paths that are used all over the code
script_dir = os.path.dirname(os.path.realpath(__file__))
#script_link_dir = os.path.dirname(os.path.abspath(__file__)) # already above
#process_dir = os.path.dirname(script_link_dir) # already above
run_dir = os.path.dirname(process_dir)
munich_dir = os.path.dirname(script_dir)
start_dir = os.getcwd()
default_run = "default.MATRIX"
default_input = "default.input.final"
if not os.path.exists(pjoin("input",default_input)):
    default_input = "default.input.MATRIX"
# we separate five classes of parameters that must be wrapped from the
# MATRIX to the MUNICH inputs
# !! Attention !! These list must be complete to avoid input parameters 
#                 which are wrong/not known

# 1. parameters that exist in both input files and are unique
# 2do: remove process_class completely ???
unique_parameters  = ["process_class","E","coll_choice","scale_fact","scale_ren","jet_algorithm","jet_R_definition","jet_R","photon_recombination","photon_R_definition","photon_R","photon_E_threshold_ratio","frixione_isolation","frixione_n","frixione_epsilon","frixione_delta_0","frixione_fixed_ET_max","pdf_content_modify","pdf_selection","define_pT missing","switch_PineAPPL"]
predefined_particles = ["jet","ljet","bjet","photon","lep","lm","lp","e","em","ep","mu","mum","mup","z","w","wm","wp","h","nua","nu","nux","nea","ne","nex","nma","nm","nmx"]
for particle in predefined_particles:
    unique_parameters.append("define_pT %s" % particle)
    unique_parameters.append("define_eta %s" % particle)
    unique_parameters.append("define_y %s" % particle)
    unique_parameters.append("n_observed_min %s" % particle)
    unique_parameters.append("n_observed_max %s" % particle)

# 2. new parameters that do not exist in, but have an effect on the MUNICH
#    input file, where the order is important
ordered_parameters = ["LHAPDF_LO","PDFsubset_LO","LHAPDF_NLO","PDFsubset_NLO","LHAPDF_NNLO","PDFsubset_NNLO"]
# these keywords are defined, so that one can uniquely connect the paramaters in MATRIX input with the ordered inputs in MUNICH
ord_params_keyword = {"LHAPDF_LO": ["type_perturbative_order","LO","LHAPDFname"],"LHAPDF_NLO": ["type_perturbative_order","NLO","LHAPDFname"],"LHAPDF_NNLO": ["type_perturbative_order","NNLO","LHAPDFname"],"LHAPDF_NNNLO": ["type_perturbative_order","NNNLO","LHAPDFname"],"PDFsubset_LO": ["type_perturbative_order","LO","LHAPDFsubset"],"PDFsubset_NLO": ["type_perturbative_order","NLO","LHAPDFsubset"],"PDFsubset_NNLO": ["type_perturbative_order","NNLO","LHAPDFsubset"],"PDFsubset_NNNLO": ["type_perturbative_order","NNNLO","LHAPDFsubset"]}
# 3. parameters that exist in both input files but have different names, these are added to file_parameter.dat if not exist
renamed_parameters = ["factor_central_scale","variation_factor","scale_res","dynamic_scale_res","factor_scale_res"]
renamed_parameter_mappings = {}
renamed_parameter_mappings["factor_central_scale"] = "prefactor_CV"
renamed_parameter_mappings["variation_factor"]     = "variation_factor_CV"
renamed_parameter_mappings["scale_res"]            = "user_cut Qres"
renamed_parameter_mappings["dynamic_scale_res"]    = "user_switch dynamical_Qres"
renamed_parameter_mappings["factor_scale_res"]     = "user_cut Qres_prefactor"
# 4. new parameters that do not concern the MUNICH input file directly
MATRIX_parameters  = ["run_LO","precision_LO","run_NLO_QCD","run_NLO_EW","add_NLL","precision_NLO_QCD","precision_NLO_EW","run_NNLO_QCD","add_NLO_EW","add_NNLL","precision_NNLO_QCD","precision_added_EW","max_time_per_job","save_previous_result","save_previous_log","include_pre_in_results","NLO_subtraction_method","check_interval","random_seed","print_out_interval","photon_induced","power_corrections_pT0",
# for backward compatibility:
"run_NLO","precision_NLO","run_NNLO","precision_NNLO","accuracy_LO","accuracy_NLO","accuracy_NNLO"]
# 5. special parameters that require a specific treatment
special_parameters = ["dynamic_scale","switch_distribution","flavor_scheme","scale_variation","switch_off_shell","reduce_workload","switch_qT_accuracy","improve_mappings_for_single_V","only_gg_chan","loop_induced","enhance_tails","approx_ckm_EW","power_corrections","extrapolate_binwise","use_TSV"]
# 6. user-defined parameters is a special class of parameters which depend on the process and are handled separately; these MUST all be set in the parameter.dat !
user_parameters = {}
user_parameters["pph21"] = []
user_parameters["pphh22"] = []
user_parameters["ppz01"] = []
user_parameters["ppnenex02"] = []
user_parameters["ppexne02nockm"] = []
user_parameters["ppenex02nockm"] = []
user_parameters["ppexne02"] = []
user_parameters["ppenex02"] = []
user_parameters["ppzz02"] = []
user_parameters["ppw01nockm"] = []
user_parameters["ppwx01nockm"] = []
user_parameters["ppw01"] = []
user_parameters["ppwx01"] = []
user_parameters["ppwxw02"] = []
user_parameters["ppttx20"] = []
user_parameters["ppbbx20"] = []
user_parameters["pphjj41heft"] = ["user_switch M_jetjet","user_cut min_M_jetjet","user_cut max_M_jetjet","user_switch absdy_jetjet","user_cut min_absdy_jetjet","user_cut max_absdy_jetjet"]
user_parameters["ppaa02"] = ["user_switch M_gamgam","user_cut min_M_gamgam","user_cut max_M_gamgam","user_switch pT_gam_1st","user_cut min_pT_gam_1st","user_switch gap_eta_gam","user_cut gap_min_eta_gam","user_cut gap_max_eta_gam","user_switch R_gamgam","user_cut min_R_gamgam"]
user_parameters["ppaaa03"] = ["user_switch M_gamgamgam","user_cut min_M_gamgamgam","user_cut max_M_gamgamgam","user_switch M_gamgam","user_cut min_M_gamgam","user_cut max_M_gamgam","user_switch photon_cuts","user_cut min_pT_gam_1st","user_cut min_pT_gam_2nd","user_cut min_pT_gam_3rd","user_switch gap_eta_gam","user_cut gap_min_eta_gam","user_cut gap_max_eta_gam","user_switch R_gamgam","user_cut min_R_gamgam"]
user_parameters["ppeexa03"] = ["user_switch M_leplep","user_cut min_M_leplep","user_cut min_M_lepgam","user_cut min_M_lepgam","user_switch R_lepgam","user_cut min_R_lepgam","user_switch R_lepjet","user_cut min_R_lepjet","user_switch R_gamjet","user_cut min_R_gamjet"]
user_parameters["ppeex02"] = ["user_switch M_leplep","user_cut min_M_leplep","user_cut max_M_leplep","user_switch R_leplep","user_cut min_R_leplep","user_switch lepton_cuts","user_cut min_pT_lep_1st","user_cut min_pT_lep_2nd"]
user_parameters["ppeeexex04"] = ["user_switch lepton_identification","user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_cut min_M_Z1","user_cut max_M_Z1","user_switch M_leplep_OSSF","user_cut min_M_leplep_OSSF","user_switch R_leplep","user_cut min_R_leplep","user_switch lepton_cuts","user_cut min_pT_lep_1st","user_cut max_eta_lep_1st","user_cut min_pT_lep_2nd","user_cut max_eta_lep_2nd","user_cut min_pT_lep_3rd","user_cut max_eta_lep_3rd","user_cut min_pT_lep_4th","user_cut max_eta_lep_4th","user_cut extra_eta_lep","user_int n_observed_min_lep_extra","user_int n_observed_max_lep_extra","user_switch M_4lep","user_cut min_M_4lep","user_cut max_M_4lep","user_cut min_delta_M_4lep","user_cut max_delta_M_4lep","user_switch lep_iso","user_cut lep_iso_delta_0","user_cut lep_iso_epsilon"]
user_parameters["ppemexmx04"] = ["user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_cut min_M_Z1","user_cut max_M_Z1","user_switch R_leplep","user_cut min_R_leplep","user_switch lepton_cuts","user_cut min_pT_lep_1st","user_cut max_eta_lep_1st","user_cut min_pT_lep_2nd","user_cut max_eta_lep_2nd","user_cut min_pT_lep_3rd","user_cut max_eta_lep_3rd","user_cut min_pT_lep_4th","user_cut max_eta_lep_4th","user_cut extra_eta_lep","user_int n_observed_min_lep_extra","user_int n_observed_max_lep_extra","user_switch electron_cuts","user_cut min_pT_e_1st","user_cut max_eta_e_1st","user_cut min_pT_e_2nd","user_cut max_eta_e_2nd","user_cut extra_eta_e","user_int n_observed_min_e_extra","user_int n_observed_max_e_extra","user_switch muon_cuts","user_cut min_pT_mu_1st","user_cut max_eta_mu_1st","user_cut min_pT_mu_2nd","user_cut max_eta_mu_2nd","user_cut extra_eta_mu","user_int n_observed_min_mu_extra","user_int n_observed_max_mu_extra","user_switch M_4lep","user_cut min_M_4lep","user_cut max_M_4lep","user_cut min_delta_M_4lep","user_cut max_delta_M_4lep","user_switch lep_iso","user_cut lep_iso_delta_0","user_cut lep_iso_epsilon"]
user_parameters["ppnenexa03"] = ["user_switch R_gamjet","user_cut min_R_gamjet"]
user_parameters["ppexnea03"] = ["user_switch R_gamjet","user_cut min_R_gamjet","user_switch R_lepgam","user_cut min_R_lepgam","user_switch R_lepjet","user_cut min_R_lepjet"]
user_parameters["ppenexa03"] = user_parameters["ppexnea03"]
user_parameters["ppemxnmnex04"] = ["user_switch M_leplep","user_cut min_M_leplep","user_cut max_M_leplep","user_switch R_leplep","user_cut min_R_leplep","user_switch pT_lep_1st","user_cut min_pT_lep_1st","user_switch gap_eta_e","user_cut gap_min_eta_e","user_cut gap_max_eta_e","user_switch rel_pT_miss","user_cut min_rel_pT_miss","user_switch R_ejet","user_cut min_R_ejet","user_switch pT_W","user_cut min_pT_W","user_cut max_pT_W"]#,"user_switch M_4lep","user_cut max_M_4lep"]
user_parameters["ppemxnmnex04EW"] = ["user_switch M_leplep","user_cut min_M_leplep","user_cut max_M_leplep","user_switch R_leplep","user_cut min_R_leplep","user_switch pT_lep_1st","user_cut min_pT_lep_1st","user_switch gap_eta_e","user_cut gap_min_eta_e","user_cut gap_max_eta_e","user_switch rel_pT_miss","user_cut min_rel_pT_miss","user_switch R_ejet","user_cut min_R_ejet","user_switch pT_W","user_cut min_pT_W","user_cut max_pT_W"]#,"user_switch M_4lep","user_cut max_M_4lep"]
user_parameters["ppeexexne04"] = ["user_switch lepton_identification","user_switch lepW_cuts","user_cut min_pT_lepW","user_cut max_eta_lepW","user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_switch delta_M_Zrec_MZ","user_cut max_delta_M_Zrec_MZ","user_switch R_leplep","user_cut min_R_leplep","user_switch R_lepZlepZ","user_cut min_R_lepZlepZ","user_switch R_lepZlepW","user_cut min_R_lepZlepW","user_switch MT_Wrec","user_cut min_MT_Wrec","user_switch lepZ_cuts","user_cut min_pT_lepZ_1st","user_cut min_pT_lepZ_2nd","user_switch M_leplep_OSSF","user_cut min_M_leplep_OSSF","user_switch delta_M_lepleplep_MZ","user_cut min_delta_M_lepleplep_MZ","user_switch lepton_cuts","user_cut min_pT_lep_1st","user_cut min_pT_lep_2nd"]
user_parameters["ppeeexnex04"] = ["user_switch lepton_identification","user_switch lepW_cuts","user_cut min_pT_lepW","user_cut max_eta_lepW","user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_switch delta_M_Zrec_MZ","user_cut max_delta_M_Zrec_MZ","user_switch R_leplep","user_cut min_R_leplep","user_switch R_lepZlepZ","user_cut min_R_lepZlepZ","user_switch R_lepZlepW","user_cut min_R_lepZlepW","user_switch MT_Wrec","user_cut min_MT_Wrec","user_switch lepZ_cuts","user_cut min_pT_lepZ_1st","user_cut min_pT_lepZ_2nd","user_switch M_leplep_OSSF","user_cut min_M_leplep_OSSF","user_switch delta_M_lepleplep_MZ","user_cut min_delta_M_lepleplep_MZ","user_switch lepton_cuts","user_cut min_pT_lep_1st","user_cut min_pT_lep_2nd"]
user_parameters["ppemexnmx04"] = ["user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_switch delta_M_Zrec_MZ","user_cut max_delta_M_Zrec_MZ","user_switch R_leplep","user_cut min_R_leplep","user_switch delta_M_lepleplep_MZ","user_cut min_delta_M_lepleplep_MZ","user_switch R_lepZlepZ","user_cut min_R_lepZlepZ","user_switch R_lepZlepW","user_cut min_R_lepZlepW","user_switch MT_Wrec","user_cut min_MT_Wrec","user_switch electron_cuts","user_cut min_pT_e_1st","user_cut min_pT_e_2nd","user_switch delta_M_lepleplep_MZ","user_cut min_delta_M_lepleplep_MZ","user_switch lepton_cuts","user_cut min_pT_lep_1st","user_cut min_pT_lep_2nd","user_switch leading_lepton_cuts","user_cut min_pT_1st_if_e","user_cut min_pT_1st_if_mu"]
user_parameters["ppeexmxnm04"] = ["user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_switch delta_M_Zrec_MZ","user_cut max_delta_M_Zrec_MZ","user_switch R_leplep","user_cut min_R_leplep","user_switch delta_M_lepleplep_MZ","user_cut min_delta_M_lepleplep_MZ","user_switch R_lepZlepZ","user_cut min_R_lepZlepZ","user_switch R_lepZlepW","user_cut min_R_lepZlepW","user_switch MT_Wrec","user_cut min_MT_Wrec","user_switch electron_cuts","user_cut min_pT_e_1st","user_cut min_pT_e_2nd","user_switch delta_M_lepleplep_MZ","user_cut min_delta_M_lepleplep_MZ","user_switch lepton_cuts","user_cut min_pT_lep_1st","user_cut min_pT_lep_2nd","user_switch leading_lepton_cuts","user_cut min_pT_1st_if_e","user_cut min_pT_1st_if_mu"]

# ============
# user_parameters["ppeexexne04"] = ["user_switch lepton_identification","user_switch W_lep_cuts","user_cut min_pT_W_lep","user_cut max_eta_W_lep","user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_switch delta_M_Zrec_MZ","user_cut max_delta_M_Zrec_MZ","user_switch R_leplep","user_cut min_R_leplep","user_switch R_lepZlepZ","user_cut min_R_lepZlepZ","user_switch R_lepZlepW","user_cut min_R_lepZlepW","user_switch MT_Wrec","user_cut min_MT_Wrec","user_switch Z_lep_cuts","user_cut min_pT_1st_Z_lep","user_cut min_pT_2nd_Z_lep"]
# user_parameters["ppeeexnex04"] = ["user_switch lepton_identification","user_switch W_lep_cuts","user_cut min_pT_W_lep","user_cut max_eta_W_lep","user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_switch delta_M_Zrec_MZ","user_cut max_delta_M_Zrec_MZ","user_switch R_leplep","user_cut min_R_leplep","user_switch R_lepZlepZ","user_cut min_R_lepZlepZ","user_switch R_lepZlepW","user_cut min_R_lepZlepW","user_switch MT_Wrec","user_cut min_MT_Wrec","user_switch Z_lep_cuts","user_cut min_pT_1st_Z_lep","user_cut min_pT_2nd_Z_lep"]
# user_parameters["ppemexnmx04"] = ["user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_switch delta_M_Zrec_MZ","user_cut max_delta_M_Zrec_MZ","user_switch R_leplep","user_cut min_R_leplep","user_switch delta_M_lepleplep_MZ","user_cut min_delta_M_lepleplep_MZ","user_switch R_lepZlepZ","user_cut min_R_lepZlepZ","user_switch R_lepZlepW","user_cut min_R_lepZlepW","user_switch MT_Wrec","user_cut min_MT_Wrec","user_switch electron_cuts","user_cut min_pT_1st_e","user_cut min_pT_2nd_e"]
# user_parameters["ppeexmxnm04"] = ["user_switch M_Zrec","user_cut min_M_Zrec","user_cut max_M_Zrec","user_switch delta_M_Zrec_MZ","user_cut max_delta_M_Zrec_MZ","user_switch R_leplep","user_cut min_R_leplep","user_switch delta_M_lepleplep_MZ","user_cut min_delta_M_lepleplep_MZ","user_switch R_lepZlepZ","user_cut min_R_lepZlepZ","user_switch R_lepZlepW","user_cut min_R_lepZlepW","user_switch MT_Wrec","user_cut min_MT_Wrec","user_switch electron_cuts","user_cut min_pT_1st_e","user_cut min_pT_2nd_e"]
# >>>>>>> develop_EW

user_parameters["ppeexnenex04"] = ["user_switch M_leplep","user_cut min_M_leplep","user_cut max_M_leplep","user_switch M_leplepnunu","user_cut min_M_leplepnunu","user_cut max_M_leplepnunu","user_cut min_delta_M_leplepnunu","user_cut max_delta_M_leplepnunu"]
user_parameters["ppeexnmnmx04"] = ["user_switch M_leplep","user_cut min_M_leplep","user_cut max_M_leplep","user_switch M_leplepnunu","user_cut min_M_leplepnunu","user_cut max_M_leplepnunu","user_cut min_delta_M_leplepnunu","user_cut max_delta_M_leplepnunu"]
# 2do: now also define mandatory cuts, which must be set, and its value restrictions


# define mandatory parameters to be cross checked if in parameter.dat
mandatory_parameters = ["E","coll_choice","save_previous_result","save_previous_log","NLO_subtraction_method"]
# define default values for parameters
default_parameters = {}
default_parameters["NLO_subtraction_method"] = 1 # use CS subtraction
default_parameters["loop_induced"] = 0 # no loop-induced contribution
default_parameters["max_time_per_job"] = 24 # hours
default_parameters["LHAPDF_LO"]   = "NNPDF30_lo_as_0118"
default_parameters["LHAPDF_NLO"]  = "NNPDF30_nlo_as_0118"
default_parameters["LHAPDF_NNLO"] = "NNPDF30_nnlo_as_0118"
# interval (in seconds) how often the status (queued/running/finished jobs) is printed out
default_parameters["print_out_interval"] = 60*5
# interval (in seconds) how often the jobs on the cluster are checked (and stopped/restarted/etc.)
default_parameters["check_interval"] = 60 * 15
default_parameters["switch_qT_accuracy"] = "0"
default_parameters["approx_ckm_EW"] = "1"

# the VT2 contribution for some processes is to slow to run 50000 events in the pre-run; 
# for these processes we can hardcode in the dictionary below (from experience) how many 
# events are roughly needed to achieve 0.001% relative precision to the total NNLO cross 
# section and how long (in seconds) this will take: [events,seconds]
VT2_use_default_runtime = {} # not used so far, but can be used to replace number of events and runtime for specific contributions after pre_run
#VT2_use_default_runtime["ppeeexex04"] = [100000,100000] # adjust from experience (note: every main run gives you new information about the runtimes so that you can improve)
# NNLO.QT-CS/24/VT2.QCD    dd~_ememepep              751834         358419     0.00017508925      5.5958941  0.00097978093
# NNLO.QT-CS/24/VT2.QCD    uu~_ememepep             1810483         893342     0.00027170381      5.5958941   0.0015204258

# new idea: use higher parallelization and events for extrapolation runs and define specific settings for different contributions
# to be able to do it later process specific we do a dictionary of a dictionary of a list [parallelization,events]
default_settings = {}
default_settings["loop"]    = [5,50000]
default_settings["VT2.QCD"] = [5,1000000] # [50,100000] 
default_settings["RVA.QCD"] = [1,1000000]  # [10,100000]
default_settings["RRA.QCD"] = [ 1,200000]
# default_settings["RA.QEW"] = [1,50000] # [50,100000] 
# default_settings["CA.QEW"] = [1,50000]  # [10,100000]
default_settings["VA.QEW"] = [1,50000]
default_settings["PT.QCD"] = [2,2000000]
default_settings["PT2.QCD"] = [5,5000000]
pre_run_settings = {}
pre_run_settings["default"] = default_settings

# for involved process use specific settings by employing the default settings and simply overwriting the ones that need to be changed
processes_with_involved_settings = ["ppttx20","ppeeexex04","ppemxnmnex04","ppeexa03","ppnenexa03","ppemexnmx04","ppenexa03","ppexnea03","ppemxnmnex04","ppemexmx04","ppeexmxnm04","ppeexexne04","ppeeexnex04","ppeexnenex04","ppeexnmnmx04","ppzz02","ppwxw02","ppaaa03"]
involved_settings = copy.copy(default_settings)
involved_settings["VA.QEW"] = [25,50000]
involved_settings["VT2.QCD"] = [100,100000]
involved_settings["RVA.QCD"] = [ 20,100000]
involved_settings["L2RT.QCD"] = [ 20,250000]
involved_settings["L2VT.QCD"] = [ 100,25000]
involved_settings["L2RA.QCD"] = [ 20,250000]
involved_settings["L2VA.QCD"] = [ 100,25000]
for proc in processes_with_involved_settings:
    pre_run_settings[proc] = copy.deepcopy(involved_settings)
#pre_run_settings[] = involved_settings # don't think we need this ?!?!
# specific settings for ppaaa03
#pre_run_settings["ppaaa03"]["VT2.QCD"] = [5,1000000] # JUST FOR NOW WITHOUT 2-loop virtual !
#pre_run_settings["ppaaa03"]["RVA.QCD"] = [20,200000]

#process specific settings for ppttx20
pre_run_settings["ppttx20"]["RVA.QCD"] = [20,1000000]
pre_run_settings["ppttx20"]["RRA.QCD"] = [5,1000000]
pre_run_settings["ppttx20"]["RCA.QCD"] = [1,1000000]
pre_run_settings["ppttx20"]["CT2.QCD"] = [5,1000000]
pre_run_settings["ppttx20"]["VT2.QCD"] = [10,1000000]
pre_run_settings["ppttx20"]["RA.QCD"]  = [1,1000000]
pre_run_settings["ppttx20"]["CA.QCD"]  = [1,1000000]
pre_run_settings["ppttx20"]["VA.QCD"]  = [1,1000000]
pre_run_settings["ppttx20"]["RT.QCD"]  = [1,1000000]
pre_run_settings["ppttx20"]["CT.QCD"]  = [1,1000000]
pre_run_settings["ppttx20"]["VT.QCD"]  = [1,1000000]
pre_run_settings["ppttx20"]["born"]    = [10,1000000]

# process specific settings for pphjj
pphjj41heft_settings = copy.copy(default_settings)
pphjj41heft_settings["VA.QCD"] = [2,10000]
pre_run_settings["pphjj41heft"] = pphjj41heft_settings


# below all model parameter are defined as a mapping from the SLHA format to the name how they are defined in MUNICH
model_mappings_to_MUNICH = multidim_dict(2)
#[Block][number]=parameter_name_in_MUNICH
model_mappings_to_MUNICH["MASS"][1]="M_d"
model_mappings_to_MUNICH["MASS"][2]="M_u"
model_mappings_to_MUNICH["MASS"][3]="M_s"
model_mappings_to_MUNICH["MASS"][4]="M_c"
model_mappings_to_MUNICH["MASS"][5]="M_b"
model_mappings_to_MUNICH["MASS"][6]="M_t"
model_mappings_to_MUNICH["MASS"][11]="M_e"
model_mappings_to_MUNICH["MASS"][12]="M_ve"
model_mappings_to_MUNICH["MASS"][13]="M_mu"
model_mappings_to_MUNICH["MASS"][14]="M_vm"
model_mappings_to_MUNICH["MASS"][15]="M_tau"
model_mappings_to_MUNICH["MASS"][16]="M_vt"
model_mappings_to_MUNICH["MASS"][23]="M_Z"
model_mappings_to_MUNICH["MASS"][24]="M_W"
model_mappings_to_MUNICH["MASS"][25]="M_H"
model_mappings_to_MUNICH["SMINPUTS"][1]="1/alpha_e_MZ"
model_mappings_to_MUNICH["SMINPUTS"][2]="G_F"
model_mappings_to_MUNICH["SMINPUTS"][111]="1/alpha_e_0"
model_mappings_to_MUNICH["EWINPUTS"][1]="ew_scheme"
model_mappings_to_MUNICH["EWINPUTS"][2]="use_adapted_ew_coupling"
model_mappings_to_MUNICH["EWINPUTS"][3]="use_cms"
model_mappings_to_MUNICH["CKM"][11]="V_du"
model_mappings_to_MUNICH["CKM"][12]="V_su"
model_mappings_to_MUNICH["CKM"][13]="V_bu"
model_mappings_to_MUNICH["CKM"][21]="V_dc"
model_mappings_to_MUNICH["CKM"][22]="V_sc"
model_mappings_to_MUNICH["CKM"][23]="V_bc"
model_mappings_to_MUNICH["CKM"][31]="V_dt"
model_mappings_to_MUNICH["CKM"][32]="V_st"
model_mappings_to_MUNICH["CKM"][33]="V_bt"
model_mappings_to_MUNICH["VCKMIN"][1]="theta_c" # Cabibbo angle
# 2do? Currently have all decay widths at all orders (LO, NLO and NNLO) the same value
model_mappings_to_MUNICH["DECAY"][6]="Gamma_t"
model_mappings_to_MUNICH["DECAY"][23]="Gamma_Z"
model_mappings_to_MUNICH["DECAY"][24]="Gamma_W"
model_mappings_to_MUNICH["DECAY"][25]="Gamma_H"
# define all processes with CKM matrix
ckm_processes = ["ppexne02","ppenex02","ppw01","ppwx01"]
ckm_EW_processes = ["ppexne02","ppenex02"]
LO_photon_induced_processes = ["ppeex02","ppeexa03","ppeeexex04","ppemexmx04","ppeexnenex04","ppeexnmnmx04","ppemxnmnex04"]
# mappings which contributions are replaced in resummation mode
# NLO+NLL mappings
resummation_map_NLO = {}
resummation_map_NLO["born"] = "NLL_LO"
resummation_map_NLO["VT.QCD"]   = "NLL_NLO"
resummation_map_NLO["CT.QCD"]   = "CT"
# NNLO+NNLL mappings
resummation_map_NNLO = {}      
resummation_map_NNLO["born"] = "NNLL_LO"
resummation_map_NNLO["VT.QCD"]   = "NNLL_NLO"
resummation_map_NNLO["CT.QCD"]   = "CT"
resummation_map_NNLO["VT2.QCD"]  = "NNLL_NNLO"
resummation_map_NNLO["CT2.QCD"]   = "CT2"

# possible run_modes (that are already working)
run_modes = []
run_modes.append("run")                 # normal run
run_modes.append("run_without_pre")     # same "run", but without pre run using pre-defined runtime.dat file
run_modes.append("run_grid")            # do only grid run
run_modes.append("run_grid_and_pre")    # do only grid run and pre run (for testing purposes)
run_modes.append("run_pre")             # do only pre run (grid_run must be already there)
run_modes.append("run_pre_and_main")    # do only main run (grid_run and pre run must be already there)
run_modes.append("run_main")            # do only main run (grid_run and pre run must be already there)
run_modes.append("run_main_without_pre") # same as "run_main", but without pre run using pre-defined runtime.dat file
run_modes.append("run_results")         # do only results run
run_modes.append("run_gnuplot")           # do only gnuplotting
run_modes.append("setup_run")           # do only set up the folder (no runs)
run_modes.append("delete_run")          # removes the run folder including all inputs/logs/results
run_modes.append("tar_run")             # create .tar archive of run folder including all inputs/logs/results
edit_input.run_modes = run_modes

#}}}

# parse command line arguments after default inputs
parser = argparse.ArgumentParser(description='MATRIX.')
parser.add_argument('run_folder', metavar='<run folder>', nargs='?', default="", help='run folder, must start with run_')
parser.add_argument('--input_dir', dest='input_dir', action='store', default=default_input, help='Specify directory inside input folder from where template MATRIX input files are taken (default: use \"%s\" folder)' % default_input)
parser.add_argument('--run_mode', dest='run_mode', action='store', default="", help='Specify run mode (RUN_MODE=\"run\"/\"run_grid\"/\"run_pre\"/\"run_pre_and_main\"/\"run_result\"/"run_gnuplot\")')
parser.add_argument('--delete_run',dest='delete_run', action='store_true', help='Remove run folder (including input/log/result).')
parser.add_argument('--setup_run',dest='setup_run', action='store_true', help='Setup the run folder, but not start running.')
parser.add_argument('--tar_run',dest='tar_run', action='store_true', help='Create .tar archive of run folder (including input/log/result).')
parser.add_argument('--change_name_to', dest='new_name', action='store', default="", help='Rename run folder (including input/log/result).')
parser.add_argument('--copy_run_from', dest='existing_run', action='store', default="", help='Copy run folder from existing run (including input/log/result).')
parser.add_argument('-c','--continue',dest='continue_run', action='store_true', help='Continue the previous run from the specified run_mode; important: make sure the inputs are consistent!')
args = parser.parse_args()    


#{{{ class: OutputSaver
# class OutputSaver(object):
#     def __init__(self,outfile):
#         self.terminal = sys.stdout
#         self.log = open(outfile, "w")

#     def write(self, message):
#         self.terminal.write(message)
#         self.log.write(message)  

#     def write_only_file(self, message):
#         self.log.write(message)  

#     def flush(self):
#         #this flush method is needed for python 3 compatibility.
#         #this handles the flush command by doing nothing.
#         #you might want to specify some extra behavior here.
#         pass    
#}}}
#{{{ class: inputs
class inputs():
    """Class to readin user inputs, wrap them and adjust MUNICH inputs"""
#{{{ def: __init__(self)
    def __init__(self):
        self.type_dict = {} # dictionary to define which infile.result has which contributions, corrections
        self.result_method = "TSV" # set default scale mode for scale variation to be TSV
        self.CV_and_TSV = False
#}}}
#{{{ def: init_infile_result(self,LOQCD,NLOQCD,NNLOQCD,LOEW,NLOEW)
    def init_infile_result(self,LOQCD,NLOQCD,NNLOQCD,NNNLOQCD,LOEW,NLOEW):
        self.all_infile_result_files = ["LO.%s%s.dat"%(LOQCD,LOEW),"NLO.%s%s.dat"%(LOQCD,LOEW),"NLO.QT.%s%s.dat"%(NLOQCD,LOEW),"NNLO.QT.%s%s.dat"%(NLOQCD,LOEW),"NLO.CS.%s%s.dat"%(NLOQCD,LOEW),"NNLO.%s%s.dat"%(LOQCD,LOEW),"NNLO.CS.%s%s.dat"%(NLOQCD,LOEW),"NNLO.QT-CS.%s%s.dat"%(NNLOQCD,LOEW)]
        # add contributions according to loop induced options
        if abs(int(parameter_list["loop_induced"])) > 0: self.all_infile_result_files.append("NNLO.%s%s.dat"%(NNLOQCD,LOEW))
        if abs(int(parameter_list["loop_induced"])) > 1:
            self.all_infile_result_files.append("NNNLO.CS.%s%s.dat"%(NNNLOQCD,LOEW))
            self.all_infile_result_files.append("NNNLO.QT.%s%s.dat"%(NNNLOQCD,LOEW))
        # add contributions according to RadISH options (not relevant for MATRIX v2)
        if parameter_list.get("add_RadISH_NLL") == "1": self.all_infile_result_files.append("RadISH.NLL.%s%s.dat"%(NLOQCD,LOEW))
        if parameter_list.get("add_RadISH_NNLL") == "1": self.all_infile_result_files.append("RadISH.NNLL.%s%s.dat"%(NNLOQCD,LOEW))
        if parameter_list.get("add_RadISH_N3LL") == "1": self.all_infile_result_files.append("RadISH.N3LL.%s%s.dat"%(NNLOQCD,LOEW))
        # add contributions according to EW options
        if parameter_list.get("run_NLO_EW","0") == "1": self.all_infile_result_files.append("NLO.CS.%s%s.dat"%(LOQCD,NLOEW))
        if parameter_list.get("add_NLO_EW","0") == "1": self.all_infile_result_files.append("NNLO.CS.%s%s.dat"%(LOQCD,NLOEW))
        if parameter_list.get("photon_induced","0") == "1":
            self.all_infile_result_files.append("LO.a%s%s.dat"%(LOQCD,LOEW))
            self.all_infile_result_files.append("NLO.a%s%s.dat"%(LOQCD,LOEW))
            self.all_infile_result_files.append("NNLO.a%s%s.dat"%(LOQCD,LOEW))
            if parameter_list.get("run_NLO_EW","0") == "1": self.all_infile_result_files.append("NLO.CS.a%s%s.dat"%(LOQCD,NLOEW))
            if parameter_list.get("add_NLO_EW","0") == "1": self.all_infile_result_files.append("NNLO.CS.a%s%s.dat"%(LOQCD,NLOEW))

        self.type_dict["---"]       = [["born","---","0"]]
        self.type_dict["RadISH.NLL.%s%s"%(NLOQCD,LOEW)] = [["NLL.RadISH","---","0"]]
        self.type_dict["RadISH.NNLL.%s%s"%(NNLOQCD,LOEW)] = [["NNLL.RadISH","---","0"]]
        self.type_dict["RadISH.N3LL.%s%s"%(NNLOQCD,LOEW)] = [["N3LL.RadISH","---","0"]]
        self.type_dict["CS"]     = [["VA","QCD","0"],["CA","QCD","0"],["RA","QCD","0"]]
        if parameter_list.get("power_corrections") == "1":
            self.type_dict["QT"]     = [["VT","QCD","0"],["CT","QCD","0"],["RT","QCD","0"],["PT","QCD","0"]]
        else:
            self.type_dict["QT"]     = [["VT","QCD","0"],["CT","QCD","0"],["RT","QCD","0"]]
        self.type_dict["NJ"]     = [["VJ","QCDorQEW","0"],["CJ","QCDorQEW","0"],["RJ","QCDorQEW","0"]]
        if parameter_list.get("power_corrections") == "1":
            self.type_dict["QT-CS"]  = [["VT2","QCD","0"],["CT2","QCD","0"],["RVA","QCD","0"],["RCA","QCD","0"],["RRA","QCD","0"],["PT2","QCD","0"]]
        else:
            self.type_dict["QT-CS"]  = [["VT2","QCD","0"],["CT2","QCD","0"],["RVA","QCD","0"],["RCA","QCD","0"],["RRA","QCD","0"]]
        self.type_dict["NJ-CS"]  = [["VJ2","QCD","0"],["CJ2","QCD","0"],["RVJ","QCD","0"],["RCJ","QCD","0"],["RRJ","QCD","0"]]
        self.type_dict["NLO.CS.%s%s"%(LOQCD,NLOEW)]  = [["VA","QEW","0"],["CA","QEW","0"],["RA","QEW","0"]]
        self.type_dict["NNLO.CS.%s%s"%(LOQCD,NLOEW)] = [["VA","QEW","0"],["CA","QEW","0"],["RA","QEW","0"]]
        self.type_dict["NLO.CS.a%s%s"%(LOQCD,NLOEW)]  = [["VA","QEW","0"],["CA","QEW","0"],["RA","QEW","0"]]
        self.type_dict["NNLO.CS.a%s%s"%(LOQCD,NLOEW)] = [["VA","QEW","0"],["CA","QEW","0"],["RA","QEW","0"]]
        self.type_dict["NNLO.%s%s"%(NNLOQCD,LOEW)]      = [["loop","---","0"]]
        self.type_dict["NNNLO.CS.%s%s"%(NNNLOQCD,LOEW)] = [["L2VA","QCD","0"],["L2CA","QCD","0"],["L2RA","QCD","0"]]
        self.type_dict["NNNLO.QT.%s%s"%(NNNLOQCD,LOEW)] = [["L2VT","QCD","0"],["L2CT","QCD","0"],["L2RT","QCD","0"]]
#{{{ def: init_infile_result(self,LOQCD,NLOQCD,NNLOQCD,LOEW,NLOEW)
#     def init_infile_result(self,LOQCD,NLOQCD,NNLOQCD,LOEW,NLOEW):
#         self.all_infile_result_files = ["LO.%s%s.dat"%(LOQCD,LOEW),"LO.aa%s%s.dat"%(LOQCD,LOEW),"NLO.%s%s.dat"%(LOQCD,LOEW),"NLO.aa%s%s.dat"%(LOQCD,LOEW),"NLO.CS.%s%s.dat"%(NLOQCD,LOEW),"NLO.CS.%s%s.dat"%(LOQCD,NLOEW),"NLO.CS.a%s%s.dat"%(LOQCD,NLOEW),"NLO.CS.aa%s%s.dat"%(LOQCD,NLOEW),"NLO.QT.%s%s.dat"%(NLOQCD,LOEW),"NLO.NJ.%s%s.dat"%(NLOQCD,LOEW),"NNLO.%s%s.dat"%(LOQCD,LOEW),"NNLO.aa%s%s.dat"%(LOQCD,LOEW),"NNLO.%s%s.dat"%(NNLOQCD,LOEW),"NNLO.CS.%s%s.dat"%(NLOQCD,LOEW),"NNLO.CS.%s%s.dat"%(LOQCD,NLOEW),"NNLO.CS.a%s%s.dat"%(LOQCD,NLOEW),"NNLO.CS.aa%s%s.dat"%(LOQCD,NLOEW),"NNLO.QT.%s%s.dat"%(NLOQCD,LOEW),"NNLO.NJ.%s%s.dat"%(NLOQCD,LOEW),"NNLO.QT-CS.%s%s.dat"%(NNLOQCD,LOEW),"NNLO.NJ-CS.%s%s.dat"%(NNLOQCD,LOEW)]#,"RadISH.NLL.%s%s.dat"%(NLOQCD,LOEW),"RadISH.NNLL.%s%s.dat"%(NNLOQCD,LOEW),"RadISH.N3LL.%s%s.dat"%(NNLOQCD,LOEW)]
#         self.type_dict["born"]   = [["born","---","0"]]
#         self.type_dict["loop"]   = [["loop","---","0"]]
# #        self.type_dict["RadISH.NLL.%s%s"%(NLOQCD,LOEW)] = [["NLL.RadISH","---","0"]]
# #        self.type_dict["RadISH.NNLL.%s%s"%(NNLOQCD,LOEW)] = [["NNLL.RadISH","---","0"]]
# #        self.type_dict["RadISH.N3LL.%s%s"%(NNLOQCD,LOEW)] = [["N3LL.RadISH","---","0"]]
#         self.type_dict["CS"]     = [["VA","QCDorQEW","0"],["CA","QCDorQEW","0"],["RA","QCDorQEW","0"]]
#         self.type_dict["QT"]     = [["VT","QCDorQEW","0"],["CT","QCDorQEW","0"],["RT","QCDorQEW","0"]]
#         self.type_dict["NJ"]     = [["VJ","QCDorQEW","0"],["CJ","QCDorQEW","0"],["RJ","QCDorQEW","0"]]
#         self.type_dict["QT-CS"]  = [["VT2","QCDorQEW","0"],["CT2","QCDorQEW","0"],["RVA","QCDorQEW","0"],["RCA","QCDorQEW","0"],["RRA","QCDorQEW","0"]]
#         self.type_dict["NJ-CS"]  = [["VJ2","QCDorQEW","0"],["CJ2","QCDorQEW","0"],["RVJ","QCDorQEW","0"],["RCJ","QCDorQEW","0"],["RRJ","QCDorQEW","0"]]
#}}}
#}}}
#{{{ def: input_change_entry(self,file_path,parameter,value)
    def input_change_entry(self,file_path,parameter,value):
# function to change a single parameter (all occurences) of MUNICH input files
# if paramater does not exist in this file it is not set
# prop 2do: depending on parameter one could allow only for certain value types
        with open(file_path+".replace",'w') as new_file:
            with open(file_path, 'r') as in_file:
                for in_line in in_file:
                    line=in_line.strip() # strip removes all spaces (including tabs and newlines)
                    # if any line starts with %, # or is an emtpy line (disregarding spaces) it is a comment line and should be skipped
                    if line=="" or line[0]=="%" or line[0]=="#": 
                        new_file.write(in_line)
                        continue
                    # split line by "=" and remove spaces again from string
                    # [0] gives you the parameter (before "="-sign)
                    file_parameter=line.split('=',1)[0].strip()
                    # [1] gives you the value (after "="-sign); remove trailing % or # and everything after in this case
                    file_value=line.split('=',1)[1].split("%")[0].split("#")[0].strip()
                    if file_parameter == parameter:
                        new_file.write("%s = %s \n" %(file_parameter,value))
                    else:
                        new_file.write(in_line)
        os.remove(file_path)
        shutil.move(file_path+".replace",file_path)
#}}}
#{{{ def: input_set_entry(self,file_path,parameter,value)
    def input_set_entry(self,file_path,parameter,value):
# function to set a single parameter (all occurences) of MUNICH input files
# if paramater does not exist in this file it added at the end of 
# prop 2do: depending on parameter one could allow only for certain value types
        if not os.path.isfile(file_path):
            open(file_path, 'a').close()
        parameter_set = False
        with open(file_path+".replace",'w') as new_file:
            with open(file_path, 'r') as in_file:
                for in_line in in_file:
                    line=in_line.strip() # strip removes all spaces (including tabs and newlines)
                    # if any line starts with %, # or is an emtpy line (disregarding spaces) it is a comment line and should be skipped
                    if line=="" or line[0]=="%" or line[0]=="#": 
                        new_file.write(in_line)
                        continue
                    # split line by "=" and remove spaces again from string
                    # [0] gives you the parameter (before "="-sign)
                    file_parameter=line.split('=',1)[0].strip()
                    # [1] gives you the value (after "="-sign); remove trailing % or # and everything after in this case
                    file_value=line.split('=',1)[1].split("%")[0].split("#")[0].strip()
                    if file_parameter == parameter:
                        new_file.write("%s = %s \n" %(file_parameter,value))
                        parameter_set = True
                    else:
                        new_file.write(in_line)
                if not parameter_set:
                    new_file.write("%s = %s \n" %(parameter,value))
        os.remove(file_path)
        shutil.move(file_path+".replace",file_path)
#}}}
#{{{ def: input_set_line(self,file_path,parameter)
    def input_set_line(self,file_path,parameter):
# function to set a full line (all occurences) of MUNICH input files
# if line does not exist in this file it added at the end of 
        if not os.path.isfile(file_path):
            open(file_path, 'a').close()
        parameter_set = False
        with open(file_path+".replace",'w') as new_file:
            with open(file_path, 'r') as in_file:
                for in_line in in_file:
                    line=in_line.strip() # strip removes all spaces (including tabs and newlines)
                    # if any line starts with %, # or is an emtpy line (disregarding spaces) it is a comment line and should be skipped
                    if line=="" or line[0]=="%" or line[0]=="#": 
                        new_file.write(in_line)
                        continue
                    # split line by "=" and remove spaces again from string
                    # [0] gives you the parameter (before "="-sign)
                    file_parameter=line.split("%")[0].split("#")[0].strip()
                    if file_parameter == parameter:
                        new_file.write("%s\n" % file_parameter)
                        parameter_set = True
                    else:
                        new_file.write(in_line)
                if not parameter_set:
                    new_file.write("%s\n" % parameter)
        os.remove(file_path)
        shutil.move(file_path+".replace",file_path)
#}}}
#{{{ def: input_add_entry(self,file_path,parameter,value)
    def input_add_entry(self,file_path,parameter,value):
# function to add a single parameter at the end of a MUNICH input file
        with open(file_path,'a') as in_file:
            if parameter == "" and value == "":
                in_file.write("\n")
            else:
                in_file.write("%s = %s \n" %(parameter,value))
#}}}
#{{{ def: input_remove_entry(self,file_path,parameter)
    def input_remove_entry(self,file_path,parameter):
# function to remove a single parameter (all occurences) from MUNICH input files
# if paramater does not exists nothing happens
        with open(file_path+".replace",'w') as new_file:
            with open(file_path, 'r') as in_file:
                for in_line in in_file:
                    line=in_line.strip() # strip removes all spaces (including tabs and newlines)
                    # if any line starts with %, # or is an emtpy line (disregarding spaces) it is a comment line and should be skipped
                    if line=="" or line[0]=="%" or line[0]=="#": 
                        new_file.write(in_line)
                        continue
                    # split line by "=" and remove spaces again from string
                    # [0] gives you the parameter (before "="-sign)
                    file_parameter=line.split('=',1)[0].strip()
                    # [1] gives you the value (after "="-sign); remove trailing % or # and everything after in this case
                    file_value=line.split('=',1)[1].split("%")[0].split("#")[0].strip()
                    if file_parameter == parameter:
                        continue
                    else:
                        new_file.write(in_line)
        os.remove(file_path)
        shutil.move(file_path+".replace",file_path)
#}}}
#{{{ def: input_search_keyword_set_entry_below(self,file_path,parameter,value)
    def input_search_keyword_set_entry_below(self,file_path,parameter,value):
# function to set single parameter (first occurence) of MUNICH input files
# prop 2do: depending on parameter one could allow only for certain value types
        # initial condition: keyword_needs to be found, and parameter needs to be set
        keyword_found = False
        parameter_set = False
        with open(file_path+".replace",'w') as new_file:
            with open(file_path, 'r') as in_file:
                for in_line in in_file:
                    line=in_line.strip() # strip removes all spaces (including tabs and newlines)
                    # if any line starts with %, # or is an emtpy line (disregarding spaces) it is a comment line and should be skipped
                    # or once the parameter was set, stop searching for more occurences and simply write out the rest of the file
                    if line=="" or line[0]=="%" or line[0]=="#" or parameter_set: 
                        new_file.write(in_line)
                        continue
                    # split line by "=" and remove spaces again from string
                    # [0] gives you the parameter (before "="-sign)
                    file_parameter=line.split('=',1)[0].strip()
                    # [1] gives you the value (after "="-sign); remove trailing % or # and everything after in this case
                    file_value=line.split('=',1)[1].split("%")[0].split("#")[0].strip()
                    # check parameter names until you find the one of the key with the right value
                    if file_parameter == ord_params_keyword[parameter][0] and file_value == ord_params_keyword[parameter][1]:
                        keyword_found = True
                    # when keyword found search below the parameter you want to set
                    if keyword_found == True and file_parameter == ord_params_keyword[parameter][2]:
                        new_file.write(file_parameter+" = "+value+" \n")
                        # once the parameter was set, stop searching for more occurences
                        parameter_set = True
                    else:
                        new_file.write(in_line)
        os.remove(file_path)
        shutil.move(file_path+".replace",file_path)
        if not keyword_found:
            out.print_warning("Keyword \"%s\" with value \"%s\" in file_parameter.dat was not found, could not set parameter \"%s\" below to value \"%s\", continuing..."%(ord_params_keyword[parameter][0],ord_params_keyword[parameter][1],parameter,value))
        if not parameter_set:
            out.print_warning("Keyword \"%s\" with value \"%s\" in file_parameter.dat was found, but could not find parameter \"%s\" below and set it to value \"%s\", continuing..."%(ord_params_keyword[parameter][0],ord_params_keyword[parameter][1],ord_params_keyword[parameter][2],value))

#}}}
#{{{ def: input_read_and_check_distribution_dat(self,file_path,distribution_list)
    def input_read_and_check_distribution_dat(self,file_path,distribution_list):
# function to read all parameters from the MATRIX input file (file_path, "parameter.dat")
# and write it into a dictionary (parameter_list)
# works also for MATRIX configuration file
        if not os.path.isfile(file_path):
            out.print_error("file "+file_path+" in function input_read_and_check_distribution_dat does not exist!")
        with open(file_path, 'r') as distribution_file:
            for in_line in distribution_file:
                line=in_line.strip() # strip removes all spaces (including tabs and newlines)
                # if any line starts with %, # or is an emtpy line (disregarding spaces) it is a comment line and should be skipped
                if line=="" or line[0]=="%" or line[0]=="#":
                    continue
                # split line by "=" and remove spaces again from string
                # [0] gives you the parameter (before "="-sign)
                parameter=line.split('=',1)[0].strip()
                # [1] gives you the value (after "="-sign); remove trailing % or # and everything after in this case
                value=line.split('=',1)[1].strip()
                if parameter == "distributionname":
                    if value in distribution_list:
                        out.print_error("Same distributionname \"%s\" in distribution.dat used twice. Use unique identifiers and restart..." % distribution_name)
                    else:
                        distribution_name = value
                else:
                    distribution_list[distribution_name][parameter]=value
#}}}
#{{{ def: input_read_parameter_dat(self,file_path,parameter_list)
    def input_read_parameter_dat(self,file_path,parameter_list):
# function to read all parameters from the MATRIX input file (file_path, "parameter.dat")
# and write it into a dictionary (parameter_list)
# works also for MATRIX configuration file
        if not os.path.isfile(file_path):
            out.print_error("file "+file_path+" in function input_read_parameter_dat does not exist!")
        with open(file_path, 'r') as param_file:
            for in_line in param_file:
                line=in_line.strip() # strip removes all spaces (including tabs and newlines)
                # if any line starts with %, # or is an emtpy line (disregarding spaces) it is a comment line and should be skipped
                if line=="" or line[0]=="%" or line[0]=="#":
                    continue
                # split line by "=" and remove spaces again from string
                # [0] gives you the parameter (before "="-sign)
                file_parameter=line.split('=',1)[0].strip()
                # [1] gives you the value (after "="-sign); remove trailing % or # and everything after in this case
                try:
                    file_value=line.split('=',1)[1]
                    if file_value.strip().startswith("\"\"\""):
                        file_value=file_value.split("\"\"\"",1)[1].rsplit("\"\"\"")[0]
                    elif file_value.strip().startswith("\""):
                        file_value=file_value.split("\"")[1]
                    else:
                        file_value=file_value.split("%")[0].split("#")[0].strip()
                except:
                    out.print_error_no_stop("Something wrong in parameter.dat file. The following line:")
                    print("\033[91m" + "                 "+line + "\033[0m")
                    out.print_error_no_stop("can not be understood. The structure must be:")
                    print("\033[91m" + "                 $parameter = $value" + "\033[0m")
                    out.print_error("and comments must be started by \"#\" or \"%%\". Exiting...")
                if file_parameter.startswith("fiducial_cut"):
                    file_parameter = line.split("%")[0].split("#")[0].strip()
                    file_value = ""
                parameter_list[file_parameter]=file_value
#}}}
#{{{ def: input_set_file_parameter_from_list(self,file_path,parameter_list)
    def input_set_file_parameter_from_list(self,file_path,parameter_list):
# function to set all parameters in MUNICH input ("file_parameter.dat") from parameter_list 
# read from the MATRIX input file
        parameter_list_copy = copy.copy(parameter_list)
        # first remove all fiducial cut entries
        self.input_remove_entry(file_path,"fiducial_cut")
        for parameter in parameter_list_copy:
            value = parameter_list[parameter] 
            if parameter in unique_parameters:
                # all parameters uniquely defined can be directly set as MUNICH input
                self.input_set_entry(file_path,parameter,value)
            elif parameter in ordered_parameters:
                # these parameters require a certain order, the following function sets the dependend on some keyword
                # the keywords for specific parameters are defined as a dictionary in the very beginning
                self.input_search_keyword_set_entry_below(file_path,parameter,value)
                if parameter == "LHAPDF_NNLO":
                    self.input_search_keyword_set_entry_below(file_path,"LHAPDF_NNNLO",value)
                if parameter == "PDFsubset_NNLO":
                    self.input_search_keyword_set_entry_below(file_path,"PDFsubset_NNNLO",value)
            elif parameter in renamed_parameters:
                parameter = renamed_parameter_mappings[parameter]
                self.input_set_entry(file_path,parameter,value)
                if parameter == "prefactor_CV":
                    self.input_set_entry(file_path,"prefactor_reference",value)          
            elif parameter in MATRIX_parameters:
                # backwards compatibility:
                if parameter == "run_NLO":
                    parameter_list["run_NLO_QCD"] = value
                if parameter == "precision_NLO":
                    parameter_list["precision_NLO_QCD"] = value
                if parameter == "run_NNLO":
                    parameter_list["run_NNLO_QCD"] = value
                if parameter == "precision_NNLO":
                    parameter_list["precision_NNLO_QCD"] = value
                if parameter == "accuracy_LO":
                    parameter_list["precision_LO"] = value
                if parameter == "accuracy_NLO":
                    parameter_list["precision_NLO_QCD"] = value
                if parameter == "accuracy_NNLO":
                    parameter_list["precision_NNLO_QCD"] = value
                # nothing else to do in that case
                continue
            elif parameter in special_parameters:
                # these are special cases for the parameter inputs
                if parameter == "switch_off_shell" and value == "1":
                    self.input_add_entry(file_path,"type_perturbative_order","all")
                    self.input_add_entry(file_path,"type_contribution","all")
                    self.input_add_entry(file_path,"type_correction","all")
                    self.input_add_entry(file_path,"n_tau_events","5000")
                    self.input_add_entry(file_path,"n_x1x2_events","5000")
                    self.input_add_entry(file_path,"n_IS_events","50000")
                    self.input_add_entry(file_path,"n_IS_events_factor","1")
                    self.input_add_entry(file_path,"n_alpha_events","5000")
                    self.input_add_entry(file_path,"n_step","5000")
                    self.input_add_entry(file_path,"","")
                    self.input_add_entry(file_path,"type_perturbative_order","all")
                    self.input_add_entry(file_path,"type_contribution","loop")
                    self.input_add_entry(file_path,"type_correction","all")
                    self.input_add_entry(file_path,"n_tau_events","500")
                    self.input_add_entry(file_path,"n_x1x2_events","500")
                    self.input_add_entry(file_path,"n_IS_events","5000")
                    self.input_add_entry(file_path,"n_IS_events_factor","1")
                    self.input_add_entry(file_path,"n_alpha_events","500")
                    self.input_add_entry(file_path,"n_step","500")
                    self.input_add_entry(file_path,"","")
                elif parameter == "switch_distribution": 
                    self.input_change_entry(file_path,parameter,value)
                    parameter = "switch_output_distribution"
                    self.input_change_entry(file_path,parameter,value)
                elif parameter == "dynamic_scale":
                    self.input_change_entry(file_path,parameter,value)
                    parameter = "dynamic_scale_CV" 
                    self.input_change_entry(file_path,parameter,value)
                elif (parameter == "scale_variation" and (int(parameter_list.get("use_TSV","1")) == 0 or self.CV_and_TSV)):
                    if value == "0": # no variation
                        self.input_change_entry(file_path,"switch_CV","5")
                        self.input_change_entry(file_path,"n_scales_CV","7")
                        parameter_list["variation_factor"] = "1"
                        self.input_change_entry(file_path,"variation_factor_CV","1")
                    if value == "1": # 7-point variation
                        self.input_change_entry(file_path,"switch_CV","5")
                        self.input_change_entry(file_path,"n_scales_CV","7")
                    if value == "2": # 9-point variation
                        self.input_change_entry(file_path,"switch_CV","6")
                        self.input_change_entry(file_path,"n_scales_CV","9")
                elif parameter == "flavor_scheme":
                    if value == "1": # 4FS
                        self.input_change_entry(file_path,"N_f","4")
                        self.input_change_entry(file_path,"N_f_active","4")
                    elif value == "2": # 5FS
                        self.input_change_entry(file_path,"N_f","5")
                        self.input_change_entry(file_path,"N_f_active","5")
                elif parameter == "reduce_workload":
                    if value == "0":
                        pass
                    elif value == "1" or value == "2":
                        self.input_set_entry(file_path,"switch_output_execution","1")   # needed for script to check wether job is finished
                        self.input_set_entry(file_path,"switch_output_result","1")      # needed for result output
                        self.input_set_entry(file_path,"switch_output_integration","0") # interesting for debugging, usually turned on, but turn off to reduce workload
                        self.input_set_entry(file_path,"switch_output_maxevent","0")    # usually turned off anyways
                        self.input_set_entry(file_path,"switch_output_comparison","0")  # usually turned off anyways
                        self.input_set_entry(file_path,"switch_output_gnuplot","0")     # usually turned off anyways
                        self.input_set_entry(file_path,"switch_output_proceeding","0")  # usually turned off anyways
                    else:
                        out.print_error("Value \"%s\" for parameter \"reduce_workload\" not implemented. Remove switch or choose different value (0,1 or 2). Stopping the code..." % value)
                elif parameter == "loop_induced":
                    if int(value) < 0:
                        parameter_list["min_qTcut"] = 0.8
                        parameter_list["max_min_qTcut"] = parameter_list["min_qTcut"]
                        parameter_list["min_interval"] = 0.
                        parameter_list["min_max_qTcut"] = 2.
                        parameter_list["min_n_qTcut"] = 1 # number of cut values used at least for extrapolation

                        parameter_list["n_qTcut"] = 81 # number of computed cuts
                        self.input_change_entry(file_path,"min_qTcut",parameter_list["min_qTcut"])
                        self.input_change_entry(file_path,"n_qTcut",parameter_list["n_qTcut"])
                        self.input_change_entry(file_path,"step_qTcut","0.04")
                elif parameter == "switch_qT_accuracy":
                    if int(parameter_list.get("loop_induced")) < 0:
                        parameter_list["min_qTcut"] = 0.8
                        parameter_list["max_min_qTcut"] = parameter_list["min_qTcut"]
                        parameter_list["min_interval"] = 0.
                        parameter_list["min_max_qTcut"] = 2.
                        parameter_list["min_n_qTcut"] = 1 # number of cut values used at least for extrapolation
                        
                        parameter_list["n_qTcut"] = 81 # number of computed cuts
                        self.input_change_entry(file_path,"min_qTcut",parameter_list["min_qTcut"])
                        self.input_change_entry(file_path,"n_qTcut",parameter_list["n_qTcut"])
                        self.input_change_entry(file_path,"step_qTcut","0.04")
                    elif value == "0": # default: lower accuracy, faster convergence
                        parameter_list["min_qTcut"] = 0.15
                        parameter_list["max_min_qTcut"] = parameter_list["min_qTcut"]
                        parameter_list["min_interval"] = 0.21
                        parameter_list["min_max_qTcut"] = 0.36
                        parameter_list["min_n_qTcut"] = 5 # number of cut values used at least for extrapolation
                        
                        parameter_list["n_qTcut"] = 86 # number of computed cuts
                        self.input_change_entry(file_path,"min_qTcut",parameter_list["min_qTcut"])
                        self.input_change_entry(file_path,"n_qTcut",parameter_list["n_qTcut"])
                        self.input_change_entry(file_path,"step_qTcut","0.01")
                        if int(parameter_list.get("extrapolate_binwise","0")) > 0:
                            self.input_set_entry(file_path,"selection_qTcut_distribution","0.15:0.2:0.25:0.3:0.35:0.5:0.75:1.") # values for r_cut extrapolation of distributios
                    elif value == "1": # increased accuracy, slower convergence
                        parameter_list["min_qTcut"] = 0.05
                        parameter_list["max_min_qTcut"] = parameter_list["min_qTcut"]
                        parameter_list["min_interval"] = 0.21
                        parameter_list["min_max_qTcut"] = 0.26
                        parameter_list["min_n_qTcut"] = 5 # number of cut values used at least for extrapolation
                
                        parameter_list["n_qTcut"] = 96 # number of computed cuts
                        self.input_change_entry(file_path,"min_qTcut",parameter_list["min_qTcut"])
                        self.input_change_entry(file_path,"n_qTcut",parameter_list["n_qTcut"])
                        self.input_change_entry(file_path,"step_qTcut","0.01")
                        if int(parameter_list.get("extrapolate_binwise","0")) > 0:
                            self.input_set_entry(file_path,"selection_qTcut_distribution","0.05:0.1:0.15:0.2:0.25:0.5:0.75:1.") # values for r_cut extrapolation of distributios
                    elif value == "2" or value == "-1": # default: maximal accuracy, slowest convergence
                        parameter_list["min_qTcut"] = 0.01
                        parameter_list["max_min_qTcut"] = 0.05
                        parameter_list["min_interval"] = 0.25
                        parameter_list["min_max_qTcut"] = 0.26
                        parameter_list["min_n_qTcut"] = 5 # number of cut values used at least for extrapolation

                        parameter_list["n_qTcut"] = 100 # number of computed cuts
                        self.input_change_entry(file_path,"min_qTcut",parameter_list["min_qTcut"])
                        self.input_change_entry(file_path,"n_qTcut",parameter_list["n_qTcut"])
                        self.input_change_entry(file_path,"step_qTcut","0.01")
                        if int(parameter_list.get("extrapolate_binwise","0")) > 0:
                            self.input_set_entry(file_path,"selection_qTcut_distribution","0.01:0.05:0.1:0.15:0.2:0.25:0.5:0.75:1.") # values for r_cut extrapolation of distributios
                    else:
                        out.print_error("Value \"%s\" for parameter \"switch_qT_accuracy\" not implemented. Remove switch or choose different value (0 or 1). Stopping the code..." % value)
                elif parameter == "power_corrections" or parameter == "extrapolate_binwise" or parameter == "use_TSV":
                    if int(parameter_list.get("use_TSV","1")) == 0:
                        self.result_method = "CV"
                    if int(value) > 0 or int(parameter_list.get("use_TSV","1")) > 0:
                        self.result_method = "TSV"
                        if parameter == "use_TSV" and int(value) == 1 or int(parameter_list.get("use_TSV","1")) == 1:
                            self.input_set_entry(file_path,"switch_CV","0")
                        elif parameter == "use_TSV" and int(value) == 2:
                            self.CV_and_TSV = True
                        self.input_set_entry(file_path,"switch_TSV","1")
                        if parameter_list["dynamic_scale"] == "0":
                            self.scale_setting = "fixed-scale"
                        else:
                            self.scale_setting = "dynamic-scale-"+parameter_list["dynamic_scale"]
                        self.input_set_entry(file_path,"scaleset",self.scale_setting)
                        self.input_set_entry(file_path,"relative_central_scale_TSV",parameter_list["factor_central_scale"])
                        self.input_set_entry(file_path,"dynamic_scale_TSV",parameter_list["dynamic_scale"])
                        if parameter_list["scale_variation"] == "0": # no variation
                            self.input_set_entry(file_path,"n_scale_TSV","1")
                            parameter_list["variation_factor"] = "1"
                            self.input_set_entry(file_path,"variation_factor_TSV","1")
                        else: # TSV always computes 7-point and 9-point variation
                            self.input_set_entry(file_path,"n_scale_TSV","3")
                        self.input_set_entry(file_path,"factor_scale_TSV",parameter_list["variation_factor"])
                        self.input_set_entry(file_path,"switch_distribution_TSV",parameter_list["switch_distribution"])
                    
                        self.input_set_entry(file_path,"name_reference_TSV",self.scale_setting) # reference scale selected by name
                        if parameter_list["scale_variation"] == "0": # no variation
                            self.input_set_entry(file_path,"no_scale_ren_reference_TSV","0")   # reference ren. scale, 0=central for no variation
                            self.input_set_entry(file_path,"no_scale_fact_reference_TSV","0")  # reference fact. scale, 0=central for no variation
                        else: # TSV always computes 7-point and 9-point variation
                            self.input_set_entry(file_path,"no_scale_ren_reference_TSV","1")   # reference ren. scale, 1=central
                            self.input_set_entry(file_path,"no_scale_fact_reference_TSV","1")  # reference fact. scale, 1=central
                        self.input_set_entry(file_path,"no_qTcut_reference_TSV","0")       # reference qTcut scale
                        if parameter == "extrapolated_binwise" and not "switch_qT_accuracy" in parameter_list:
                            self.input_set_entry(file_path,"selection_qTcut_distribution","0.15:0.2:0.25:0.3:0.35:0.5:0.75:1.") # values for r_cut extrapolation of distributions
                continue
            elif parameter.startswith("user_"): # use this to include all possibly newly user-defined parameters
                # user defined parameters are process dependent and case dependent
                if prc.process_name in ["ppeeexex04"] and parameter in ["user_switch M_leplep","user_cut min_M_leplep","user_cut max_M_leplep","user_cut min_M_leplep_IR"]: # very special case to choose either ATLAS or CMS pairing
                    if not parameter == "user_switch M_leplep":
                        self.input_set_entry(file_path,parameter,value)                        
                    elif value == "0":
                        self.input_set_entry(file_path,parameter,value)                        
                    elif value == "1": # this case set ATLAS paring
                        self.input_set_entry(file_path,parameter,value)                        
                        self.input_set_entry(file_path,"user_switch M_leplep_ATLAS","1")
                        self.input_set_entry(file_path,"user_switch M_leplep_CMS","0")
                    elif value == "2": # this case set CMS paring
                        value = "1"
                        self.input_set_entry(file_path,parameter,value)                        
                        self.input_set_entry(file_path,"user_switch M_leplep_ATLAS","0")
                        self.input_set_entry(file_path,"user_switch M_leplep_CMS","1")
                else: # standard behavior
                    self.input_set_entry(file_path,parameter,value)
                    # not needed anymore since switches are now explicit in input file
#                     # and its switch
#                     if parameter in user_parameter_switches: # pre-defined hard-coded switch mappings
#                         switch = user_parameter_switches[parameter]
#                     else: # default behaviour
#                         if parameter.split()[1].startswith("max_"):
#                             switch = "user_switch "+parameter.split()[1][parameter.split()[1].startswith("max_") and len("max_"):]
#                         elif parameter.split()[1].startswith("min_"):
#                             switch = "user_switch "+parameter.split()[1][parameter.split()[1].startswith("min_") and len("min_"):]
#                         else:
#                             switch = "user_switch "+parameter.split()[1]

#                     switch_value = "1"
# #                    print("switch   ",switch,switch_value)
#                     self.input_set_entry(file_path,switch,switch_value)
                continue
            elif parameter.startswith("fiducial_cut"): # use this to include all possible settings one may wanna add to the file_paramter.dat
                # a hidden parameter is used like a unique parameter, but can be any not just the pre-defined parameters
                self.input_set_line(file_path,parameter)
                continue
            elif parameter.startswith("hidden "): # use this to include all possible settings one may wanna add to the file_paramter.dat
                # a hidden parameter is used like a unique parameter, but can be any not just the pre-defined parameters
                parameter = parameter[7:]
                self.input_set_entry(file_path,parameter,value)
                continue
            elif parameter.startswith("OL "): # allow OL parameters to be overwritten or added
                self.input_set_entry(file_path,parameter,value)
                continue
            elif parameter.startswith("RCL "): # allow RCL parameters to be overwritten or added
                self.input_set_entry(file_path,parameter,value)
                continue
            elif parameter.startswith("switch_OL"): # allow OL switch parameter to be overwritten or added
                self.input_set_entry(file_path,parameter,value)
                continue
            elif parameter.startswith("switch_RCL"): # allow RCL switch parameter to be overwritten or added
                self.input_set_entry(file_path,parameter,value)
                continue
            elif parameter.startswith("switch_yuk"): # allow RCL switch parameter to be overwritten or added
                self.input_set_entry(file_path,parameter,value)
                continue
            elif parameter.startswith("order_y"): # allow RCL switch parameter to be overwritten or added
                self.input_set_entry(file_path,parameter,value)
                continue
         #   elif  parameter.startswith("N_quarks"):
         #       self.input_set_entry(file_path,parameter,value)
         #       continue
            else:
                out.print_error("Parameter \"%s\" in parameter.dat is not listed as proper input parameter." % parameter)
#}}}
#{{{ def: input_check_parameter_consistencies_from_list(self,file_path,parameter_list)
    def input_check_parameter_consistencies_from_list(self,file_path,parameter_list): # incomplete (not crucial)
        # this function checks wether there are inconsistencies in the input of the parameter.dat file
        # this will be a long file with if clauses; it will also set defaults to parameters that are not mandatory
        # first check if all mandatory parameter are set
        for parameter in mandatory_parameters:
            if not parameter in parameter_list:
                out.print_error("Parameter \"%s\" is mandatory, but not set in parameter.dat file." % parameter)
        # handle all pre-defined user defined parameters as mandatory; otherwise unexpected behavior could occur when commenting 
        # a parameter, which is actually set in the default file_parameter.dat
        for parameter in user_parameters[prc.process_name]: # these are the !pre-defined! user parameters
            if not parameter in parameter_list:
                out.print_error("Parameter \"%s\" is a mandatory user parameter, but not set in parameter.dat file." % parameter)
        # then set default values for all parameters that are not given
        for parameter in default_parameters:
            if not parameter in parameter_list:
                parameter_list[parameter] = default_parameters[parameter]
                if not parameter == "check_interval" and not parameter == "print_out_interval" and not parameter == "loop_induced" and not parameter == "approx_ckm_EW" and not parameter == "switch_qT_accuracy":
                    out.print_info("Parameter \"%s\" not set in parameter.dat file. Setting it to default value: %s." % (parameter,default_parameters[parameter]))
        # catch specific cases
        if parameter_list.get("switch_qT_accuracy") == "2" and not parameter_list.get("extrapolate_binwise") == "1":
                out.print_error("To set switch_qT_accuracy=2 you need to also use the binwise extrapolation extrapolate_binwise=1. Please reset inputs accordingly. Exiting...")
        if parameter_list.get("frixione_isolation") in ["1","2"]: # frixione isolation turned on 
            frixione_list = ["frixione_n","frixione_delta_0"] # required parameters for frixione isolation
            for parameter in frixione_list:
                if not parameter in parameter_list: # catch if these parameters are not given
                    out.print_error("\"frixione_isolation\" requires input of \"%s\". Please specify in parameter.dat file and restart." % parameter)            
        if parameter_list.get("frixione_isolation") == "1": # frixione isolation ATLAS setup
            if not "frixione_epsilon" in parameter_list:
                out.print_error("\"frixione_isolation\" set to \"1\" (ATLAS setup) requires input of \"frixione_epsilon\". Please specify in parameter.dat file and restart.")
            if "frixione_fixed_ET_max" in parameter_list:
                out.print_error("\"frixione_isolation\" set to \"1\" (ATLAS setup) does not allow for input of \"frixione_fixed_ET_max\". Please remove (comment) from parameter.dat file and restart.")
        elif parameter_list.get("frixione_isolation") == "2": # frixione isolation CMS setup
            if not "frixione_fixed_ET_max" in parameter_list:
                out.print_error("\"frixione_isolation\" set to \"2\" (CMS setup) requires input of \"frixione_fixed_ET_max\". Please specify in parameter.dat file and restart.")
            if "frixione_epsilon" in parameter_list:
                out.print_error("\"frixione_isolation\" set to \"2\" (CMS setup) does not allow for input of \"frixione_epsilon\". Please remove (comment) from parameter.dat file and restart.")
        if float(parameter_list.get("max_time_per_job")) < 1: # max_time_per_job become unreliable below 1h
            out.print_warning("Parameter max_time_per_job (set to %s hours) chosen below 1 hour. This is fine to tune the degree of parallelization, but does not constitute a realistic maximal run time of the jobs." % parameter_list["max_time_per_job"])
        if not parameter_list.get("flavor_scheme","not-set") in ["1","2","not-set"]:
            out.print_error("Parameter flavor_scheme in parameter.dat (set to %s) chosen different from \"1\" (four-flavor scheme) and \"2\" (five-flavor scheme). Please choose either of these two values and restart..." % parameter_list["flavor_scheme"])
        if prc.process_name in ["ppeexexne04","ppeeexnex04"]: # technical cut on pT of W's needed at O(as^2) in WW to avoid instabilities.
            if parameter_list.get("user_switch lepton_identification") in ["1","2"]:
                pass
            elif not parameter_list.get("user_switch lepton_identification") == "0":
                for switch in ["user_switch lepW_cuts","user_switch M_Z","user_switch delta_M_Z","user_switch R_lepZlepZ","user_switch R_lepZlepW","user_switch MT_W"]:
                    if parameter_list.get(switch) == "1":
                        out.print_error("Applying cut \"%s\" (set to \"1\"), but no lepton identifaction chosen in parameter.dat (\"user_switch lepton_identification = %s\"). Please set \"user_switch lepton_isolation\" either to \"1\" (ATLAS prescription) and \"2\" (CMS prescription) and restart..." % (switch,parameter_list["user_switch lepton_identifiaction"]))
            else:
                out.print_error("Parameter \"user_switch lepton_identification\" in parameter.dat (set to \"%s\") chosen different from \"0\" (off), \"1\" (ATLAS prescription) and \"2\" (CMS prescription). Please choose either of these three values and restart..." % parameter_list["user_switch lepton_identifiaction"])
        if parameter_list.get("add_NLL") == "1":
            if not parameter_list.get("NLO_subtraction_method") == "2":
                out.print_warning("Resummation at NLL turned on (add_NLL=1), but not QT subtraction scheme chosen at NLO (NLO_subtraction_method!=2). Setting NLO_subtraction_method=2 (QT subtraction) and continuing...")
                parameter_list["NLO_subtraction_method"] = "2"
            if not parameter_list.get("run_NLO_QCD") == "1":
                out.print_error("Resummation at NLL turned on (add_NLL=1), must be matched to NLO cross section, but NLO turned off (run_NLO_QCD=0). Adjust parameter.dat file accordingly, ie, set run_NLO_QCD=1. Exiting...") # cannot run NLL resummation without NLO fixed order part
            if not parameter_list.get("scale_variation") == "0":
                out.print_warning("Resummation at NLL turned on (add_NLL=1), cannot do automatic scale variation (scale_variation=%s). Setting scale_variation=0 (no scale variation) and continuing..." % parameter_list.get("scale_variation") )
                parameter_list["scale_variation"] = "0"
            if not parameter_list.get("dynamic_scale") == "0":
                out.print_warning("Resummation at NLL turned on (add_NLL=1), cannot use dynamical scales for muR and muF (dynamic_scale!=0). Setting dynamic_scale=1 (fixed scale as specified in parameter.dat: scale_ren=%s and scale_fact=%s) and continuing..." % (parameter_list.get("scale_ren"),parameter_list.get("scale_ren")) )
                parameter_list["dynamic_scale"] = "0"
        if parameter_list.get("add_NNLL") == "1":
            if not parameter_list.get("NLO_subtraction_method") == "2":
                out.print_warning("Resummation at NNLL turned on (add_NNLL=1), but not QT subtraction scheme chosen at NLO (NLO_subtraction_method!=2). Setting NLO_subtraction_method=2 (QT subtraction) and continuing...")
                parameter_list["NLO_subtraction_method"] = "2"
            if parameter_list.get("loop_induced") != "0":
                out.print_warning("Resummation at NNLL turned on (add_NNLL=1). Cannot include loop-induced contribution for resummation. Setting loop_induced=0 and continuing...")
                parameter_list["loop_induced"] = "0"
            if not parameter_list.get("run_NNLO_QCD") == "1":
                out.print_error("Resummation at NNLL turned on (add_NNLL=1), must be matched to NNLO cross section, but NNLO turned off (run_NNLO_QCD=0). Adjust parameter.dat file accordingly, ie, set run_NNLO_QCD=1. Exiting...") # cannot run NLL resummation without NLO fixed order part
            if not parameter_list.get("scale_variation") == "0":
                out.print_warning("Resummation at NNLL turned on (add_NNLL=1), cannot do automatic scale variation (scale_variation=%s). Setting scale_variation=0 (no scale variation) and continuing..." % parameter_list.get("scale_variation") )
                parameter_list["scale_variation"] = "0"
            if not parameter_list.get("dynamic_scale") == "0":
                out.print_warning("Resummation at NNLL turned on (add_NNLL=1), cannot use dynamical scales for muR and muF (dynamic_scale!=0). Setting dynamic_scale=1 (fixed scale as specified in parameter.dat: scale_ren=%s and scale_fact=%s) and continuing..." % (parameter_list.get("scale_ren"),parameter_list.get("scale_ren")) )
                parameter_list["dynamic_scale"] = "0"
        if parameter_list.get("run_NLO_EW") == "1" or parameter_list.get("add_NLO_EW") == "1":
            if parameter_list.get("frixione_isolation") in ["1","2"] and parameter_list.get("photon_recombination") == "1": # frixione isolation turned on 
                out.print_error("EW run turned on (run_NLO_EW=1 or add_NLO_EW=1); cannot do photon recombination and frixione frixione isolation at the same time. If you want to do an EW run please turn off frixione isolation. Exiting...")
        if parameter_list.get("add_NLO_EW") == "1" and not parameter_list.get("run_NNLO_QCD") == "1":
            out.print_error("If you want to add_NLO_EW at NNLO you also have to turn on run_NNLO_QCD. Exiting...")

        if parameter_list.get("add_NLO_EW") == "1" and int(parameter_list.get("loop_induced")) < 0:
            out.print_error("You have chosen to run NLO gg standalone (loop_induced<1) and to add NLO EW at NNLO (add_NLO_EW=1). You can only run them together by setting loop_induced>1 or set add_NLO_EW=0. Exiting...")

        if parameter_list.get("run_NNLO_QCD") == "1" and int(parameter_list.get("loop_induced")) > 1 and parameter_list.get("NLO_subtraction_method") == "2":
            out.print_error("If you want to compute NNLO QCD and NLO loop-induced gg contribution together, you must used Catani-Seymour as NLO subtraction method. Either switch to Catani-Seymour (NLO_subtraction_method=1) or disable NLO gg contribution (loop_induced<2), and restart the code. Exiting...")
        if prc.process_name in ckm_EW_processes and parameter_list.get("approx_ckm_EW") != "0" and parameter_list.get("approx_ckm_EW") != "1" and parameter_list.get("approx_ckm_EW") != "2":
            out.print_error("Switch approx_ckm_EW can only assume values 0 (for exact ckm), 1 (for trivial ckm of 1-loop EW correction) or 2 (for trivial ckm of entire EW correction). Please set approx_ckm_EW=0 or approx_ckm_EW=1 or approx_ckm_EW=2 and resart the run. Exiting...")
#}}}
#{{{ def: input_read_SLHA(self,file_path,SLHA_list)
    def input_read_SLHA(self,file_path,SLHA_list):
# function to read a file in the SLHA format, returning a dictionary with:
# BLOCK[number]: [value, commet]
        if not os.path.isfile(file_path):
            out.print_error("File "+file_path+" in function input_read_SLHA does not exist!")
        with open(file_path, 'r') as model_file:
            for in_line in model_file:
                line=in_line.strip() # strip removes all spaces (including tabs and newlines)
                # if any line starts with %, # or is an emtpy line (disregarding spaces) it is a comment line and should be skipped
                if line=="" or line[0]=="%" or line[0]=="#": 
                    continue
                # split line by spaces and remove otherspaces again from string
                # [0] gives you the number (before the first space)
                file_number=line.split()[0].strip() # 2do multiple spaces
                file_value=line.split()[1].strip()
                try:
                    file_comment=line.split('#')[1].strip()
                except: 
                    file_comment=""
                    pass
                if file_number.upper() == "DECAY":
                    Block=file_number
                    file_number=line.split()[1].strip()
                    file_value=line.split()[2].strip()
                    SLHA_list[Block][int(file_number)]=file_value
                    SLHA_list[Block+" comment"][int(file_number)]=file_comment
                    continue
 
                if file_number.upper() == "BLOCK":
                    Block=file_value
                elif file_number.upper() == "EW": 
                    ew_par = line.split()[1].strip() 
                    file_value=line.split()[2].strip()
                    SLHA_list["EW"][ew_par]= file_value #electroweak scheme
                else:
                    SLHA_list[Block][int(file_number)]=file_value
                    SLHA_list[Block+" comment"][int(file_number)]=file_comment
#}}}
#{{{ def: input_set_file_model_from_SLHA(self,file_path,SLHA_list)
    def input_set_file_model_from_SLHA(self,file_path,SLHA_list):
# function to set all model paramaters in MUNICH input ("file_model.dat") from SLHA_list 
# read from the MATRIX input file
        # do some concistency checks for Processes with CKM Matrix
        if ("CKM" in SLHA_list or "VCKMIN" in SLHA_list) and not prc.process_name in ckm_processes:
            out.print_error("CKM matrix not supported for process %s. Remove CKM and VCKMIN Blocks from model.dat file and restart. Exiting..." % prc.process_name)
        elif "CKM" in SLHA_list and "VCKMIN" in SLHA_list:
            out.print_error("Both blocks CKM (full CKM) and VCKMIN (Cabibbo) exist in model.dat file. Remove one of the two and restart. Exiting...")
        elif "CKM" in SLHA_list:
            self.input_set_entry(file_path,"CKM_matrix","individual")
        elif "VCKMIN" in SLHA_list:
            self.input_set_entry(file_path,"CKM_matrix","Cabibbo")
        elif prc.process_name in ckm_processes:
            self.input_set_entry(file_path,"CKM_matrix","individual")
            self.input_set_entry(file_path,"V_du","1")
            self.input_set_entry(file_path,"V_su","0")
            self.input_set_entry(file_path,"V_bu","0")
            self.input_set_entry(file_path,"V_dc","0")
            self.input_set_entry(file_path,"V_sc","1")
            self.input_set_entry(file_path,"V_bc","0")
            self.input_set_entry(file_path,"V_dt","0")
            self.input_set_entry(file_path,"V_st","0")
            self.input_set_entry(file_path,"V_bt","1")
        else:
            self.input_set_entry(file_path,"CKM_matrix","trivial")
        for Block in SLHA_list:
            try:
                split=Block.split()[1].strip()
                if not split=="comment":
                    out.print_error("Block in input_set_file_model_from_SLHA contains spaces.")
            except:
                for number in SLHA_list[Block]:              
                    parameter = model_mappings_to_MUNICH[Block][number]
                    value = SLHA_list[Block][number]
                    # add some sepecial case consistency checks
                    if parameter_list.get("flavor_scheme") == "1" and parameter == "M_b" and float(value) == 0.: # 4FS
                        out.print_warning("Bottom mass (block %s entry %s) in model.dat set to M_b=0, but four-flavor scheme (flavor_scheme=1) with massive bottom quarks chosen. Using default value for bottom mass (M_b=4.75 GeV)." %(Block,number))
                        value = 4.75
                    elif parameter_list.get("flavor_scheme") == "2" and parameter == "M_b" and float(value) != 0.: # 5FS
                        out.print_warning("Bottom mass (block %s entry %s) in model.dat set to M_b=%s GeV, but five-flavor scheme (flavor_scheme=1) with massless bottom quarks chosen. Using M_b=0 for bottom mass." %(Block,number,str(float(value))))
                        value = 0.
                    if Block != "EW":
                       self.input_set_entry(file_path,parameter,value)
            if Block == "EW": #electroweak scheme
                for i in SLHA_list[Block]:      
                    parameter = i
                    value =  SLHA_list[Block][i]
                    self.input_set_entry(file_path,parameter,value)
#}}}
#{{{ def: create_infile_result_file(self,file_path,runtime_table,phase)
    def create_infile_result_file(self,file_path,runtime_table,phase):
        file_name = os.path.basename(file_path).replace(".dat","")
        type_perturbative_order = file_name.split(".")[0]
        if "QT-CS" in file_name:
            subtraction_method = "QT-CS"
        elif "NJ-CS" in file_name:
            subtraction_method = "NJ-CS"
        elif "CS" in file_name:
            subtraction_method = "CS"
        elif "QT" in file_name:
            subtraction_method = "QT"
        elif "NJ" in file_name:
            subtraction_method = "NJ"
        else:
            subtraction_method = "---"
        photon_induced = 0
        channel_selection = "---"
        if parameter_list.get("power_corrections") == "1" and (subtraction_method == "QT" or subtraction_method == "QT-CS"):
            extra_selection = "withPC" # at least political correct !
        else:
            extra_selection = "---"
        contribution_order_alpha_s = file_name.rsplit(".",1)[1][0]
        contribution_order_alpha_e = file_name.rsplit(".",1)[1][1]
        if contribution_order_alpha_s == "a": # special treatment for photon induced
            photon_induced = 1
            contribution_order_alpha_s = file_name.rsplit(".",1)[1][1]
            contribution_order_alpha_e = file_name.rsplit(".",1)[1][2]
        try:
            types_here = self.type_dict[file_name]
        except:
            types_here = self.type_dict[subtraction_method]
        with open(file_path, 'w') as new_file:
            # set combination mode hybrid with average_factor=1
            new_file.write("processname                 =  %s\n" % prc.process_name)
            new_file.write("\n")
            new_file.write("resultdirectory             =  %s\n" % file_name)
            new_file.write("type_perturbative_order     =  %s\n" % type_perturbative_order)
            new_file.write("subtraction_method          =  %s\n" % subtraction_method)
            new_file.write("contribution_order_alpha_s  =  %s\n" % contribution_order_alpha_s)
            new_file.write("contribution_order_alpha_e  =  %s\n" % contribution_order_alpha_e)
            new_file.write("photon_induced              =  %s\n" % photon_induced)
            new_file.write("channel_selection           =  %s\n" % channel_selection)
            new_file.write("extra_selection             =  %s\n" % extra_selection)
            # new_file.write("photon_induced = 0\n" # hard-coded for now!
            for type_here in types_here:
                type_contribution = type_here[0]
                type_correction = type_here[1]
                interference = type_here[2]
                new_file.write("\n")
                new_file.write("type_contribution           =  %s\n" % type_contribution)
                new_file.write("type_correction             =  %s\n" % type_correction)
                new_file.write("interference                =  %s\n" % interference)
                directory = pjoin(type_perturbative_order+"%s"%("."+subtraction_method if subtraction_method != "---" else ""),"%s%s%s"%("a" if photon_induced == 1 else "",contribution_order_alpha_s,contribution_order_alpha_e),type_contribution+"%s"%("."+type_correction if type_correction != "---" else ""))
                run_dir_0 = pjoin(fold.run_folder_path,directory,"run.0")
                path = pjoin(fold.run_folder_path,directory)
                if not os.path.isdir(path): # if path does not exist
                    start_folder_index = 0
                    max_parallel_runs = 0
                elif phase == -1: # result combination for extrapolation
                    start_folder_index = 0
                    max_parallel_runs = run.get_parallel_pre_runs_for_contribution(run_dir_0)
                else: # final result combination
                    path = pjoin(fold.run_folder_path,directory)
                    if os.path.exists(path):
                        max_parallel_runs = fold.get_highest_integer_of_run_dirs_inside_path(path)
                        # determine wether to include the extrapolation runs or not
                        # default is to include them
                        start_folder_index = run.get_lowest_index_of_run_folder_to_include_inside_path(path,max_parallel_runs)
                    else:
                        max_parallel_runs = 0
                        start_folder_index = 0
                for i in range(start_folder_index,max_parallel_runs): # add all folders of the parallel runs
                    new_file.write("directory                   =  %s\n" % (pjoin(directory,"run.%s"%i)))
                # additional directories for tail enhancement
                if int(parameter_list.get("enhance_tails","0")) > 0:
                    directory = pjoin(type_perturbative_order+"%s"%("."+subtraction_method if subtraction_method != "---" else "")+".tau","%s%s%s"%("a" if photon_induced == 1 else "",contribution_order_alpha_s,contribution_order_alpha_e),type_contribution+"%s"%("."+type_correction if type_correction != "---" else ""))
                    run_dir_0 = pjoin(fold.run_folder_path,directory,"run.0")
                    if phase == -1: # result combination for extrapolation
                        start_folder_index = 0
                        max_parallel_runs = run.get_parallel_pre_runs_for_contribution(run_dir_0)
                    else: # final result combination
                        path = pjoin(fold.run_folder_path,directory)
                        if os.path.exists(path):
                            max_parallel_runs = fold.get_highest_integer_of_run_dirs_inside_path(path)
                            # determine wether to include the extrapolation runs or not
                            # default is to include them
                            start_folder_index = run.get_lowest_index_of_run_folder_to_include_inside_path(path,max_parallel_runs)
                        else:
                            max_parallel_runs = 0
                            start_folder_index = 0
                    for i in range(start_folder_index,max_parallel_runs): # add all folders of the parallel runs
                        new_file.write("directory tau               =  %s\n" % (pjoin(directory,"run.%s"%i)))
            new_file.write("\n")
#}}}
#{{{ def: create_infile_result_file(self,file_path,runtime_table,phase)
#     def create_infile_result_file(self,file_path,runtime_table,phase,coupling_order_QCD_LO,coupling_order_EW_LO):
#         file_name = os.path.basename(file_path).replace(".dat","")
#         type_perturbative_order = file_name.split(".")[0]
#         if "QT-CS" in file_name:
#             subtraction_method = "QT-CS"
#         elif "NJ-CS" in file_name:
#             subtraction_method = "NJ-CS"
#         elif "CS" in file_name:
#             subtraction_method = "CS"
#         elif "QT" in file_name:
#             subtraction_method = "QT"
#         elif "NJ" in file_name:
#             subtraction_method = "NJ"
#         else:
#             subtraction_method = "---"
#         contribution_order_alpha_s = file_name.rsplit(".",1)[1].lstrip("a")[0]
#         contribution_order_alpha_e = file_name.rsplit(".",1)[1].lstrip("a")[1]
#         if "aa" in file_name.rsplit(".",1)[1]:
#             photon_induced = 2
#             photon_string = "aa"
#         elif "a" in file_name.rsplit(".",1)[1]:
#             photon_induced = 1
#             photon_string = "a"
#         else:
#             photon_induced = 0
#             photon_string = ""
#         try:
#             types_here = self.type_dict[file_name]
#         except:
#             try:
#                 types_here = self.type_dict[subtraction_method]
#             except:
#                 if contribution_order_alpha_s > coupling_order_QCD_LO:
#                     types_here = self.type_dict["loop"]
#                 else:
#                     types_here = self.type_dict["born"]
#         with open(file_path, 'w') as new_file:
#             # set combination mode hybrid with average_factor=1
#             new_file.write("processname                 =  %s\n" % prc.process_name)
#             new_file.write("\n")
#             new_file.write("resultdirectory             =  %s\n" % file_name)
#             new_file.write("type_perturbative_order     =  %s\n" % type_perturbative_order)
#             new_file.write("subtraction_method          =  %s\n" % subtraction_method)
#             new_file.write("contribution_order_alpha_s  =  %s\n" % contribution_order_alpha_s)
#             new_file.write("contribution_order_alpha_e  =  %s\n" % contribution_order_alpha_e)
#             new_file.write("photon_induced              =  %s\n" % photon_induced)
#             # new_file.write("photon_induced = 0\n" # hard-coded for now!
#             for type_here in types_here:
#                 type_contribution = type_here[0]
#                 if photon_induced == 1 and type_contribution == "VA":
#                     continue
#                 type_correction = type_here[1]
#                 if type_correction == "QCDorQEW":
#                     if contribution_order_alpha_s > coupling_order_QCD_LO:
#                         type_correction = "QCD"
#                     elif contribution_order_alpha_e > coupling_order_EW_LO:
#                         type_correction = "QEW"
#                     else:
#                         out.print_error("Gettining a contribution which has non-LO QCD and EW coupling. Mixed QCD-EW not supported at the moment. So there must be something wrong. Exiting...")
#                 interference = type_here[2]
#                 new_file.write("\n")
#                 new_file.write("type_contribution           =  %s\n" % type_contribution)
#                 new_file.write("type_correction             =  %s\n" % type_correction)
#                 new_file.write("interference                =  %s\n" % interference)
#                 directory = pjoin(type_perturbative_order+"%s"%("."+subtraction_method if subtraction_method != "---" else ""),photon_string+"%s%s"%(contribution_order_alpha_s,contribution_order_alpha_e),type_contribution+"%s"%("."+type_correction if type_correction != "---" else ""))
#                 run_dir_0 = pjoin(fold.run_folder_path,directory,"run.0")
#                 path = pjoin(fold.run_folder_path,directory)
#                 if not os.path.isdir(path): # if path does not exist
#                     start_folder_index = 0
#                     max_parallel_runs = 0
#                 elif phase == -1: # result combination for extrapolation
#                     start_folder_index = 0
#                     max_parallel_runs = run.get_parallel_pre_runs_for_contribution(run_dir_0)
#                 else: # final result combination
#                     path = pjoin(fold.run_folder_path,directory)
#                     if os.path.exists(path):
#                         max_parallel_runs = fold.get_highest_integer_of_run_dirs_inside_path(path)
#                         # determine wether to include the extrapolation runs or not
#                         # default is to include them
#                         start_folder_index = run.get_lowest_index_of_run_folder_to_include_inside_path(path,max_parallel_runs)
#                     else:
#                         max_parallels_runs = 0
#                         start_folder_index = 0
#                 for i in range(start_folder_index,max_parallel_runs): # add all folders of the parallel runs
#                     new_file.write("directory                   =  %s\n" % (pjoin(directory,"run.%s"%i)))
#                 # additional directories for tail enhancement
#                 if int(parameter_list.get("enhance_tails","0")) > 0:
#                     directory = pjoin(type_perturbative_order+"%s"%("."+subtraction_method if subtraction_method != "---" else "")+".tau","%s%s%s"%("a" if photon_induced == 1 else "",contribution_order_alpha_s,contribution_order_alpha_e),type_contribution+"%s"%("."+type_correction if type_correction != "---" else ""))
#                     run_dir_0 = pjoin(fold.run_folder_path,directory,"run.0")
#                     if phase == -1: # result combination for extrapolation
#                         start_folder_index = 0
#                         max_parallel_runs = run.get_parallel_pre_runs_for_contribution(run_dir_0)
#                     else: # final result combination
#                         path = pjoin(fold.run_folder_path,directory)
#                         if os.path.exists(path):
#                             max_parallel_runs = fold.get_highest_integer_of_run_dirs_inside_path(path)
#                             # determine wether to include the extrapolation runs or not
#                             # default is to include them
#                             start_folder_index = run.get_lowest_index_of_run_folder_to_include_inside_path(path,max_parallel_runs)
#                         else:
#                             max_parallels_runs = 0
#                             start_folder_index = 0
#                     for i in range(start_folder_index,max_parallel_runs): # add all folders of the parallel runs
#                         new_file.write("directory tau               =  %s\n" % (pjoin(directory,"run.%s"%i)))
#             new_file.write("\n")
#}}}
#{{{ def: create_infile_scaleband_file(self)
    def create_infile_scaleband_file(self,file_path):
        dummy_dict = {}
        dummy_dict["scale_setting"] = self.scale_setting
        with open(file_path, 'w') as new_file:
            none = """outpath = %(scale_setting)s

inpath_scalecentral = %(scale_setting)s/scale.1.1

inpath_scalevariation = %(scale_setting)s/scale.1.1
""" % dummy_dict
            
            sevenpoint = """outpath = %(scale_setting)s

inpath_scalecentral = %(scale_setting)s/scale.1.1

inpath_scalevariation = %(scale_setting)s/scale.0.0
inpath_scalevariation = %(scale_setting)s/scale.0.1
inpath_scalevariation = %(scale_setting)s/scale.1.0
inpath_scalevariation = %(scale_setting)s/scale.1.1
inpath_scalevariation = %(scale_setting)s/scale.1.2
inpath_scalevariation = %(scale_setting)s/scale.2.1
inpath_scalevariation = %(scale_setting)s/scale.2.2
""" % dummy_dict
            
            ninepoint = """outpath = %(scale_setting)s

inpath_scalecentral = %(scale_setting)s/scale.1.1

inpath_scalevariation = %(scale_setting)s/scale.0.0
inpath_scalevariation = %(scale_setting)s/scale.0.1
inpath_scalevariation = %(scale_setting)s/scale.1.0
inpath_scalevariation = %(scale_setting)s/scale.1.1
inpath_scalevariation = %(scale_setting)s/scale.1.2
inpath_scalevariation = %(scale_setting)s/scale.2.1
inpath_scalevariation = %(scale_setting)s/scale.2.2
inpath_scalevariation = %(scale_setting)s/scale.2.0
inpath_scalevariation = %(scale_setting)s/scale.0.2
""" % dummy_dict
            if parameter_list.get("scale_variation") == "0":
                new_file.write(none)
            elif parameter_list.get("scale_variation") == "1":
                new_file.write(sevenpoint)
            elif parameter_list.get("scale_variation") == "2":
                new_file.write(ninepoint)
            else:
                out.print_error("Invalid setting of scale_variation in parameter.dat file. Exiting...")
#}}}
#{{{ def: create_string_file_parameter_contribution(self,path,order,contribution,coupling)
    def create_string_file_parameter_contribution(self,path,order,contribution,coupling):
### contribution-specific settings
        specific_settings_string = ""
# inputs for power corrections
        if "PT" in contribution:
            specific_settings_string = """
user_switch recoil                      =       1
no_qTcut_reference_TSV                  =       %s
switch_decay_pTthreshold                =       1
exp_decay_pTthreshold_cth               =       4.
decay_pTthreshold_cth                   =       %s
""" % (int(parameter_list["n_qTcut"])-1, parameter_list["power_corrections_pT0"])  # FOR NOW HARD CODED !!!
        setting_dict = {}
        try:
            setting_dict["order"] = order.split(".")[0]
        except:
            setting_dict["order"] = order
        setting_dict["contribution"] = contribution.split(".")[0]
        setting_dict["correction"] = contribution.split(".")[1]
        setting_dict["order_alpha_s"] = coupling[0]
        setting_dict["order_alpha_e"] = coupling[1]
        setting_dict["grid"] = pjoin(order,coupling,contribution,"grid")
        out_string = """type_perturbative_order                 =       %(order)s
type_contribution                       =       %(contribution)s
type_correction                         =       %(correction)s
contribution_order_alpha_s              =       %(order_alpha_s)s
contribution_order_alpha_e              =       %(order_alpha_e)s
contribution_order_interference         =       0
MCweight_in_directory                   =       %(grid)s
pdf_disable                             =       a
output_level                            =       INFO
""" % setting_dict
        out_string += specific_settings_string
        
        return out_string
#}}}
#{{{ def: input_read_distribution_dat(self,file_path,content)
    def input_read_distribution_dat(self,file_path):
# this function reads in the whole file and returns it
        with open(file_path, "r") as f:
            content = f.read()
        return content
#}}}
#{{{ def: input_set_file_distribution_dat(self,file_path,content)
    def input_set_file_distribution_dat(self,file_path,content):
# this function appends content to the file file_path
        with open(file_path, "a") as f:
            f.write(content)
#}}}
#{{{ def: write_infile_result_MATRIX(self,file_path,order_in,paramter_list,NLO_subtraction,coupling_order_LO,coupling_order_NLO,coupling_order_NLO_EW,coupling_order_NNLO,loop_induced,cross_section)
    def write_infile_result_MATRIX(self,file_path,order_in,paramter_list,NLO_subtraction,coupling_order_LO,coupling_order_NLO,coupling_order_NLO_EW,coupling_order_NNLO,coupling_order_NNNLO,loop_induced,cross_section):
# function to write the infile for the result/distribution collection
        with open(file_path, 'w') as new_file:
            # set combination mode hybrid with average_factor=4
            
            if int(parameter_list.get("enhance_tails","0")) > 0:
                new_file.write("phasespace_optimization = tau3  # include tail enhancement runs in runtime.dat\n")
#                new_file.write("phasespace_optimization = offshellZ  # use specific tail enhancement optimization\n")
            new_file.write("\n")
            new_file.write("average_factor = 1  # number of samples for the hybrid combination\n")
            new_file.write("deviation_tolerance_factor = 50  # tollerance how much bigger the uncertainty of a part in the combination can be\n")
            new_file.write("\n")
            # determine minimum value for extrapolation range and error
            if cross_section:
                min_qTcut = parameter_list["min_qTcut"] 
                max_min_qTcut = parameter_list["max_min_qTcut"]
                max_qTcut = 1
                min_interval = 0.1
                if "a" in prc.process_name or (prc.process_name == "ppeex02" and not parameter_list.get("power_corrections") == "1"): # use smaller range for photon processes
                    min_max_qTcut = 0.25
                    min_n_qTcut = 10
                else:
                    min_max_qTcut = 0.5
                    min_n_qTcut = 30
            else:
                min_qTcut = parameter_list["min_qTcut"] 
                max_min_qTcut = parameter_list["max_min_qTcut"]
                max_qTcut = 1
                min_interval = parameter_list["min_interval"]
                min_max_qTcut = parameter_list["min_max_qTcut"]
                min_n_qTcut = parameter_list["min_n_qTcut"]
                
            new_file.write("min_qTcut_extrapolation = %s  # lowest value used for extrapolation (if lowest produced value is higher, that one is used)\n" % min_qTcut)
            new_file.write("max_min_qTcut_extrapolation = %s  # excludes lower qTcut values up to this values\n" % max_min_qTcut)
            new_file.write("max_qTcut_extrapolation = %s  # maximal value used for extrapolation (if highest produced value is lower, that one is used)\n" % max_qTcut)
            new_file.write("min_value_extrapolation_range = %s  # minimal interval used for extrapolation\n" % min_interval)
            new_file.write("error_extrapolation_range_chi2 = 4.  # biggest chi deviation\n")
            new_file.write("min_max_value_extrapolation_range = %s  # minimal value of the upper bound of the interval used for extrapolation\n" % min_max_qTcut)
            new_file.write("min_n_qTcut_extrapolation_range = %s  # minimal number of values used for extrapolation\n" % min_n_qTcut)
            new_file.write("\n")
            new_file.write("switch_output_subprocess = 0  # switch on(1)/off(0) output for each partonic subprocess in each contribution\n")
            new_file.write("switch_output_contribution = 1  # switch on(1)/off(0) output for each contribution (born, VA.QCD, CA.QCD, etc.)\n")
            new_file.write("switch_output_list = 1  # switch on(1)/off(0) output for each list (each contribution_file specified below)\n")
            new_file.write("switch_output_order = 1  # switch on(1)/off(0) output for each order (each resultdirectory specified below) -> required for MATRIX output\n")
            if self.result_method == "TSV":
                new_file.write("\n")
                new_file.write("switch_output_plot = 1  # output level for plot.* format (0: off, 1: order, 2: contribution, 3: list, 4: subprocess) -> (>=1) required for MATRIX output\n")
                new_file.write("switch_output_result = 0  # output level for result.* format (0: off, 1: order, 2: contribution, 3: list, 4: subprocess)\n")
                new_file.write("switch_output_qTcut = 3  # output level for fixed rcut values in qTcut.*/plot.* format (0: off, 1: order, 2: contribution, 3: list, 4: subprocess)\n")
            else:
                new_file.write("switch_output_plot = 4  # output option for plot.* results\n")
                new_file.write("switch_output_result = 0  # output option for result.* results\n")
            new_file.write("switch_output_overview = 3  # output level for overview.* format (0: off, 1: order, 2: contribution, 3: list)\n")
            new_file.write("\n")
            new_file.write("switch_output_complete = 1  # output for all calculated scale combinations\n")
            new_file.write("switch_output_ren = 0  # output for renormalisation scale variation (factorisation scale fixed)\n")
            new_file.write("switch_output_fact = 0  # output for factorisation scale variation (renormalisation scale fixed)\n")
            new_file.write("switch_output_equal = 0  # output for 3-point variation with muR=muF\n")
            new_file.write("switch_output_antipodal = 0  # output for antipodal variation of muR and muF (muR=xi*mu, muF=mu/xi)\n")
            new_file.write("switch_output_7point = 0  # output for standard 7-point variation (9-point variation excluding the antipodal variation)\n")
            new_file.write("switch_output_9point = 0  # output for standard 9-point variation\n")
            new_file.write("\n")
            new_file.write("output_selection_distribution_format = 1dd.plot  # selects output format for 1D distributions\n")
            new_file.write("output_selection_distribution_format = 2dd.plot  # selects output format for 2D distributions\n")
            new_file.write("\n")
            if not "LO" in order_in and not "NLO" in order_in and not "NNLO" in order_in:
                out.print_error("Unknown order=%s specified in write_infile_result. Exiting..." % order_in)
            result_folder = "result.."+os.path.basename(file_path).lstrip("infile.").replace(".dat","")
            new_file.write("final_resultdirectory = %s\n" % result_folder)
            new_file.write("\n")

            if int(parameter_list["switch_PineAPPL"]) == 1:
                new_file.write("path_input_script = %s\n" % fold.input_folder_path)
#                fold.input_folder_path  = pjoin(process_dir,"input",run_folder)
                new_file.write("\n")

            if "LO" in order_in:
                if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                    new_file.write("resultdirectory = LO-LOa__LORUN\n")
                else:
                    new_file.write("resultdirectory = LO__LORUN\n")
                new_file.write("contribution_file = infile.result/LO."+coupling_order_LO+".dat\n")
                if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                    new_file.write("\n")
                    new_file.write("resultdirectory = LOa__LORUN\n")
                    new_file.write("contribution_file = infile.result/LO.a"+coupling_order_LO+".dat\n")
                    new_file.write("accuracy_relative = 0.01\n")
                    new_file.write("\n")
                    new_file.write("resultdirectory = LO__LORUN\n")
                    new_file.write("contribution_file = infile.result/LO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/LO.a"+coupling_order_LO+".dat\n")
                # create qq alone contibutions only if loop-induced is there (otherwise just repition from LO)
                if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes: 
                    new_file.write("\n")
                    new_file.write("resultdirectory = LOqq__LORUN\n")
                    new_file.write("contribution_file = infile.result/LO."+coupling_order_LO+".dat\n")
                    new_file.write("\n")
            if "NLO" in order_in:
                new_file.write("\n")
                if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                    new_file.write("resultdirectory = LO-LOa__NLORUN\n")
                else:
                    new_file.write("resultdirectory = LO__NLORUN\n")
                new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                    new_file.write("\n")
                    
                    new_file.write("resultdirectory = LOa__NLORUN\n")
                    new_file.write("contribution_file = infile.result/NLO.a"+coupling_order_LO+".dat\n")
                    new_file.write("accuracy_relative = 0.01\n")
                    new_file.write("\n")
                    
                    new_file.write("resultdirectory = LO__NLORUN\n")
                    new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NLO.a"+coupling_order_LO+".dat\n")
                    new_file.write("\n")
                        
                if parameter_list.get("run_NLO_QCD","0") == "1":
                    # if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                    #     new_file.write("resultdirectory = NLO.QCD-a__NLORUN\n")
                    #     new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                    #     new_file.write("contribution_file = infile.result/NLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    #     new_file.write("\n")
                    
                    new_file.write("resultdirectory = NLO.QCD__NLORUN\n")
                    new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                    if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                        new_file.write("contribution_file = infile.result/NLO.a"+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("\n")
                if parameter_list.get("run_NLO_EW","0") == "1":
                    if parameter_list.get("photon_induced","0") == "1":
                        new_file.write("resultdirectory = NLOqq.EW__NLORUN\n")
                    else:
                        new_file.write("resultdirectory = NLO.EW__NLORUN\n")
                    new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NLO.CS."+coupling_order_NLO_EW+".dat\n")
                    new_file.write("\n")
                    if parameter_list.get("photon_induced","0") == "1":
                        if prc.process_name in LO_photon_induced_processes:
                            new_file.write("resultdirectory = NLOa__NLORUN\n")
                            new_file.write("contribution_file = infile.result/NLO.a"+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("accuracy_relative = 0.1\n")
                            new_file.write("\n")
                            
                            new_file.write("resultdirectory = NLO.EW__NLORUN\n")
                            new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NLO.a"+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NLO.CS."+coupling_order_NLO_EW+".dat\n")
                            new_file.write("contribution_file = infile.result/NLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("\n")
                        else:
                            new_file.write("resultdirectory = NLO.EW__NLORUN\n")
                            new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NLO.CS."+coupling_order_NLO_EW+".dat\n")
                            new_file.write("contribution_file = infile.result/NLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("\n")

                            new_file.write("resultdirectory = NLOa__NLORUN\n")
                            new_file.write("contribution_file = infile.result/NLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("accuracy_relative = 100000000\n")
                            new_file.write("\n")
                if parameter_list.get("run_NLO_QCD","0") == "1" and parameter_list.get("run_NLO_EW","0") == "1":
                    new_file.write("resultdirectory = NLO.QCD+NLO.EW__NLORUN\n")
                    new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("contribution_file = infile.result/NLO.CS."+coupling_order_NLO_EW+".dat\n")
                    if parameter_list.get("photon_induced","0") == "1":
                        if prc.process_name in LO_photon_induced_processes:
                            new_file.write("contribution_file = infile.result/NLO.a"+coupling_order_LO+".dat\n")
                        new_file.write("contribution_file = infile.result/NLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                    new_file.write("\n")
                    
                    new_file.write("resultdirectory = NLO.QCDxNLO.EW__NLORUN\n")
                    new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                    if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                        new_file.write("contribution_file = infile.result/NLO.a"+coupling_order_LO+".dat\n")
                    new_file.write("combination       = x\n")
                    new_file.write("contribution_file = infile.result/NLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("combination       = x\n")
                    new_file.write("contribution_file = infile.result/NLO.CS."+coupling_order_NLO_EW+".dat\n")                    
                    if parameter_list.get("photon_induced","0") == "1":
                        new_file.write("contribution_file = infile.result/NLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                    new_file.write("\n")
                    
                    if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                        new_file.write("resultdirectory = NLO.QCDxNLOqq.EW+NLOa__NLORUN\n")
                        new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                        new_file.write("combination       = x\n")
                        new_file.write("contribution_file = infile.result/NLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                        new_file.write("combination       = x\n")
                        new_file.write("contribution_file = infile.result/NLO.CS."+coupling_order_NLO_EW+".dat\n")               
                        new_file.write("combination       = +\n")
                        new_file.write("contribution_file = infile.result/NLO.a"+coupling_order_LO+".dat\n")
                        new_file.write("contribution_file = infile.result/NLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                        new_file.write("\n")

                # # NLO + loop-induced
                # if int(parameter_list["loop_induced"]) > 0:
                #     new_file.write("resultdirectory = NLOqq.QCD+LOgg__NLORUN\n")
                #     new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                #     new_file.write("contribution_file = infile.result/NLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                #     new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                #     new_file.write("\n")

                # create qq alone contibutions only if loop-induced is there (otherwise just repition from LO, NLO etc)
                if parameter_list.get("photon_induced","0") == "1" and (prc.process_name in LO_photon_induced_processes or parameter_list.get("run_NLO_EW","0") == "1"):
                    new_file.write("resultdirectory = LOqq__NLORUN\n")
                    new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                    new_file.write("\n")
                    if parameter_list.get("run_NLO_QCD","0") == "1":
                        new_file.write("resultdirectory = NLOqq.QCD__NLORUN\n")
                        new_file.write("contribution_file = infile.result/NLO."+coupling_order_LO+".dat\n")
                        new_file.write("contribution_file = infile.result/NLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                        new_file.write("\n")
                
            if "NNLO" in order_in:
              if int(parameter_list["loop_induced"]) >= 0:
                new_file.write("\n")
                if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                    new_file.write("resultdirectory = LO-LOa__NNLORUN\n")
                else:
                    new_file.write("resultdirectory = LO__NNLORUN\n")
                new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                new_file.write("\n")
                
                if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                    new_file.write("resultdirectory = LOa__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                    new_file.write("accuracy_relative = 0.01\n")
                    new_file.write("\n")
                    
                    new_file.write("resultdirectory = LO__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                    new_file.write("\n")
                    
                # if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                #     new_file.write("resultdirectory = NLO.QCD-a__NNLORUN\n")
                #     new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                #     new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                #     new_file.write("\n")
                        
                new_file.write("resultdirectory = NLO.QCD__NNLORUN\n")
                new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                    new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                new_file.write("\n")
                
                if parameter_list.get("add_NLO_EW","0") == "1":
                    if parameter_list.get("photon_induced","0") == "1":
                        new_file.write("resultdirectory = NLOqq.EW__NNLORUN\n")                        
                    else:
                        new_file.write("resultdirectory = NLO.EW__NNLORUN\n")                        
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")
                    new_file.write("\n")

                    if parameter_list.get("photon_induced","0") == "1":
                        if prc.process_name in LO_photon_induced_processes:
                            new_file.write("resultdirectory = NLOa__NNLORUN\n")
                            new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("accuracy_relative = 0.1\n")
                            new_file.write("\n")

                            new_file.write("resultdirectory = NLO.EW__NNLORUN\n")
                            new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("\n")
                        else:
                            new_file.write("resultdirectory = NLO.EW__NNLORUN\n")
                            new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("\n")

                            new_file.write("resultdirectory = NLOa__NNLORUN\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("accuracy_relative = 100000000\n")
                            new_file.write("\n")

                    new_file.write("resultdirectory = NLO.QCD+NLO.EW__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")
                    if parameter_list.get("photon_induced","0") == "1":
                        if prc.process_name in LO_photon_induced_processes:
                            new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                        new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                    new_file.write("\n")

                    new_file.write("resultdirectory = NLO.QCDxNLO.EW__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                        new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                    new_file.write("combination       = x\n")
                    new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("combination       = x\n")
                    new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")                    
                    if parameter_list.get("photon_induced","0") == "1":
                        new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                    new_file.write("\n")
                            
                    if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                        new_file.write("resultdirectory = NLO.QCDxNLOqq.EW+NLOa__NNLORUN\n")
                        new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                        new_file.write("combination       = x\n")
                        new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                        new_file.write("combination       = x\n")
                        new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")               
                        new_file.write("combination       = +\n")
                        new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                        new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                        new_file.write("\n")

                # NNLO QCD always created
                new_file.write("resultdirectory = NNLO.QCD__NNLORUN\n")
                new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                    new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                if abs(int(parameter_list["loop_induced"])) > 0:
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                new_file.write("\n")

                # if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                #     if int(parameter_list["loop_induced"]) > 1:
                #         new_file.write("resultdirectory = nNNLO.QCD-a__NNLORUN\n")
                #     else:
                #         new_file.write("resultdirectory = NNLO.QCD-a__NNLORUN\n")
                #     new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                #     new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                #     new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                #     if int(parameter_list["loop_induced"]) > 0:
                #         new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                #     if int(parameter_list["loop_induced"]) > 1:
                #          new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")
                #     new_file.write("\n")

                if parameter_list.get("add_NLO_EW","0") == "1":
                    if int(parameter_list["loop_induced"]) > 1:
                        new_file.write("resultdirectory = nNNLO.QCD+NLO.EW__NNLORUN\n")
                    else:
                        new_file.write("resultdirectory = NNLO.QCD+NLO.EW__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")
                    if parameter_list.get("photon_induced","0") == "1":
                        if prc.process_name in LO_photon_induced_processes:
                            new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                        new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                    if int(parameter_list["loop_induced"]) > 0:
                        new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                    if int(parameter_list["loop_induced"]) > 1:
                        new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")
                    new_file.write("\n")
                    
                    if int(parameter_list["loop_induced"]) > 1:
                        new_file.write("resultdirectory = nNNLO.QCDxNLO.EW__NNLORUN\n")
                    else:
                        new_file.write("resultdirectory = NNLO.QCDxNLO.EW__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                        new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                    new_file.write("combination       = x\n")
                    new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                    if int(parameter_list["loop_induced"]) > 0:
                        new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                    if int(parameter_list["loop_induced"]) > 1:
                        new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")
                    new_file.write("combination       = x\n")
                    new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")                    
                    if parameter_list.get("photon_induced","0") == "1":
                        new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                    new_file.write("\n")

                    if int(parameter_list["loop_induced"]) > 0:
                        if int(parameter_list["loop_induced"]) > 1:
                            new_file.write("resultdirectory = NNLOqq.QCDxNLO.EW+NLOgg__NNLORUN\n")
                        else:
                            new_file.write("resultdirectory = NNLOqq.QCDxNLO.EW+LOgg__NNLORUN\n")
                        new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                        if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                            new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                        new_file.write("combination       = x\n")
                        new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                        new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                        new_file.write("combination       = x\n")
                        new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")                    
                        if parameter_list.get("photon_induced","0") == "1":
                            new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                        if int(parameter_list["loop_induced"]) > 0:
                            new_file.write("combination       = +\n")
                            new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                        if int(parameter_list["loop_induced"]) > 1:
                            new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")
                        new_file.write("\n")
                        
                        if int(parameter_list["loop_induced"]) > 1:
                            new_file.write("resultdirectory = NLO.QCDxNLO.EW+nNNLO.QCD__NNLORUN\n")
                        else:
                            new_file.write("resultdirectory = NLO.QCDxNLO.EW+NNLO.QCD__NNLORUN\n")
                        new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                        if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                            new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                        new_file.write("combination       = x\n")
                        new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                        new_file.write("combination       = x\n")
                        new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")                    
                        if parameter_list.get("photon_induced","0") == "1":
                            new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                        new_file.write("combination       = +\n")
                        new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                        if int(parameter_list["loop_induced"]) > 0:
                            new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                        if int(parameter_list["loop_induced"]) > 1:
                            new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")
                        new_file.write("\n")

                    if parameter_list.get("photon_induced","0") == "1":
                        if int(parameter_list["loop_induced"]) > 1:
                            new_file.write("resultdirectory = nNNLO.QCD+NLOqq.EW+NLOa__NNLORUN\n")
                        else:
                            new_file.write("resultdirectory = NNLO.QCD+NLOqq.EW+NLOa__NNLORUN\n")
                        new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                        new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                        new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                        new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")
                        if int(parameter_list["loop_induced"]) > 0:
                            new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                        if int(parameter_list["loop_induced"]) > 1:
                            new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")
                        new_file.write("combination       = +\n")
                        if prc.process_name in LO_photon_induced_processes:
                            new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                        new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                        new_file.write("\n")

                        
                        if int(parameter_list["loop_induced"]) > 0:
                            if int(parameter_list["loop_induced"]) > 1:
                                new_file.write("resultdirectory = NNLOqq.QCDxNLOqq.EW+NLOa+NLOgg__NNLORUN\n")
                            else:
                                new_file.write("resultdirectory = NNLOqq.QCDxNLOqq.EW+NLOa+LOgg__NNLORUN\n")
                            new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                            new_file.write("combination       = x\n")
                            new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                            new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                            new_file.write("combination       = x\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")                    
                            new_file.write("combination       = +\n")
                            new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                            if int(parameter_list["loop_induced"]) > 1:
                                new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")
                            if prc.process_name in LO_photon_induced_processes:
                                new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("\n")

                            if int(parameter_list["loop_induced"]) > 1:
                                new_file.write("resultdirectory = NLO.QCDxNLOqq.EW+NLOa+nNNLO.QCD__NNLORUN\n")
                            else:
                                new_file.write("resultdirectory = NLO.QCDxNLOqq.EW+NLOa+NNLO.QCD__NNLORUN\n")
                            new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                            if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                                new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                            new_file.write("combination       = x\n")
                            new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                            new_file.write("combination       = x\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS."+coupling_order_NLO_EW+".dat\n")                    
                            new_file.write("combination       = +\n")
                            new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                            if int(parameter_list["loop_induced"]) > 0:
                                new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                            if int(parameter_list["loop_induced"]) > 1:
                                new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")
                            if prc.process_name in LO_photon_induced_processes:
                                new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                            new_file.write("contribution_file = infile.result/NNLO.CS.a"+coupling_order_NLO_EW+".dat\n")
                            new_file.write("\n")

                # NLO' + loop-induced
                # if int(parameter_list["loop_induced"]) > 0:
                #     new_file.write("resultdirectory = NLOqq.QCD.prime+LOgg__NNLORUN\n")
                #     new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                #     new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                #     new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                #     new_file.write("\n")

                # create qq alone contibutions only if loop-induced or add_EW is there (otherwise just repition from LO, NLO, NNLO etc)
                if int(parameter_list["loop_induced"]) > 0 or (parameter_list.get("photon_induced","0") == "1" and (prc.process_name in LO_photon_induced_processes or parameter_list.get("add_NLO_EW","0") == "1")):
                    new_file.write("resultdirectory = LOqq__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    new_file.write("\n")
                
                    new_file.write("resultdirectory = NLOqq.QCD__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("\n")
                
                    new_file.write("resultdirectory = NNLOqq.QCD__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                    new_file.write("\n")

                if (int(parameter_list["loop_induced"]) == 2):
                    new_file.write("resultdirectory = nNNLO.QCD__NNLORUN\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_LO+".dat\n")
                    if prc.process_name in LO_photon_induced_processes:
                        new_file.write("contribution_file = infile.result/NNLO.a"+coupling_order_LO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO."+NLO_subtraction+"."+coupling_order_NLO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO.QT-CS."+coupling_order_NNLO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                    new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")
                    new_file.write("\n")
              if abs(int(parameter_list["loop_induced"])) > 0:
                  new_file.write("resultdirectory = loopLOgg.QCD__NNLORUN\n")
                  new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                  new_file.write("\n")
              if abs(int(parameter_list["loop_induced"])) > 1:
                  new_file.write("resultdirectory = loopNLOgg.QCD__NNLORUN\n")
                  new_file.write("contribution_file = infile.result/NNLO."+coupling_order_NNLO+".dat\n")
                  new_file.write("contribution_file = infile.result/NNNLO."+NLO_subtraction+"."+coupling_order_NNNLO+".dat\n")                
                  if int(parameter_list["loop_induced"]) > 1:
                      new_file.write("accuracy_relative = 0.01\n")
                  new_file.write("\n")
#}}}
#}}}
#{{{ class: Dummyopen(object)
class Dummyopen(object):
# dummy class to be called def: write(self, data) to do nothing
    def write(self, data):
        pass # ignore the data
    def __enter__(self): return self
    def __exit__(*x): pass
#}}}
#{{{ def: line_prepender(filename, line)
def line_prepender(filename, line):
    # adds line at beginning of file
    with open(filename, 'r+') as f:
        content = f.read()
        f.seek(0, 0)
        f.write(line.rstrip('\r\n') + '\n' + content)
#}}}
#{{{ def: get_nr_of_lines(filename)
def get_nr_of_lines(filename):
# returns the number of lines of a file (filename)
    """ Return number of lines of a file
    """  
    nr_of_lines = 0
    with open(filename) as f:
        for nr_of_lines, l in enumerate(f):
            pass
    return nr_of_lines + 1
#}}}
#{{{ class: run_class()
class run_class(): # class to run C++ executable of MUNICH in different modes (multicore, cluster)
#{{{ def: __init__(self,mode,grid_folder,main_run_folder,NLO_subtraction,order,set_parallel_runs,grid_assignment,include_loop_induced,config_list)
    def __init__(self,mode,grid_folder,main_run_folder,NLO_subtraction,order,set_parallel_runs,grid_assignment,include_loop_induced,config_list):
        if not run_mode in ["run_results","run_gnuplot"]:
            out.print_info("Now it's time for running...")
            out.print_info("Running in %s mode..." % mode)
        self.errors_flag = False
        self.grid_dirs = []
        self.loop_grid_dirs = []
        self.phase = 0
        # get grids to be run for warmup (separated in normal process folders and loop-induced ones)
        # these are class variables for later usage
        self.grid_dirs, self.loop_grid_dirs = self.get_dirs("grid",NLO_subtraction,order)
        # get run dirs for the main run (separated in normal process folders and loop-induced ones)
        self.run_dirs, self.loop_run_dirs = self.get_dirs(main_run_folder,NLO_subtraction,order)
        # for all run_dirs creaete automatically contribution folder if it doesn't exist; requires channel_assignment for contribution
        for path in self.run_dirs:
            channel_assigned = False
            contribution_path = os.path.dirname(path)
            if not os.path.exists(contribution_path):
                contribution = self.get_contribution(path)
                if not contribution in ["PT.QCD","PT2.QCD"]:
                    out.print_warning("Path to contribution: %s doesn't exist. Trying to create it." % contribution_path)
                for dir_path in self.run_dirs:
                    if channel_assignment[contribution] == self.get_contribution(dir_path):
                        contribution_channel = self.get_dir_channels([dir_path])[dir_path]
                        channel_assigned = True
                        break
                if channel_assigned:
                    this_order,subtraction,coupling,contribution,run_dir = self.get_properties(path)
                    string_file_parameter = inp.create_string_file_parameter_contribution(path,this_order,contribution,coupling)
                    fold.create_contribution_folder(contribution_path,prc.process_name,string_file_parameter,contribution_channel)
                else:
                    out.print_error("Trying to create contribution folder %s, but could not find any channel_assignment to create subprocesses.dat file. Exiting..." % contribution_path)
        # get the channels associated to dirs
        self.channels = self.get_dir_channels(self.grid_dirs) # these are class variables for later usage
        self.loop_channels = self.get_dir_channels(self.loop_grid_dirs) # these are class variables for later usage
        self.run_channels = self.get_dir_channels(self.run_dirs) # these are class variables for later usage
        if not self.grid_dirs and not self.loop_grid_dirs and run_mode in ["run","run_grid_and_pre","run_grid", "run_pre", "run_main", "run_pre_and_main","run_without_pre","run_main_without_pre"]:
# should be improved to make sure that *all* required grid folders have been found
            out.print_error("No grid folders found. Stopping the code...")
        # check for all dirs that the contribution folder exists, otherwise try to create it


        # make all external variables class variables, so that they can be changed later on
        # important particularly for runmode
        self.runmode=mode
        self.grid_folder=grid_folder
        self.main_run_folder=main_run_folder
        self.NLO_subtraction=NLO_subtraction[0] 
        self.order=order
# not used anymore:
#        self.combine_distributions_path = pjoin(munich_dir,"bin","modules","combine_distributions.py")
#        self.set_parallel_runs = set_parallel_runs
        # manual dictionary which connects level 3 folders with required grids, needs to be changed 
        # if, eg, K+P terms should get different phase-space, or when QED is considered as well
        self.grid_assignment=grid_assignment
        self.include_loop_induced=include_loop_induced
        self.grid_dirs_for_run_dirs = {}
        self.grid_dirs_for_run_dirs = self.get_grid_dirs_for_run_dirs() # assign the grid dirs to the runs
        self.config_list = config_list
        self.runtime_table = multidim_dict(3)
        self.pre_cross_section = multidim_dict(3)
        self.cross_section = multidim_dict(3)
        # hard-coded parameters for extrapolation that might be adjusted with experience:
        # minimal number of events per channel
        self.min_events_per_channel = 50000
        # minimal number of parallelizations per channel (at least 2 in case one goes wrong)
        self.min_parallel_pre_run = 1 # in pre run parallelize at least with two instances
        self.min_parallel_per_channel = 1 # in main run (that means one additional; make sense because that is why we extrapolate the runtimes)
        run_class.max_nr_of_tries = 3
        # this is to make sure that if you abort the script the termination of jobs works as expected (or is not done because no jobs started)
        self.jobs_started = False
        self.pre_parallel_printed = [] # empty list, add folders for which warning about restriction of parallel runs was printed
        self.failed_run_list = [] # to print out all failed runs in the end
        self.top_order = max(self.order, key=len) # often needed: highest order of run
        # set common infiles for extrapolation/result combination which also uniquely determin result folder name of MUNICH
        self.infile_extrapolation   = pjoin(fold.run_folder_path,"result","infile.MATRIX."+self.top_order+".extrapolation.dat")
        self.infile_result          = pjoin(fold.run_folder_path,"result","infile.MATRIX."+self.top_order+".result.dat")
        self.infile_distribution    = pjoin(fold.run_folder_path,"result","infile.MATRIX."+self.top_order+".distribution.dat")
        self.infile_scaleband       = pjoin(fold.run_folder_path,"result","infile.scaleband.dat")
        self.folder_extrapolation   = pjoin(fold.run_folder_path,"result","result.."+os.path.basename(self.infile_extrapolation).lstrip("infile.").replace(".dat",""))
        self.folder_result          = pjoin(fold.run_folder_path,"result","result.."+os.path.basename(self.infile_result).lstrip("infile.").replace(".dat",""))
        self.folder_distribution    = pjoin(fold.run_folder_path,"result","result.."+os.path.basename(self.infile_distribution).lstrip("infile.").replace(".dat",""))
        # create static scaleband file
        if inp.result_method == "TSV":
            inp.create_infile_scaleband_file(self.infile_scaleband)
        # initialize file names for input class:
        LOQCD = self.get_coupling_order_QCD("LO")
        NLOQCD = self.get_coupling_order_QCD("NLO")
        NNLOQCD = self.get_coupling_order_QCD("NNLO")
        NNNLOQCD = self.get_coupling_order_QCD("NNNLO")
        LOEW = self.get_coupling_order_EW("LO")
        NLOEW = self.get_coupling_order_EW("NLO")
        inp.init_infile_result(LOQCD,NLOQCD,NNLOQCD,NNNLOQCD,LOEW,NLOEW)

#       specify here all contributions in the order as they should be printed out, separated by qq and gg contributions
        self.sort_list_qq   = ["LOqq", \
                               "NLOqq.QCD", \
                               "NLOqq.EW", \
                               "NNLOqq.QCD"]
        self.sort_list_gg   = ["loopLOgg.QCD", \
                               "loopNLOgg.QCD"]
        # self.sort_list_aa   = ["LOaa", \
        #                        "NLOa+aa"]
        self.sort_list_a    = ["LOa", \
                               "NLOa"]
        self.sort_list_sum  = ["LO", \
                               "NLO.QCD", \
                               "NLO.EW", \
                               "NLO.QCD+NLO.EW", \
                               "NLO.QCDxNLO.EW", \
                               "NLO.QCDxNLOqq.EW+NLOa", \
                               "NNLO.QCD", \
                               "nNNLO.QCD", \
                               # if without NLO gg
                               "NNLO.QCD+NLO.EW", \
                               "NNLO.QCDxNLO.EW", \
#                               "NLO.QCDxNLO.EW+NNLO.QCD", \
                               "NNLO.QCDxNLOqq.EW+NLOa", \
                               "NNLOqq.QCDxNLO.EW+LOgg", \
                               "NNLOqq.QCDxNLOqq.EW.QCD+NLOa+LOgg", \
                               # if with NLO gg
                               "nNNLO.QCD+NLO.EW", \
                               "nNNLO.QCDxNLO.EW", \
#                               "NLO.QCDxNLO.EW+nNNLO.QCD"
                               "NNLOqq.QCDxNLO.EW+NLOgg", \
                               "NNLOqq.QCDxNLOqq.EW+NLOa+NLOgg"]
        self.sort_list_pre  = ["LO", \
                               "NLO.QCD", \
                               "NLO.EW", \
                               "NLO.QCD+NLO.EW", \
                               "NNLO.QCD", \
                               "nNNLO.QCD", \
                               "NNLO.QCD+NLO.EW", \
                               "nNNLO.QCD+NLO.EW"]

#       use sorted list according to whether it includes gg or qq
        self.sort_list = self.sort_list_qq + self.sort_list_gg + self.sort_list_a + self.sort_list_sum
        
#       the file name might be different from the output string, provide the mapping here
        self.identifier_mapping = {}
        self.identifier_mapping["LOqq"] = "LO qq"
        self.identifier_mapping["NLOqq.EW"] = "NLO.EW qq"
        self.identifier_mapping["NLOqq.QCD"] = "NLO.QCD qq"
        self.identifier_mapping["NNLOqq.QCD"] = "NNLO.QCD qq"
        self.identifier_mapping["loopLOgg.QCD"] = "LO gg"
        self.identifier_mapping["loopNLOgg.QCD"] = "NLO.QCD gg"
        self.identifier_mapping["LOa"]  = "LO aa"
        if prc.process_name in LO_photon_induced_processes:
            self.identifier_mapping["NLOa"] = "NLO.EW aa+ax+xa"
        else:
            self.identifier_mapping["NLOa"] = "NLO.EW ax+xa"

#       create dictionary of file names from the previous contribution, used to identify which rates/distributions are copied
        self.used_identifier_with_mapping = multidim_dict(2)
        for identifier in self.sort_list:
            self.used_identifier_with_mapping["LO"][identifier] = "" # default setting (no change of filename)
            self.used_identifier_with_mapping["NLO"][identifier] = "" # default setting (no change of filename)
            self.used_identifier_with_mapping["NNLO"][identifier] = "" # default setting (no change of filename)
#       By default the value of the dictionary is empty for all filenames, but you may change it by 
#       hand if you want to change the filename for both rates and distributions when copied from 
#       the MUNICH output to the MATRIX output
#        self.used_identifier_with_mapping ["LO"]                      = "better_LO_name"
#}}}
#{{{ def: get_grid_dirs_for_run_dirs(self)
    def get_grid_dirs_for_run_dirs(self):
        # returns a dictionary that determines the grid folder of each run folder
        grid_dirs_for_run_dirs = {}
        for run_dir in self.run_dirs:
            dir_matched = False
            for grid_dir in self.grid_dirs:
                # check if contribution is the same and to distinguish photon-initiated also if coupling XX or aXX is the same
                contribution_match = self.get_contribution(run_dir) == self.get_contribution(grid_dir) and self.get_coupling(run_dir) == self.get_coupling(grid_dir)
                both_photon_induced = (self.get_coupling(run_dir).startswith("a") and self.get_coupling(grid_dir).startswith("a"))
                both_not_photon_induced = (not self.get_coupling(run_dir).startswith("a") and not self.get_coupling(grid_dir).startswith("a"))
                assignment_match = self.grid_assignment.get(self.get_contribution(run_dir)) == self.get_contribution(grid_dir) and (both_photon_induced or both_not_photon_induced)
                if contribution_match or assignment_match:
                    if self.get_firstfolder(grid_dir).endswith(".tau") and not self.get_firstfolder(run_dir).endswith(".tau"):
                        contribution_match = False
                        assignment_match = False
                    if not self.get_firstfolder(grid_dir).endswith(".tau") and self.get_firstfolder(run_dir).endswith(".tau"):
                        contribution_match = False
                        assignment_match = False
                if contribution_match or assignment_match:
                    if dir_matched: out.print_error("There seems to be a double assignment of grids for run dir %s" % run_dir)
                    grid_dirs_for_run_dirs[run_dir]=grid_dir
                    dir_matched = True
            if not dir_matched:
                out.print_error("Could not find correct grid dir for run dir %s, check grid assignments" % run_dir)
        for run_dir in self.loop_run_dirs:
            dir_matched = False
            for grid_dir in self.loop_grid_dirs:
                contribution_match = self.get_contribution(run_dir) == self.get_contribution(grid_dir)
                assignment_match = self.grid_assignment.get(self.get_contribution(run_dir)) == self.get_contribution(grid_dir)
                if contribution_match or assignment_match:
                    grid_dirs_for_run_dirs[run_dir]=grid_dir
                    dir_matched = True
            if not dir_matched:
                out.print_error("Could not find correct grid dir for loop run dir %s, check grid assignments" % run_dir)
        return grid_dirs_for_run_dirs
#}}}
#{{{ def: warmup(self,wp_phase)
    def warmup(self,wp_phase): # pre-run to set up a required grids for run
        # wp_phase: switch allows to redo the warmup run if some runs have not correctly finished
        self.phase = wp_phase
        # (1) normal warmup, (2) redo warmup for failed runs
        if self.phase == 1: out.print_info("Starting grid setup (warmup)...")
        # Create a list of jobs and then iterate through
        # the number of processes appending each process to
        # the job list 
        job_list = []
        # add required jobs for warmup to job list split into:
        for grid_dir in self.grid_dirs: # normal dirs
            # create grid dir with channels in log folder
            fold.create_dir(grid_dir,self.channels[grid_dir])
            # add grid identifier to these folders
            fold.add_dir_identifier(grid_dir,"grid")
            self.set_inputs_grid_run(grid_dir)
            for channel in self.channels[grid_dir]:
                if self.phase == 2 or continue_run:
                    # if we are in phase 2 (restarted runs) or we want an old run to contine; we ommit all jobs which have finished
                    if self.job_correctly_finished(grid_dir,channel):
                        continue
                job_list.append([grid_dir,channel])
        # switch later to turn off loop-induced sub-processes 
        if self.include_loop_induced:
            for grid_dir in self.loop_grid_dirs: # loop dirs
                # create grid dir with channels in log folder
                fold.create_dir(grid_dir,self.loop_channels[grid_dir])
                # add grid identifier to these folders
                fold.add_dir_identifier(grid_dir,"grid")
                self.set_inputs_grid_run(grid_dir)
                for channel in self.loop_channels[grid_dir]:
                    if self.phase == 2 or continue_run:
                        # if we are in phase 2 (restarted runs) or we want an old run to contine; we ommit all jobs which have finished
                        if self.job_correctly_finished(grid_dir,channel):
                            continue
                    job_list.append([grid_dir,channel])
        if job_list and self.phase == 2:
            out.print_info("Re-starting grid setup (warmup) for runs that failed...")

        self.jobs_started = True
        # reverse order of list so that NNLO runs start first
        job_list = list(reversed(sorted(job_list)))
        if job_list: self.submit_jobs(job_list)
#}}}
#{{{ def: clear_warmup(self)
    def clear_warmup(self):
        # always clean everything which would come after
        self.clear_pre_run()
        self.clear_main_run()
        # no cleaning if we continue a run; 2do: maybe still try cleaning for each folder AND channel that did NOT correctly finished?
        # self.job_correctly_finished(grid_dir,channel)
        if continue_run:
            return
        # remove unnecessary content of grid dirs
        something_cleaned = False
        for grid_dir in self.grid_dirs: # normal grid dirs
            needed_cleaning = fold.clean_run_dir(grid_dir) # returns true when there was something to clean
            if needed_cleaning:
                something_cleaned = True
        if self.include_loop_induced:
            for grid_dir in self.loop_grid_dirs: # loop grid dirs
                needed_cleaning = fold.clean_run_dir(grid_dir) # returns true when there was something to clean
                if needed_cleaning:
                    something_cleaned = True
        if something_cleaned:
            out.print_info("Cleaning previous grid runs (warmup)...")
#}}}
#{{{ def: clear_pre_run(self)
    def clear_pre_run(self):
        # always clean everything which would come after
        self.clear_main_run()
        self.clear_pre_results()
        # no cleaning if we continue a run; 2do: maybe still try cleaning for each folder AND channel that did NOT correctly finish?
        # self.job_correctly_finished(grid_dir,channel)
        if continue_run:
            return
        # remove all unnecessary content of run.0 dirs
        something_cleaned = False
        for run_dir in self.run_dirs: # normal grid dirs
            needed_cleaning = fold.clean_run_dir(run_dir) # returns true when there was something to clean
            if needed_cleaning:
                something_cleaned = True
        if self.include_loop_induced:
            for run_dir in self.loop_run_dirs: # loop grid dirs
                needed_cleaning = fold.clean_run_dir(run_dir) # returns true when there was something to clean
                if needed_cleaning:
                    something_cleaned = True
        # remove all run.1-XX dirs
        for run_dir_0 in self.run_dirs: # normal run dirs
            run_dir_up = run_dir_0.rsplit('/', 1)[0]
            run_dirs_in_folder = [ d for d in os.listdir(run_dir_up) if os.path.isdir(pjoin(run_dir_up,d)) and d.startswith("run.") and not d == "run.0"]
            for run_dir in run_dirs_in_folder:
                shutil.rmtree(pjoin(run_dir_up,run_dir))
                something_cleaned = True
        if self.include_loop_induced:
            for run_dir in self.loop_run_dirs: # loop run dirs
                run_dir_up = run_dir.rsplit('/', 1)[0]
                run_dirs_in_folder = [ d for d in os.listdir(run_dir_up) if os.path.isdir(pjoin(run_dir_up,d)) and d.startswith("run.") and not d == "run.0"]
                for run_dir in run_dirs_in_folder:
                    shutil.rmtree(pjoin(run_dir_up,run_dir))
                    something_cleaned = True
        if something_cleaned:
            out.print_info("Cleaning previous extrapolation runs (pre run)...")
#}}}
#{{{ def: main_run(self,mn_phase)
    def main_run(self,mn_phase): # main run to start cross section computation in all folders
        # mn_phase: switch allows to redo the main run if some runs have not correctly finished
        self.phase = mn_phase
        if self.phase == -1: out.print_info("Starting runs to determine runtimes (pre run)...")
        if self.phase == 1: out.print_info("Starting cross section computation (main run)...")
        # Create a list of jobs and then iterate through
        # the number of processes appending each process to
        # the job list 
        job_list = []
        # add required jobs for main run to job list split into:
        for run_dir in self.run_dirs: # normal dirs
            # create run.0 dir for each run dir with channels in log folder
            fold.create_dir(run_dir,self.run_channels[run_dir])
            for channel in self.run_channels[run_dir]: # loop through channels
                if self.phase < 0: # for pre run use predefine number of parallel runs, depending on contribution
                    parallel_runs = self.get_parallel_pre_runs_for_contribution(run_dir)
                else: # for main run use computed number of parallel runs from runtime extrapolation
                    parallel_runs = self.runtime_table[run_dir][channel]["parallel_jobs"]
                # elif(len(self.runtime_table[run_dir][channel]) > 1): # for main run use computed number of parallel runs from runtime extrapolation
                #     parallel_runs = self.runtime_table[run_dir][channel]["parallel_jobs"]
                # else:
                #     out.print_error("Problem with reading runtimes for run_dir: %s and channel: %s. Cannot find their extrapolated runtimes in the runtime.dat file." % (run_dir,channel))
                for k in range(0,parallel_runs): # for parallel running of same contributions
                    # change here the required inputs (in file_parameter.dat) for the pre run (in run.0-parallel_runs_of_pre folder)
                    if self.phase < 0:
                        i=k # this is to use run.0-parallel_runs_of_pre for the extrapolation run
                    else:
                        i=k+self.get_parallel_pre_runs_for_contribution(run_dir) # this is to use run.parallel_runs_of_pre and onwards for the main runs
                    run_dir_i = run_dir.replace(main_run_folder,"run.%s" % i)
                    # if we are in phase 2 (restarted runs) or we want an old run to contine; we ommit all jobs which have finished
                    # CAREFULL: if we continue a run we HAVE TO make sure we use the same inputs as before; 2do: implement cross check of inputs; 2do: remove cleaning
                    if abs(self.phase) == 2 or continue_run:
                        if self.job_correctly_finished(run_dir.replace(main_run_folder,"run.%s" % i),channel):
                            continue
                    # for certain processes exclude VT2 in prerun here
                    if self.phase < 0 and "VT2.QCD" in run_dir and prc.process_name in VT2_use_default_runtime:
                        out.print_info("VT2 job (dir: %s, channel: %s) excluded from extrapolation run, because amplitude to slow. Will assume a default setting for the main run." % (run_dir_i,channel))
                        continue
                    # set inputs the same for all channels in pre runs
                    if self.phase < 0:
                        self.set_inputs_pre_run(run_dir_i,i)
                        # add pre run identifier to these folders
                        fold.add_dir_identifier(run_dir_i,"pre")
                    # change here the required inputs (in file_parameter.dat) inside the run.X folders separately for the different channels
                    if self.phase > 0:
                        self.set_inputs_main_run(run_dir_i,channel,i)
                        # add main run identifier to these folders
                        fold.add_dir_identifier(run_dir_i,"main")
                    job_list.append([run_dir_i,channel])
        # switch later to turn off loop-induced sub-processes 
        if self.include_loop_induced:
            for run_dir in self.loop_run_dirs: # loop dirs
              # create run.0 dir for each run dir with channels in log folder
              fold.create_dir(run_dir,self.loop_channels[self.grid_dirs_for_run_dirs[run_dir]])
              for channel in self.loop_channels[self.grid_dirs_for_run_dirs[run_dir]]: # loop through channels
                if self.phase < 0:
                    parallel_runs = self.get_parallel_pre_runs_for_contribution(run_dir)
                else:
                    parallel_runs = self.runtime_table[run_dir][channel]["parallel_jobs"]
                # elif(len(self.runtime_table[run_dir][channel]) > 1): # for main run use computed number of parallel runs from runtime extrapolation
                #     parallel_runs = self.runtime_table[run_dir][channel]["parallel_jobs"]
                # else:
                #     out.print_error("Problem with reading runtimes for run_dir: %s and channel: %s. Cannot find their extrapolated runtimes in the runtime.dat file." % (run_dir,channel))
                for k in range(0,parallel_runs): # for parallel running of same contributions
                    # change here the required inputs (in file_parameter.dat) for the pre run (in run.0-parallel_runs_of_pre folder)
                    if self.phase < 0:
                        i=k # this is to use run.0-parallel_runs_of_pre for the extrapolation run
                    else:
                        i=k+self.get_parallel_pre_runs_for_contribution(run_dir) # this is to use run.parallel_runs_of_pre and onwards for the main runs
                    run_dir_i = run_dir.replace(main_run_folder,"run.%s" % i)
                    # if we are in phase 2 (restarted runs) or we want an old run to contine; we ommit all jobs which have finished
                    if abs(self.phase) == 2 or continue_run:
                        if self.job_correctly_finished(run_dir.replace(main_run_folder,"run.%s" % i),channel):
                            continue
                    # set inputs the same for all channels in pre runs
                    if self.phase < 0:
                        self.set_inputs_pre_run(run_dir_i,i)
                        # add pre run identifier to these folders
                        fold.add_dir_identifier(run_dir_i,"pre")
                    # change here the required inputs (in file_parameter.dat) inside the run.X folders separately for the different channels
                    if self.phase > 0:
                        self.set_inputs_main_run(run_dir_i,channel,i)
                        # add main run identifier to these folders
                        fold.add_dir_identifier(run_dir_i,"main")
                    job_list.append([run_dir_i,channel])
        if job_list:
            if self.phase == 2:
                out.print_info("Re-starting cross section computation (main run) for runs that failed...")
            elif self.phase == -2:
                out.print_info("Re-starting extrapolation runs (pre run) for runs that failed...")
        # reverse order of list so that NNLO runs start first, in particular VT2 very early (~ third position)
        job_list = list(reversed(sorted(job_list)))
        # for job in job_list:
        #     print(job)
        # exit(0)
        # this is to make sure that if you abort the script the termination of jobs works as expected (or is not done because no jobs started)
        self.jobs_started = True
        # run the jobs from the list (only if there are jobs in job_list)
        if job_list: self.submit_jobs(job_list)
#}}}
#{{{ def: clear_main_run(self)
    def clear_main_run(self):
        # no cleaning if we continue a run; 2do: maybe still try cleaning for each folder AND channel that did NOT correctly finish?
        # self.job_correctly_finished(grid_dir,channel)
        if continue_run:
            return
        # remove all run.1-XX dirs
        something_cleaned = False
        for run_dir_0 in self.run_dirs: # normal run dirs
            run_dir_up = run_dir_0.rsplit('/', 1)[0]
            run_dirs_in_folder = fold.get_dirs_with_identifier(run_dir_up,"main")
            for run_dir in run_dirs_in_folder:
                shutil.rmtree(pjoin(run_dir_up,run_dir))
                something_cleaned = True
        if self.include_loop_induced:
            for run_dir in self.loop_run_dirs: # loop run dirs
                run_dir_up = run_dir.rsplit('/', 1)[0]
                run_dirs_in_folder = fold.get_dirs_with_identifier(run_dir_up,"main")
                for run_dir in run_dirs_in_folder:
                    shutil.rmtree(pjoin(run_dir_up,run_dir))
                    something_cleaned = True
        if something_cleaned:
            out.print_info("Cleaning previous cross section runs (main run)...")
#}}}
#{{{ def: extrapolate_runtimes(self)
    def extrapolate_runtimes(self): # extrapolate results after the pre run has finished
        out.print_info("Extrapolating runtimes...")
        # create files inside result/infile.result/ folder
        path = pjoin(fold.run_folder_path,"result","infile.result")
        try:
            os.makedirs(path)
        except:
            pass
        for file_name in inp.all_infile_result_files:
             inp.create_infile_result_file(pjoin(path,file_name),self.runtime_table,-1)
        self.set_inputs_result_combination(pjoin(fold.run_folder_path,"result"))
                
        # this is done by a single results job
        inp.write_infile_result_MATRIX(self.infile_extrapolation,self.order,parameter_list,self.NLO_subtraction,self.get_coupling_order("LO"),self.get_coupling_order("NLO") \
                                       ,self.get_coupling_order("LO","NLO"),self.get_coupling_order("NNLO"),self.get_coupling_order("NNNLO"),self.include_loop_induced,cross_section=True)
        job_list = []
        job_list.append([os.path.basename(self.infile_extrapolation),"result"])

        runmode_sav = self.runmode
        self.runmode = "multicore" # the extrapolation is always done locally
        if job_list: self.submit_jobs(job_list)
        self.runmode = runmode_sav # change back to original runmode
        runtime_file_path = pjoin(fold.run_folder_path,"result","runtime.dat")
        shutil.copy(runtime_file_path, runtime_file_path.replace(".dat","")+"_pre_run.dat")
#}}}
#{{{ def: print_pre_run(self)
    def print_pre_run(self):
        # combine collected results from pre-run/extrapolation and print first preliminary result
        phase = -1 # for pre-run
        if inp.result_method == "CV":
            self.copy_rates_CV(phase)
        elif inp.result_method == "TSV":
            self.copy_rates_TSV(phase)
        else:
            out.print_error("No valide result_method set. Must be CV or TSV. Exiting...")
        
        self.print_results_onscreen_and_to_summary_file(phase)
#}}}
#{{{ def: clear_pre_results(self)
    def clear_pre_results(self):
        # remove MUNICH extrapolation folder
        try:
            shutil.rmtree(self.folder_extrapolation)
        except:
            pass
#}}}
#{{{ def: clear_results(self)
    def clear_results(self):
        # remove MUNICH and MATRIX result folders

        # MUNICH folders:
        try:
            shutil.rmtree(self.folder_result)
        except:
            pass
        try:
            shutil.rmtree(self.folder_distribution)
        except:
            pass

        # MATRIX folder:
        # remove only the old *-run folders (if there are any)
        result_folder = pjoin(process_dir,"result",run_folder)
        result_sub_folder = glob.glob(pjoin(result_folder,"*-run"))
        # remove summary folder
        if os.path.isdir(pjoin(fold.result_folder_path,"summary")):
            result_sub_folder.append(pjoin(fold.result_folder_path,"summary"))
        if os.path.isdir(pjoin(fold.result_folder_path,"gnuplot")):
            result_sub_folder.append(pjoin(fold.result_folder_path,"gnuplot"))
        for folder in result_sub_folder:
            shutil.rmtree(folder)
        try:
            os.remove(pjoin(fold.result_folder_path,"CITATIONS.bib"))
        except:
            pass
        out.print_info("Cleaning previous results (result run)...")
#}}}
#{{{ def: combine_results(self)
    def combine_results(self): # collect results after the main run has finished
        out.print_info("Collecting and combining results...")
        # Create a list of jobs and then iterate through the number of processes appending each process to the job list 

        # create files inside result/infile.result/ folder
        path = pjoin(fold.run_folder_path,"result","infile.result")
        try:
            os.makedirs(path)
        except:
            pass
        for file_name in inp.all_infile_result_files:
             inp.create_infile_result_file(pjoin(path,file_name),self.runtime_table,1)
        # set inputs in file_parameter.dat of result combination
        self.set_inputs_result_combination(pjoin(fold.run_folder_path,"result"))

        job_list = []
        # 2do: add some sanity checks to make sure all data is there in the run.xx folders
        inp.write_infile_result_MATRIX(self.infile_result,self.order,parameter_list,self.NLO_subtraction,self.get_coupling_order("LO"),self.get_coupling_order("NLO") \
                                       ,self.get_coupling_order("LO","NLO"),self.get_coupling_order("NNLO"),self.get_coupling_order("NNNLO"),self.include_loop_induced,cross_section=True)
        job_list.append([os.path.basename(self.infile_result),"result"])
        

        if int(parameter_list["switch_distribution"]) == 1:
            out.print_info("Collecting and combining distributions...")
            inp.write_infile_result_MATRIX(self.infile_distribution,self.order,parameter_list,self.NLO_subtraction,self.get_coupling_order("LO"),self.get_coupling_order("NLO") \
                                           ,self.get_coupling_order("LO","NLO"),self.get_coupling_order("NNLO"),self.get_coupling_order("NNNLO"),self.include_loop_induced,cross_section=False)
            if inp.result_method == "TSV":
             job_list.append([os.path.basename(self.infile_distribution),"distribution","infile.scaleband.dat"])
            else:
              job_list.append([os.path.basename(self.infile_distribution),"distribution"])

                # use local mode, but save original runmode]
            
        runmode_sav = self.runmode
        run.runmode = "multicore" # the result combination is always done locally
        # run the jobs from the list (only if there are jobs in job_list)
        if job_list: self.submit_jobs(job_list)

        
        if inp.result_method == "CV":
            self.copy_rates_CV()
            if int(parameter_list["switch_distribution"]) == 1: 
                self.copy_distributions_CV()
        elif inp.result_method == "TSV":
            self.copy_rates_TSV() 
            if int(parameter_list["switch_distribution"]) == 1: 
                self.copy_distributions_TSV()
        else:
            out.print_error("No valide result_method set. Must be CV or TSV. Exiting...")

        if int(parameter_list["switch_PineAPPL"]) == 1:
            out.print_info("Collecting and combining PineAPPL grids...")
            self.submit_jobs([[os.path.basename(self.infile_distribution),"PineAPPL"]])
            self.copy_PineAPPL_grids()   

        self.runmode = runmode_sav # change back to original runmode
                
#}}}
#{{{ def: copy_rates_CV(self,phase)
    def copy_rates_CV(self, phase = 1): # copy results needed for MATRIX from MUNICH output
        # copy relevant results to MATRIX results folder
        cross_section = multidim_dict(3)

        if phase == -1:
            result_folder = self.folder_extrapolation
            order_list = [self.top_order]
        else:
            result_folder = self.folder_result
            order_list = self.order
        self.MATRIX_rates_folder = {}

        # loop over orders since the runs at each order (with different PDFs etc.) are put into a separate folder
        for this_order in order_list:
            # determines all files inside the combination resutl forlder containing the result method (".CV.")
            files_to_copy = self.get_named_files(result_folder,".CV.",2)
            # copy only files for current run: if LORUN, NLORUN, NNLORUN are in the file name
            files_to_copy = [f for f in files_to_copy if "__"+this_order+"RUN.dat" in os.path.basename(f)]
            # select files which are not extrapolated or need to be extrapolated (using QT subtraction)
            files_to_copy = [f for f in files_to_copy if not ".extrapolated." in os.path.basename(f) or (".extrapolated." in os.path.basename(f) and ("NNLO.QCD" in os.path.basename(f) or "NNLOqq.QCD" in os.path.basename(f) or (self.NLO_subtraction == "QT" and ("NLO.QCD" in os.path.basename(f) or "NLOqq.QCD" in os.path.basename(f) or "loopNLOgg.QCD" in os.path.basename(f)))))]

            # create intermediate MATRIX folders at each order to copy the relevant files into
            self.MATRIX_rates_folder[this_order] = pjoin(os.path.dirname(files_to_copy[0]),"MATRIX_rates_"+this_order)
            try:
                os.makedirs(self.MATRIX_rates_folder[this_order])
            except:
                pass
            # go through all files_to_copy and copy them into the created MATRIX folders
            for file_src in files_to_copy: # some special treatment for loop-induced contribution
                # get filename of current file
                file_name = os.path.basename(file_src)                
                file_to_copy = file_src
                # determine destination
                file_dest = pjoin(self.MATRIX_rates_folder[this_order],file_name)
                shutil.copy(file_to_copy,file_dest)

#            self.skip_contribution = ["LO-LOaa","NLO.EW-a-aa","NLO.EW-aa","NLO.QCD-aa"]

            # now all files from MATRIX_rates_folder are converted (renamed, min/max computed) and saved in MATRIX result folder
            src_files = os.listdir(self.MATRIX_rates_folder[this_order])
            MATRIX_result_folder = pjoin(process_dir,"result",run_folder,this_order+"-run")
            for file_name in src_files:
                if not phase == -1: # no need to copy to final result forder for pre-run
                    # reject contributions that we don't want to copy
                    identifier = file_name.split("__")[0].replace("plot.CV.","").replace("extrapolated.","")
                    if identifier not in self.used_identifier_with_mapping[this_order]:
                        continue
                    file_name_MATRIX = "rate_"+file_name.replace(".","_").replace("plot_","").replace("CV_","").replace("_dat",".dat").replace("NNLO_"+self.get_coupling_order("NNLO")+"_loop","loop-induced_QCD").replace("_"+self.get_coupling_order("LO"),"").replace("_"+self.get_coupling_order("NLO"),"").replace("_"+self.get_coupling_order("NNLO"),"").replace("__LORUN","").replace("__NLORUN","").replace("__NNLORUN","")
                    if self.used_identifier_with_mapping[this_order][identifier]:
                        file_name_MATRIX = file_name_MATRIX.replace(identifier,self.used_identifier_with_mapping[this_order][identifier])
                    file_dest = ""

                    if this_order == "LO" and parameter_list.get("photon_induced","0") == "1" and prc.process_name not in LO_photon_induced_processes:
                        file_dest = pjoin(MATRIX_result_folder,file_name_MATRIX)
                    elif identifier in self.sort_list_qq:
                        file_dest = pjoin(MATRIX_result_folder,"rates__qq",file_name_MATRIX)
                    elif identifier in self.sort_list_gg:
                        file_dest = pjoin(MATRIX_result_folder,"rates__gg",file_name_MATRIX)
                    elif this_order == "LO" and identifier in self.sort_list_a:
                        file_dest = pjoin(MATRIX_result_folder,"rates__aa",file_name_MATRIX)
                    elif identifier in self.sort_list_a and prc.process_name in LO_photon_induced_processes:
#                        file_dest = pjoin(MATRIX_result_folder,"rates__aa+ax+xa",file_name_MATRIX)
                        file_dest = pjoin(MATRIX_result_folder,"rates__aa",file_name_MATRIX)
                    elif identifier in self.sort_list_a:
#                        file_dest = pjoin(MATRIX_result_folder,"rates__ax+xa",file_name_MATRIX)
                        file_dest = pjoin(MATRIX_result_folder,"rates__aa",file_name_MATRIX)
                    else:
                        file_dest = pjoin(MATRIX_result_folder,file_name_MATRIX)

                file_src = pjoin(self.MATRIX_rates_folder[this_order], file_name)
                if (os.path.isfile(file_src)):
                    # save cross section information
                    central, err, up, down = res.get_cross_sections_from_file_CV(file_src)
                    cross_section[this_order][file_src]["central"] = central
                    cross_section[this_order][file_src]["err"]     = err
                    cross_section[this_order][file_src]["up"]      = up
                    cross_section[this_order][file_src]["down"]    = down
                    if central == 0.:
                        out.print_warning("Combined cross section appears to be zero when trying to collect %s results." % this_order)
                    if phase == -1:
                        self.pre_cross_section = cross_section
                        continue
                    self.cross_section = cross_section
                    # change the first column into two columns with muR and muF
                    res.convert_to_independent_scales(file_src)
                    if file_dest:
                        if not os.path.isdir(os.path.dirname(file_dest)):
                            os.makedirs(os.path.dirname(file_dest))
                        shutil.copy(file_src,file_dest)
                        line_prepender(file_dest,"#      muR       muF  cross_section        num_err")
#}}}
#{{{ def: copy_rates_TSV(self, phase = 1)
    def copy_rates_TSV(self, phase = 1): # copy results needed for MATRIX from MUNICH output
        # copy relevant results to MATRIX results folder

        cross_section = multidim_dict(3)

        if phase == -1:
            result_folder = self.folder_extrapolation
            order_list = [self.top_order]
        else:
            result_folder = self.folder_result
            order_list = self.order
        self.MATRIX_rates_folder = {}

        # loop over orders since the runs at each order (with different PDFs etc.) are put into a separate folder
        for this_order in order_list:
            # all NLO' style results are missing so far, but these should be possible to simply add via the standard MUNICH inputs (2do: adopt this accordingly later)
            files_to_copy = [f for f in self.get_named_files(pjoin(result_folder,inp.scale_setting,"complete"),"plot.",0) if not ".qTcut." in f]
            # copy only files for current run: if LORUN, NLORUN, NNLORUN are in the file name
            files_to_copy = [f for f in files_to_copy if "__"+this_order+"RUN.dat" in os.path.basename(f)]
            # select files which are not extrapolated or need to be extrapolated (using QT subtraction)
            files_to_copy = [f for f in files_to_copy if (not "extrapolated" in os.path.basename(f)  and not ".rcut" in os.path.basename(f)) or ( ".rcut" in os.path.basename(f) and ("NNLO.QCD" in os.path.basename(f) or "NNLOqq.QCD" in os.path.basename(f) or (self.NLO_subtraction == "QT" and ("NLO.QCD" in os.path.basename(f) or "NLOqq.QCD" in os.path.basename(f) or "loopNLOgg.QCD" in os.path.basename(f)))))]
            
            # create intermediate MATRIX folders at each order to copy the relevant files into
            self.MATRIX_rates_folder[this_order] = pjoin(os.path.dirname(files_to_copy[0]),"MATRIX_rates_"+this_order)
            try:
                os.makedirs(self.MATRIX_rates_folder[this_order])
            except:
                pass
            # go through all files_to_copy and copy them into the created MATRIX folders
            for file_src in files_to_copy: # some special treatment for loop-induced contribution
                # get filename of current file
                file_name = os.path.basename(file_src)                
                file_to_copy = file_src
                # determine destination
                file_dest = pjoin(self.MATRIX_rates_folder[this_order],file_name)
                shutil.copy(file_to_copy,file_dest)

#            self.skip_contribution = ["LO-LOaa","NLO.EW-a-aa","NLO.EW-aa","NLO.QCD-aa"]

            # now all files from MATRIX_rates_folder are converted (renamed, min/max computed) and saved in MATRIX result folder
            src_files = os.listdir(self.MATRIX_rates_folder[this_order])
            MATRIX_result_folder = pjoin(process_dir,"result",run_folder,this_order+"-run")
            for file_name in src_files:
                if not phase == -1: # no need to copy to final result forder for pre-run
                    # reject contributions that we don't want to copy
                    identifier = file_name.split("__")[0].replace("plot.","").replace("rcut%s."%parameter_list["max_min_qTcut"],"")
                    if identifier not in self.used_identifier_with_mapping[this_order]:
                        continue
                    file_name_MATRIX = "rate_"+file_name.replace(str(parameter_list["max_min_qTcut"]),"XYZYX").replace(".","_").replace("plot_","").replace("CV_","").replace("_dat",".dat").replace("NNLO_"+self.get_coupling_order("NNLO")+"_loop","loop-induced_QCD").replace("_"+self.get_coupling_order("LO"),"").replace("_"+self.get_coupling_order("NLO"),"").replace("_"+self.get_coupling_order("NNLO"),"").replace("__LORUN","").replace("__NLORUN","").replace("__NNLORUN","").replace("XYZYX",str(parameter_list["max_min_qTcut"]/100.))
                    if self.used_identifier_with_mapping[this_order][identifier]:
                        file_name_MATRIX = file_name_MATRIX.replace(identifier,self.used_identifier_with_mapping[this_order][identifier])
                    file_dest = ""

                    if this_order == "LO" and parameter_list.get("photon_induced","0") == "1" and prc.process_name not in LO_photon_induced_processes:
                        file_dest = pjoin(MATRIX_result_folder,file_name_MATRIX)
                    elif identifier in self.sort_list_qq:
                        file_dest = pjoin(MATRIX_result_folder,"rates__qq",file_name_MATRIX)
                    elif identifier in self.sort_list_gg:
                        file_dest = pjoin(MATRIX_result_folder,"rates__gg",file_name_MATRIX)
                    elif this_order == "LO" and identifier in self.sort_list_a:
                        file_dest = pjoin(MATRIX_result_folder,"rates__aa",file_name_MATRIX)
                    elif identifier in self.sort_list_a and prc.process_name in LO_photon_induced_processes:
#                        file_dest = pjoin(MATRIX_result_folder,"rates__aa+ax+xa",file_name_MATRIX)
                        file_dest = pjoin(MATRIX_result_folder,"rates__aa",file_name_MATRIX)
                    elif identifier in self.sort_list_a:
#                        file_dest = pjoin(MATRIX_result_folder,"rates__ax+xa",file_name_MATRIX)
                        file_dest = pjoin(MATRIX_result_folder,"rates__aa",file_name_MATRIX)
                    else:
                        file_dest = pjoin(MATRIX_result_folder,file_name_MATRIX)
                        
                file_src = pjoin(self.MATRIX_rates_folder[this_order], file_name)
                if (os.path.isfile(file_src)):
                    # save cross section information 
                    central, err, up, down = res.get_cross_sections_from_file_TSV(file_src,parameter_list.get("scale_variation",1))
                    cross_section[this_order][file_src]["central"] = central
                    cross_section[this_order][file_src]["err"]     = err
                    cross_section[this_order][file_src]["up"]      = up
                    cross_section[this_order][file_src]["down"]    = down
                    if central == 0.:
                        out.print_warning("Combined cross section appears to be zero when trying to collect %s results." % this_order)
                    if phase == -1:
                        self.pre_cross_section = cross_section
                        continue
                    self.cross_section = cross_section
                    # change the first column into two columns with muR and muF
#                    res.convert_to_independent_scales(file_src)
                    if file_dest:
                        if not os.path.isdir(os.path.dirname(file_dest)):
                            os.makedirs(os.path.dirname(file_dest))
                        shutil.copy(file_src,file_dest)
#}}}
#{{{ def: copy_distributions_CV(self)
    def copy_distributions_CV(self): # copy distribution needed for MATRIX from MUNICH output
        files = {}
        if res.seven_point_variation_distribution(pjoin(self.folder_distribution,"CV")): # 7-point variation
            central_dir = pjoin(self.folder_distribution,"CV","scale.3.3")
        elif res.nine_point_variation_distribution(pjoin(self.folder_distribution,"CV")): # 9-point variation
            central_dir = pjoin(self.folder_distribution,"CV","scale.4.4")
        else:
            out.print_error("Trying to combine distributions from a folder that contains neither 7-point nor 9-point variation.")
        MATRIX_distributions_folder = pjoin(os.path.dirname(central_dir),"MATRIX_distributions")
        try:
            os.makedirs(MATRIX_distributions_folder)
        except:
            pass
        variation_dirs = [x for x in glob.glob(pjoin(self.folder_distribution,"CV","scale*.*")) if not x == central_dir] # variation

        # all distribution files
        files["all"]        = glob.glob(pjoin(central_dir,"plot.*.dat")) 

        # compute minimum und maximum of all distributions and save to MATRIX subfolder
        for file_path in files["all"]:
            file_list = [file_path]
            for variation_dir in variation_dirs:
                file_list.append(file_path.replace(central_dir,variation_dir))
            res.get_central_min_max_from_distribution_files(file_list,pjoin(MATRIX_distributions_folder,os.path.basename(file_path)))

        # copy distributions with modified names to MATRIX result folders
        for file_name in os.listdir(MATRIX_distributions_folder):
            try:
                identifier = file_name.split("..")[1].split("__")[0]
                order_run  = file_name.split("__")[1].replace("RUN.dat","-run")
                this_order = order_run.replace("-run","")
            except:
                out.print_error_continue("Something is wrong with the naming of the distributions. Did you use \"__\" or \"..\" in their names in the distribution.dat file? This should not be done to guarantee that they can be properly copied. ")
                continue
            if identifier in self.used_identifier_with_mapping[this_order]:
                if self.used_identifier_with_mapping[this_order][identifier]:
                    identifier = self.used_identifier_with_mapping[this_order][identifier]
            else:
                continue
            identifier = identifier.replace(".","_")
            MATRIX_result_dist_folder = pjoin(process_dir,"result",run_folder,order_run,"distributions__"+identifier)
            try:
                os.makedirs(MATRIX_result_dist_folder)
            except:
                pass
            file_name_MATRIX = file_name.split("..")[0].replace("plot.","")+"__"+identifier+".dat"
            file_dest = pjoin(MATRIX_result_dist_folder,file_name_MATRIX)
            file_src  = pjoin(MATRIX_distributions_folder,file_name)

            # if (order_run != "NLO-run" or identifier != "LO") and (identifier != "loop_QCD"):
            #     MATRIX_result_dist_folder = pjoin(process_dir,"result",run_folder,order_run,"distributions__"+identifier)
            #     try:
            #         os.makedirs(MATRIX_result_dist_folder)
            #     except:
            #         pass
            # else:
            #     MATRIX_result_dist_folder = ""
#            file_name_MATRIX = file_name.split("..")[0].replace("plot.","")+"__"+file_name.split("..")[1].replace("..",".").replace(".","_").replace("plot_","").replace("CV_","").replace("_dat",".dat").replace("NNLO_"+self.get_coupling_order("NNLO")+"_loop","loop-induced_QCD")
            shutil.copy(file_src,file_dest)
            length = 15
            observable = file_name_MATRIX.split("__")[0]
            observable2 = "" # usually not two line are needed
            if len(observable)>14:
                observable2 = observable[13:]
                observable = observable[:13]
            central = "central"
            minimum = "min (scale)"
            maximum = "max (scale)"
            num_err = "num_err"
            line = "#"+" "*(length-len(observable)-1)+observable # 1 column title: observable
            line = line+" "*(length-len(central))+central # 2: central cross section
            line = line+" "*(length-len(num_err))+num_err # 3: num_err
            line = line+" "*(length-len(minimum))+minimum # 4: minimal cross section due to scale variation
            line = line+" "*(length-len(num_err))+num_err # 5: num_err
            line = line+" "*(length-len(maximum))+maximum # 6: maximal cross section due to scale variation
            line = line+" "*(length-len(num_err))+num_err # 7: num_err
            if observable2:
                line_prepender(file_dest,"# "+observable2)
            line_prepender(file_dest,line)
#}}}
#{{{ def: copy_PineAPPL_grids(self)
    def copy_PineAPPL_grids(self): # copy pineappl grids needed for MATRIX from MUNICH output
        PineAPPL_grids_folder = pjoin(self.folder_distribution,inp.scale_setting,"PineAPPL")
        TSV_files = glob.glob(pjoin(PineAPPL_grids_folder,"*RUN.pineappl.lz4"))
        if not TSV_files:
            out.print_error_no_stop("There was a problem in the PineAPPL grid combination. No combined distributions are found in the right place: "+PineAPPL_grids_folder+" . Check the log-file, whether there has been an error: %s" % pjoin(self.infile_distribution)+".PineAPPL.log")
        # copy grids to MATRIX result folders
        for file_path in TSV_files:
            file_name = os.path.basename(file_path)
            try:
                order_run  = file_name.split("__")[1].replace("RUN.pineappl.lz4","-run")
                this_order = order_run.replace("-run","")
            except:
                out.print_error_continue("Something is wrong with the naming of the distributions. Did you use \"__\" or \"..\" in their names in the distribution.dat file? This should not be done to guarantee that they can be properly copied. ")
                continue
            MATRIX_result_pineAPPL_folder = pjoin(process_dir,"result",run_folder,order_run,"PineAPPL_grids")
            try:
                os.makedirs(MATRIX_result_pineAPPL_folder)
            except:
                pass
            file_name_MATRIX = file_name.split("__")[0]+".pineappl.lz4"

            #copies the pineappl grids adding metadata

            file_dest = pjoin(MATRIX_result_pineAPPL_folder,file_name_MATRIX)
            file_src  = pjoin(PineAPPL_grids_folder,file_name)
            shutil.copy(file_src,file_dest)

##           copies the pineappl grids adding metadata
#            if os.path.isfile(pjoin(self.folder_distribution,"../runtime_pre_run.dat"))==False:
#                out.print_warning("%s not found." % pjoin(self.folder_distribution,"../runtime_pre_run.dat"))
##                runtime = ""
#            else:
#                runtime_filename = pjoin(self.folder_distribution,"../runtime_pre_run.dat")
##                runtime_file = open(pjoin(self.folder_distribution,"../runtime_pre_run.dat"),"r")
##                runtime = runtime_file.read()
##                runtime_file.close()
#            if os.path.isfile(pjoin(fold.input_folder_path,"parameter.dat"))==False:
#                out.print_warning("%s not found." % pjoin(fold.input_folder_path,"parameter.dat"))
#                parameter = ""      
#            else:
#                parameter_filename = pjoin(fold.input_folder_path,"parameter.dat")
##                parameter_file =open(pjoin(fold.input_folder_path,"parameter.dat"), "r")
##                parameter = parameter_file.read()
##                parameter_file.close()
#            if os.path.isfile(pjoin(fold.input_folder_path,"model.dat"))==False:
#                out.print_warning("%s not found." % pjoin(fold.input_folder_path,"model.dat"))
##                model = ""      
#            else:
#                model_filename = pjoin(fold.input_folder_path,"model.dat")
##                model_file =open(pjoin(fold.input_folder_path,"model.dat"), "r")
##                model = model_file.read()
##                model_file.close()
#            if os.path.isfile(pjoin(fold.input_folder_path,"distribution.dat"))==False:
#                out.print_warning("%s not found." % pjoin(fold.input_folder_path,"distribution.dat"))
##                distribution = ""      
#            else:
#                distribution_filename = pjoin(fold.input_folder_path,"distribution.dat")
##                distribution_file =open(pjoin(fold.input_folder_path,"distribution.dat"), "r")
##                distribution = distribution_file.read()
##                distribution_file.close()
#            if os.path.isfile(pjoin(fold.input_folder_path,"dddistribution.dat"))==False:
#                out.print_warning("%s not found." % pjoin(fold.input_folder_path,"dddistribution.dat"))            
##                dddistribution = ""
#            else:
#                dddistribution_filename = pjoin(fold.input_folder_path,"dddistribution.dat")
##                dddistribution_file =open(pjoin(fold.input_folder_path,"dddistribution.dat"), "r")
##                dddistribution = dddistribution_file.read()
##                dddistribution_file.close()
#
#            try:
#                subprocess.run(["pineappl","write","--set-key-file","runtime.dat",runtime_filename,"--set-key-file","parameter.dat",parameter_filename,"--set-key-file","model.dat",model_filename,"--set-key-file","distribution.dat",distribution_filename,"--set-key-file","dddistribution.dat",dddistribution_filename,file_src,file_dest])
#            except:
#                out.print_error_continue("Something is wrong with pineappl write: "+file_src+"   "+file_dest+" : copy instead!")
#                shutil.copy(file_src,file_dest)

#}}}
#{{{ def: copy_distributions_TSV(self)
    def copy_distributions_TSV(self): # copy distribution needed for MATRIX from MUNICH output
        TSV_distribution_folder = pjoin(self.folder_distribution,inp.scale_setting,"scale.band")
        TSV_files = glob.glob(pjoin(TSV_distribution_folder,"*dd.plot.*.dat"))

        if not TSV_files:
            out.print_error_no_stop("There was a problem in the result combination. No combined distributions are found in the right place: %s" % pjoin(self.folder_distribution,inp.scale_setting,"scale.band")+" . Check the log-file, whether there has been an error: %s" % pjoin(self.infile_distribution)+".distribution.log")
        # copy distributions with modified names to MATRIX result folders
        for file_path in TSV_files:
            file_name = os.path.basename(file_path)
            try:
                identifier = file_name.split("..")[1].split("__")[0]
                order_run  = file_name.split("__")[1].replace("RUN.dat","-run")
                this_order = order_run.replace("-run","")
            except:
                out.print_error_continue("Something is wrong with the naming of the distributions. Did you use \"__\" or \"..\" in their names in the distribution.dat file? This should not be done to guarantee that they can be properly copied. ")
                continue
            if identifier in self.used_identifier_with_mapping[this_order]:
                if self.used_identifier_with_mapping[this_order][identifier]:
                    identifier = self.used_identifier_with_mapping[this_order][identifier]
            else:
                continue
            identifier = identifier.replace(".","_")
            MATRIX_result_dist_folder = pjoin(process_dir,"result",run_folder,order_run,"distributions__"+identifier)
            try:
                os.makedirs(MATRIX_result_dist_folder)
            except:
                pass
            file_name_MATRIX = file_name.split("..")[0].replace("1dd.plot.","").replace("2dd.plot.","2D_")+"__"+identifier+".dat"

            # normal copy
            file_dest = pjoin(MATRIX_result_dist_folder,file_name_MATRIX)
            file_src  = pjoin(TSV_distribution_folder,file_name)
            shutil.copy(file_src,file_dest)

            # copy also minimum fixed rcut results when extrapolation is on
            file_fixed_rcut_dest = None
            if int(parameter_list.get("extrapolate_binwise",0)) > 0:
                if ("NNLO.QCD" in file_name or "NNLOqq.QCD" in file_name or (self.NLO_subtraction == "QT" and ("NLO.QCD" in file_name or "NLOqq.QCD" in file_name or "loopNLOgg.QCD" in file_name))) : 
                    MATRIX_result_dist_folder = pjoin(process_dir,"result",run_folder,order_run,"distributions__"+identifier)
                    try:
                        os.makedirs(pjoin(MATRIX_result_dist_folder,"qTcut-%s" % parameter_list["max_min_qTcut"]))
                    except:
                        pass
                    file_fixed_rcut_dest = pjoin(MATRIX_result_dist_folder,"qTcut-%s" % parameter_list["max_min_qTcut"],file_name_MATRIX)
                    file_fixed_rcut_src  = pjoin(TSV_distribution_folder,"qTcut-%s" % parameter_list["max_min_qTcut"],file_name)
                    shutil.copy(file_fixed_rcut_src,file_fixed_rcut_dest)
                
            # length = 19
            # observable = file_name_MATRIX.split("__")[0]
            # observable2 = "" # usually not two line are needed
            # if len(observable)>14:
            #     observable2 = observable[13:]
            #     observable = observable[:13]
            # central = "central"
            # minimum = "min (scale)"
            # maximum = "max (scale)"
            # num_err = "num_err"
            # line = "#"+" "*(16-len(observable)-1)+observable # 1 column title: observable
            # line = line+" "*(length-len(central))+central # 2: central cross section
            # line = line+" "*(length-len(num_err))+num_err # 3: num_err
            # line = line+" "*(16-len(minimum))+minimum # 4: minimal cross section due to scale variation
            # line = line+" "*(length-len(num_err))+num_err # 5: num_err
            # line = line+" "*(16-len(maximum))+maximum # 6: maximal cross section due to scale variation
            # line = line+" "*(length-len(num_err))+num_err # 7: num_err
            # if observable2:
            #     line_prepender(file_dest,"# "+observable2)
            #     if file_fixed_rcut_dest:
            #         line_prepender(file_fixed_rcut_dest,"# "+observable2)
            # line_prepender(file_dest,line)
            # if file_fixed_rcut_dest:
            #     line_prepender(file_fixed_rcut_dest,line)
#}}}
#{{{ def: print_results_onscreen_and_to_summary_file(self)
    def print_results_onscreen_and_to_summary_file(self,phase = 1):
        # screen output at end of run
        if phase == -1:
            sort_list = self.sort_list_pre
        else:
            sort_list = self.sort_list
        
        banner.size = 50
        banner.intend = 20
        intend = " "*16
        if parameter_list["coll_choice"]=="1":
            collider = "LHC"
        elif parameter_list["coll_choice"]=="2":
            collider = "Tevatron"
        else:
            out.print_error("collider_choice in parameter_list in routine print_results_onscree_and_to_summary_file is neither 1 nor 2.")
        energy = float(parameter_list["E"])*2/1000
        process = prc.get_nice_process_name()
        where = "@ %.4g TeV %s" % (energy,collider)

        # redirect output also to file in summary folder
        summary_folder = pjoin(process_dir,"result",run_folder,"summary")
        try:
            os.makedirs(summary_folder)
        except:
            pass
        f = open(pjoin(summary_folder,"result_summary.dat"), "w")
        original = sys.stdout
        sys.stdout = Tee(sys.stdout, f)

        print("")
        banner.initial_print()
        if phase == -1:
            banner.print_center("Pre-run result for:")
        else:
            banner.print_center("Final result for:")
        banner.print_center(process+"  "+where)
        banner.final_print()
        nruns = len(self.order)
        print("")
        if not phase == -1:
            if(nruns > 1):
                out.print_result("%s separate runs were made" % nruns)
            else:
                out.print_result("%s separate run was made" % nruns)
            print("")
        for this_order in sorted(self.order):
            if phase == -1 and not this_order in self.MATRIX_rates_folder: # for pre-run only highest run is combined
                continue

            result_out = this_order+"-run"
            print(intend+"#"+"-"*(len(result_out)+2)+"\\")
            print(intend+"# "+result_out+" |")
            print(intend+"#"+"-"*(len(result_out)+2)+"/")
            pdf_set = parameter_list["LHAPDF_%s" % this_order]
            out.print_result("PDF: "+pdf_set)

            #print(self.MATRIX_rates_folder[this_order])
            src_files = os.listdir(self.MATRIX_rates_folder[this_order])
            sorted_list = sorted(src_files)
            extrapolated_list = []
            # put extrapolated results at right position
            copy_sorted_list = copy.copy(sorted_list)
            for item in copy_sorted_list:
                if "extrapolated" in item or "rcut"+str(parameter_list["max_min_qTcut"]) in item:
                    sorted_list.remove(item)
                    extrapolated_list.append(item)
            final_sorted_list = []

            sorted_src_files = []
            max_length_output = 0
            rcut_string    = " -- qT subtr. cut r_cut=%s:" % (parameter_list["max_min_qTcut"]/100.)
            extrap_string  = " -- extrapolated to r_cut=0:"
            if (this_order == "NNLO" and not int(parameter_list["loop_induced"]) < 0) or this_order in ["NLO","NNLO"] and self.NLO_subtraction == "QT":
                max_length_output = max(len(rcut_string),len(extrap_string))
            for identifier in sort_list:
                order_out = self.identifier_mapping.get(identifier,identifier)
                if inp.result_method == "CV":
                    for file_name in sorted_list:
                        if "."+identifier+"__" in file_name:
                            sorted_src_files.append([file_name,order_out+":"])
                            max_length_output = max(max_length_output,len(order_out)+1)
                    for file_name in extrapolated_list:
                        if "."+identifier+"__" in file_name:
                            sorted_src_files.append([file_name,order_out+":"])
                            max_length_output = max(max_length_output,len(order_out)+1)
                elif inp.result_method == "TSV":
                    for file_name in extrapolated_list:
                        if "."+identifier+"__" in file_name:
                            sorted_src_files.append([file_name,order_out+":"])
                            max_length_output = max(max_length_output,len(order_out)+1)
                    for file_name in sorted_list:
                        if "."+identifier+"__" in file_name:
                            sorted_src_files.append([file_name,order_out+":"])
                            max_length_output = max(max_length_output,len(order_out)+1)
            out.print_result("Total rate (possibly within cuts):")
            for [file_name_orig,order_out] in sorted_src_files:
                if order_out.startswith("LO") or (order_out.startswith("NLO.EW ax+xa") and not prc.process_name in LO_photon_induced_processes):
                    out.print_result("-" * (max_length_output+58))
                file_src = pjoin(self.MATRIX_rates_folder[this_order], file_name_orig)
                #print(file_src)
                if phase == -1: # user cross sections from pre-run
                    central = self.pre_cross_section[this_order][file_src]["central"]
                    err = self.pre_cross_section[this_order][file_src]["err"]
                    up = self.pre_cross_section[this_order][file_src]["up"]
                    down = self.pre_cross_section[this_order][file_src]["down"]
                else:
                    central = self.cross_section[this_order][file_src]["central"]
                    err = self.cross_section[this_order][file_src]["err"]
                    up = self.cross_section[this_order][file_src]["up"]
                    down = self.cross_section[this_order][file_src]["down"]
                file_name = "rate_"+file_src.rsplit('/', 1)[1]
                size_central = len("0.0000001")
                size_err     = len("0.00001")
                #print(this_order,file_src,central,err)
                central_string = "%#.4g" % central
                err_string     = "%.2g" % err
                central_spaces = " "*(size_central-len(central_string))
                err_spaces     = " "*(size_err-len(err_string))
                if central == 0 or abs((up/central-1)*100) >= 10:
                    up_space = ""
                else:
                    up_space = " "
                if central == 0 or abs((down/central-1)*100) >= 10:
                    down_space = ""
                else:
                    down_space = " "
                if central != 0:
                    if (not ".extrapolated." in file_name_orig and file_name_orig.replace("plot.CV","plot.CV.extrapolated") in extrapolated_list) or ".rcut%s." % parameter_list["max_min_qTcut"] in file_name_orig:
                        out.print_result(order_out)
                        out.print_result(rcut_string+" " * (max_length_output-len(rcut_string))+central_spaces+central_string+" fb +/- "+err_string+" fb"+err_spaces+" (muR, muF unc.: "+up_space+"+%.1f%% " % abs((up/central-1)*100)+down_space+"-%.1f%%)" % abs((down/central-1)*100))
                    elif ".extrapolated." in file_name or file_name_orig.replace("plot.","plot.rcut%s." % parameter_list["max_min_qTcut"]) in extrapolated_list:
                        out.print_result(extrap_string+" " * (max_length_output-len(extrap_string))+central_spaces+central_string+" fb +/- "+err_string+" fb"+err_spaces+" (muR, muF unc.: "+up_space+"+%.1f%% " % abs((up/central-1)*100)+down_space+"-%.1f%%)" % abs((down/central-1)*100))
                    else:
                        out.print_result(order_out+" " * (max_length_output-len(order_out))+central_spaces+central_string+" fb +/- "+err_string+" fb"+err_spaces+" (muR, muF unc.: "+up_space+"+%.1f%% " % abs((up/central-1)*100)+down_space+"-%.1f%%)" % abs((down/central-1)*100))
                else:
                    out.print_result(order_out+" " * (max_length_output-len(order_out))+central_spaces+central_string+" fb +/- "+err_string+" fb"+err_spaces+" (muR, muF unc.: "+up_space+"+%.1f%% " % 0+down_space+"-%.1f%%)" % 0)
            out.print_result("-" * (max_length_output+58))
            if phase == -1:
                out.print_result("This result is very inaccurate and only a rough estimate!")
                out.print_result("Wait until the main run finishes to get the final result!")
            print("")
        # use the original output mode
        sys.stdout = original
#}}}
#{{{ def: submit_jobs(self,job_list)
    def submit_jobs(self,job_list):
        if self.runmode == "multicore":
            self.submit_jobs_local(job_list)
        elif self.runmode == "cluster":
#            self.submit_jobs_local(job_list)
            self.submit_jobs_cluster(job_list)
#}}}int 
#{{{ def: submit_jobs_local(self,job_list)
    def submit_jobs_local(self,job_list):
        # loop over jobs and add to process queue
        jobs = []
        prc_names = []

        for job in job_list:
            prc = multiprocessing.Process(target=self.job_process, args=(job,))
            jobs.append(prc)
            prc_names.append(prc.name)
        max_jobs = len(jobs)
        queued_jobs = max_jobs
        missing_jobs = max_jobs
        current_time  = str(datetime.datetime.now()).split('.')[0]
        # prints initial phase of jobs (all jobs queued)
        out.print_jobs("| %s | Queued: %s | Running: 0 | Finished: 0 |" % 
                       (current_time, queued_jobs))
        # Start the processes
        for prc in jobs:
            time_before = time.time()
            firsttime = True
            while (len(multiprocessing.active_children()) >= int(nr_cores) and int(nr_cores) != -1) or (self.runmode == "cluster" and cluster.get_jobs_in_cluster_queue() > int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"]) !=-1):
                time.sleep(600)
                time_now = time.time()
                # prints status every 5 minutes to show that script is alive
                # (important also for cluster mode, where not all jobs can always be started at once)
                if time_now - time_before >= parameter_list["print_out_interval"] or firsttime:
                    firsttime = False
                    if self.runmode == "cluster" and int(nr_cores) != -1 or (self.runmode == "cluster" and cluster.get_jobs_in_cluster_queue() > int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"]) !=-1):
                        queued_jobs   = missing_jobs+cluster.get_nr_of_cluster_jobs("pending")
                        running_jobs  = cluster.get_nr_of_cluster_jobs("running")
                        finished_jobs = max_jobs - queued_jobs - running_jobs
                        # print information why in this loop
                        if cluster.get_jobs_in_cluster_queue() > int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"]) !=-1:
                            out.print_info("Cluster queue full (%s jobs > max_jobs_in_cluster_queue=%s in MATRIX_configuration). Waiting for other jobs to finish..." % (cluster.get_jobs_in_cluster_queue(),config_list["max_jobs_in_cluster_queue"]))
                        elif len(multiprocessing.active_children()) >= nr_cores and int(nr_cores) != -1:
                            out.print_info("Submitted max_nr_parallel_jobs=%s (from MATRIX_configuration) jobs to cluster queue. Waiting for own jobs to finish..." % nr_cores)
                    current_time  = str(datetime.datetime.now()).split('.')[0]
                    out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" % 
                                   (current_time, queued_jobs, running_jobs, finished_jobs))
                    time_before = time_now
            # stop main program if one job produces an error
            prc.start() # start of each process
#            time.sleep(0.001)
            if self.runmode == "multicore": # only difference here is that not all submitted jobs are directly running
                queued_jobs   = queued_jobs - 1
                running_jobs  = len(multiprocessing.active_children())
                finished_jobs = max_jobs - queued_jobs - running_jobs
            elif self.runmode == "cluster":# and int(nr_cores) != -1 or (self.runmode == "cluster" and cluster.get_jobs_in_cluster_queue() > int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"]) !=-1):
#            elif self.runmode == "cluster":# and (int(nr_cores) != -1 or (cluster.get_jobs_in_cluster_queue() > int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"]) !=-1)):
                missing_jobs   = missing_jobs - 1
#                if queued_jobs+running_jobs != len(multiprocessing.active_children()): # this does not work always due to different timings I suppose, also not really important...
#                    out.print_warning("Sum of pending and running jobs does not add up to number of active jobs.")
                # if queued_jobs+running_jobs != cluster.get_nr_of_cluster_jobs("pending,running"): # this does not work always due to different timings I suppose, also not really important...
                #     out.print_warning("Sum of pending and running jobs does is not equal to all active jobs.")
            current_time  = str(datetime.datetime.now()).split('.')[0]
            # prints intermediate status, whenever jobs have been sent
            if len(multiprocessing.active_children()) >= nr_cores and int(nr_cores) != -1:
                if self.runmode == "cluster" and int(nr_cores) != -1:
                    queued_jobs   = missing_jobs+cluster.get_nr_of_cluster_jobs("pending")
                    running_jobs  = cluster.get_nr_of_cluster_jobs("running")
                    finished_jobs = max_jobs - queued_jobs - running_jobs
                out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" % 
                               (current_time, queued_jobs, running_jobs, finished_jobs))
        if self.runmode == "multicore": # only difference here is that not all submitted jobs are directly running
            running_jobs  = len(multiprocessing.active_children())
            finished_jobs = max_jobs - queued_jobs - running_jobs
        elif self.runmode == "cluster":
            queued_jobs   = missing_jobs+cluster.get_nr_of_cluster_jobs("pending")
            running_jobs  = cluster.get_nr_of_cluster_jobs("running")
            finished_jobs = max_jobs - queued_jobs - running_jobs
        running_jobs_before = running_jobs
        finished_jobs_before = finished_jobs
        time_before = time.time()
        firsttime = True
        # this whileloop waits that all jobs finish and prints out the number of queued/running/finished jobs from time to time
        while len(multiprocessing.active_children()) > 0:
            time.sleep(5)
            time_now = time.time()
            if self.runmode == "multicore": # only difference here is that not all submitted jobs are directly running
                running_jobs  = len(multiprocessing.active_children())
                finished_jobs = max_jobs - queued_jobs - running_jobs
            elif self.runmode == "cluster":
                queued_jobs   = cluster.get_nr_of_cluster_jobs("pending")
                running_jobs  = cluster.get_nr_of_cluster_jobs("running")
#                if queued_jobs+running_jobs != len(multiprocessing.active_children()): # this does not work always due to different timings I suppose, also not really important...
#                    out.print_warning("Sum of pending and running jobs does not add up to number of active jobs.")
#                if queued_jobs+running_jobs != cluster.get_nr_of_cluster_jobs("pending,running"): # this does not work always due to different timings I suppose, also not really important...
#                    out.print_warning("Sum of pending and running jobs does is not equal to all active jobs.")
            finished_jobs = max_jobs - queued_jobs - running_jobs
            if firsttime: # print out the status the first time in loop
            # simply assume that there are no finished jobs at the first printout (looks stupid otherwise if jobs are finished because of an error and then resubmitted
                if self.runmode == "cluster":
                    finished_jobs = 0
                    queued_jobs = max_jobs - running_jobs
                current_time  = str(datetime.datetime.now()).split('.')[0]
                out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" % 
                               (current_time, queued_jobs, running_jobs, finished_jobs))
                firsttime = False
            if running_jobs_before != running_jobs or finished_jobs_before != finished_jobs: # print out status whenever some jobs started or finished running
                # wait if these jobs failed and are resubmitted
#                print self.job_just_restarted()
#                if self.job_just_restarted():
                if self.runmode == "multicore": # only difference here is that not all submitted jobs are directly running
                    running_jobs  = len(multiprocessing.active_children())
                    finished_jobs = max_jobs - queued_jobs - running_jobs
                elif self.runmode == "cluster":
                    queued_jobs   = cluster.get_nr_of_cluster_jobs("pending")
                    running_jobs  = cluster.get_nr_of_cluster_jobs("running")
                    time.sleep(15)
                #    self.job_just_restarted_remove()
                if running_jobs_before != running_jobs or finished_jobs_before != finished_jobs: # print out status whenever some jobs started or finished running
                    current_time  = str(datetime.datetime.now()).split('.')[0]
                    out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" % 
                                   (current_time, queued_jobs, running_jobs, finished_jobs))
                    time_before = time_now
                    running_jobs_before = running_jobs
                    finished_jobs_before = finished_jobs
            if time_now - time_before >= parameter_list["print_out_interval"]: # print out status every time interval (hard coded at the beginning)
                current_time  = str(datetime.datetime.now()).split('.')[0]
                out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" % 
                               (current_time, queued_jobs, running_jobs, finished_jobs))
                time_before = time_now

        # Ensure all of the processes have finished
        for prc in jobs:
            while prc.exitcode is None:
                prc.join()
            if prc.exitcode > 0:
                self.errors_flag = True

        current_time  = str(datetime.datetime.now()).split('.')[0]
        # prints final phase of jobs (all jobs finished)
        out.print_jobs("| %s | Queued: 0 | Running: 0 | Finished: %s |" % 
                       (current_time, max_jobs))

        # check wether there are still active jobs
        if self.runmode == "cluster":
            folder_path = pjoin(fold.run_folder_path,"cluster","active_jobs")
            onlyfiles = [ f for f in os.listdir(folder_path) if os.path.isfile(pjoin(folder_path,f)) ]
            if onlyfiles:
                out.print_warning("Although run finished there appear to remain still active jobs, see folder: "+folder_path)
#}}}
#{{{ def: submit_jobs_cluster(self,job_list)
    def submit_jobs_cluster(self,job_list):
        # loop over jobs and add to process queue

        # first create a tarball if running locally on the nodes of the cluster
        if int(config_list.get("cluster_local_run",0)) > 0:
            fold.tar_run_folder()
        # create job dictionary to keep track of all jobs and its IDs to check which status they are and restart if necessary
        job_dict = {}
        should_not_be_running_and_not_correctly_finished = [] # list with job ids that should not be running anymore on cluster (either restarted or failed)

        max_jobs = len(job_list)
        queued_jobs = max_jobs
        missing_jobs = max_jobs
#{{{ initial printout
        current_time  = str(datetime.datetime.now()).split('.')[0]
        out.print_jobs("| %s | Queued: %s | Running: 0 | Finished: 0 |" % (current_time, queued_jobs))
#}}}
#{{{ initial submit of all jobs, including relevant printouts
        for job in job_list:
            time_before = time.time()
            firsttime = True
            while (self.runmode == "cluster" and cluster.get_jobs_in_cluster_queue() >= int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"]) !=-1):
                time.sleep(600)
                time_now = time.time()
                # prints status every 5 minutes to show that script is alive
                # (important also for cluster mode, where not all jobs can always be started at once)
                if time_now - time_before >= parameter_list["print_out_interval"] or firsttime:
                    firsttime = False
                    if self.runmode == "cluster" and int(nr_cores) != -1 or (self.runmode == "cluster" and cluster.get_jobs_in_cluster_queue() >= int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"]) !=-1):
                        queued_jobs   = missing_jobs+cluster.get_nr_of_cluster_jobs("pending")
                        running_jobs  = cluster.get_nr_of_cluster_jobs("running")
                        finished_jobs = max_jobs - queued_jobs - running_jobs
                        # print information while in this loop
                        if cluster.get_jobs_in_cluster_queue() >= int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"]) !=-1:
                            out.print_info("Cluster queue full (%s jobs > max_jobs_in_cluster_queue=%s in MATRIX_configuration). Waiting for other jobs to finish..." % (cluster.get_jobs_in_cluster_queue(),config_list["max_jobs_in_cluster_queue"]))
                        elif len(multiprocessing.active_children()) >= nr_cores and int(nr_cores) != -1:
                            out.print_info("Submitted max_nr_parallel_jobs=%s (from MATRIX_configuration) jobs to cluster queue. Waiting for own jobs to finish..." % nr_cores)
                    current_time  = str(datetime.datetime.now()).split('.')[0]
                    # out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" %
                    #                (current_time, queued_jobs, running_jobs, finished_jobs))
                    time_before = time_now
            nr_of_tries = 1 
            job_id, start_time = self.start_job_on_cluster(job,nr_of_tries)
            current_time  = str(datetime.datetime.now()).split('.')[0]
            self.write_job_log_start(job[0],job[1],"started at %s ..."%(current_time))
            job_dict[job_id] = job+[nr_of_tries,start_time]
            missing_jobs   = missing_jobs - 1
        queued_jobs_before   = missing_jobs+cluster.get_nr_of_cluster_jobs("pending")
        running_jobs_before  = cluster.get_nr_of_cluster_jobs("running")
        finished_jobs_before = max_jobs - queued_jobs_before - running_jobs_before
        time_before = time.time()
        firsttime = True
#}}}
#{{{ monitor all jobs, take action if they finished, failes, etc.
        time_before = time.time()
        while job_dict: # this whileloop waits until all jobs finish and prints out the number of queued/running/finished jobs from time to time
            # check all jobs every 2 minutes
            if time.time() - time_before >= parameter_list["check_interval"] or (queued_jobs == 0 and running_jobs == 0) or (running_jobs_before != cluster.get_nr_of_cluster_jobs("running")):
                time_before = time.time()
                for job_id in should_not_be_running_and_not_correctly_finished:
                    if not cluster.cluster_job_finished(job_id):
                        cluster.cluster_job_remove(job_id) # removes from active jobs and add to finished job list
                        out.print_warning("Killed ghost job (job_id: %s) which should not be running as it has already been restarted or finally failed." % job_id)
                # go through job list and check which job have finished, failed, etc. and need to be removed from the list, need to be restarted, etc.
                job_dict_copy = copy.copy(job_dict)
                try:
                    job_dict_copy_iteritems = job_dict_copy.iteritems() # python 2
                except:
                    job_dict_copy_iteritems = iter(job_dict_copy.items()) # python 3
                for job_id, job in job_dict_copy_iteritems:
                    run_path = job[0]
                    process  = job[1]
                    cluster_job_finished = False
                    job_correctly_finished = False

                    if cluster.cluster_job_finished(job_id):
                        cluster_job_finished = True
                        if self.job_correctly_finished(run_path,process):
                            job_correctly_finished = True
                        else:
                            time.sleep(30)
                            if cluster.cluster_job_finished(job_id): # check again if this job really does not exist anymore
                              if self.job_correctly_finished(run_path,process): # make sure job has not correctly finished in meanwhile
                                job_correctly_finished = True
                            else:
                              cluster_job_finished = False

                    if cluster_job_finished or job_correctly_finished:
                        del job_dict[job_id]
                        print(f"Length of job_dict: {len(job_dict)}")
                        run_path    = job[0]
                        process     = job[1]
                        nr_of_tries = job[2]
                        start_time  = job[3]
                        m, s = divmod(time.time()-start_time, 60)
                        h, m = divmod(m, 60)
                        if job_correctly_finished:
                            # remove logs
                            cluster.remove_job_from_folder(job_id,"active_jobs") # remove job from active jobs
                            cluster.add_job_id_to_list(job_id,"job_ids_finished.list") # add job to finished job list
                            # write that job successfully finished into log file (with tries and time) and final line
                            self.write_job_log(run_path,process,"try %s successfully finished after %dh:%02dm:%02ds"%(nr_of_tries, h, m, s))
                            current_time  = str(datetime.datetime.now()).split('.')[0]
                            self.write_job_log_finish(run_path,process,"...success %s"%(current_time))
                            # try to remove from list of failed jobs (can happen when job was restarted)
                            try:
                                self.remove_job_failed_log(run_path,process)
                            except: 
                                pass
                            # add job to log of list of succseffully finished jobs
                            self.add_job_success_log(run_path,process)
                        else:
                            job_id_old = job_id
                            should_not_be_running_and_not_correctly_finished.append(job_id)
                            # write that try failed
                            self.write_job_log(run_path,process,"try %s failed after %dh:%02dm:%02ds"%(nr_of_tries, h, m, s))
                            if nr_of_tries < self.max_nr_of_tries:
                                while (cluster.get_jobs_in_cluster_queue() >= int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"]) !=-1):
                                    time.sleep(600)
                                    time_now = time.time()
                                    # prints status every 5 minutes to show that script is alive
                                    if time_now - time_before >= parameter_list["print_out_interval"]:
                                        if cluster.get_jobs_in_cluster_queue() >= int(config_list["max_jobs_in_cluster_queue"]) and int(config_list["max_jobs_in_cluster_queue"] !=-1):
                                            queued_jobs   = missing_jobs+cluster.get_nr_of_cluster_jobs("pending")
                                            running_jobs  = cluster.get_nr_of_cluster_jobs("running")
                                            finished_jobs = max_jobs - queued_jobs - running_jobs
                                            out.print_info("Cluster queue full (%s jobs > max_jobs_in_cluster_queue=%s in MATRIX_configuration). Waiting for other jobs to finish..." % (cluster.get_jobs_in_cluster_queue(),config_list["max_jobs_in_cluster_queue"]))
                                        current_time  = str(datetime.datetime.now()).split('.')[0]
                                        out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" %
                                                       (current_time, queued_jobs, running_jobs, finished_jobs))
                                        time_before = time_now
                                out.print_warning("Job%s failed; path: %s, channel: %s. Re-trying with different random seed..." % (" (ID %s)" % job_id if self.runmode == "cluster" else "",run_path,process))
                                # change random seed of run
                                try: # normal runs
                                    parallel_folder_i = int(run_path.rsplit(".",1)[1])
                                    run_dirs_in_path = [ f for f in os.listdir(run_path.rsplit('/', 1)[0]) if f.startswith("run.") and os.path.isdir(pjoin(run_path.rsplit('/', 1)[0],f)) ]
                                    max_parallel_runs = int(len(run_dirs_in_path)) # result combination now uses always all folders which are there
                                    zwahl = max_parallel_runs*(nr_of_tries)+parallel_folder_i
                                except: # grid runs
                                    zwahl = randint(10,5000)
                                # adding max_parallel_runs makes sure there is no overlapping in random seed with the other runs; 
                                # NOTE (2do:?) there could be a overlapping between extrapolation and main run, but what do you want?
                                param_file_path = pjoin(run_path,"log","file_parameter."+process+".dat")
                                inp.input_set_entry(param_file_path,"zwahl",str(zwahl))
                                # save jobs that were restarted to a file which is printed at the end:
                                log.add_to_list("restarted_list.log",pjoin(run_path,"log",process+"_try"+str(nr_of_tries)+".log"))
                                # restart job
                                job_id, start_time = self.start_job_on_cluster(job,nr_of_tries+1)
                                job_dict[job_id] = job
                                job_dict[job_id][2] = nr_of_tries+1
                                job_dict[job_id][3] = start_time
                            else:
                                current_time  = str(datetime.datetime.now()).split('.')[0]
                                self.write_job_log_finish(run_path,process,"... failed %s"%(current_time))
                                # try to remove from list of successful jobs (can happen when successful job was restarted)
                                try:
                                    self.remove_job_success_log(run_path,process)
                                except: 
                                    pass
                                self.add_job_failed_log(run_path,process)
                            cluster.cluster_job_remove(job_id_old) # removes from active jobs and add to finished job list
#}}}
#{{{ print out job info if at first time, if things change, or every time interval
            # delay while loop
            time.sleep(parameter_list["check_interval"])  # needed for nikhef cluster to not overload the nr of condor_q calls
            time_now = time.time()
            queued_jobs   = cluster.get_nr_of_cluster_jobs("pending")
            running_jobs  = cluster.get_nr_of_cluster_jobs("running")
            finished_jobs = max_jobs - queued_jobs - running_jobs
            if firsttime: # print out the status the first time in loop
                # simply assume that there are no finished jobs at the first printout (looks stupid otherwise if jobs are finished because of an error and then resubmitted
                finished_jobs = 0
                queued_jobs = max_jobs - running_jobs
                current_time  = str(datetime.datetime.now()).split('.')[0]
                out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" % 
                               (current_time, queued_jobs, running_jobs, finished_jobs))
                firsttime = False
            if running_jobs_before != running_jobs or finished_jobs_before != finished_jobs: # print out status whenever some jobs started or finished running
                # wait if these jobs failed and are resubmitted
                time.sleep(15)
                queued_jobs   = cluster.get_nr_of_cluster_jobs("pending")
                running_jobs  = cluster.get_nr_of_cluster_jobs("running")
                if running_jobs_before != running_jobs or finished_jobs_before != finished_jobs: # print out status whenever some jobs started or finished running
                    current_time  = str(datetime.datetime.now()).split('.')[0]
                    out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" % 
                                   (current_time, queued_jobs, running_jobs, finished_jobs))
                    time_before = time_now
                    running_jobs_before = running_jobs
                    finished_jobs_before = finished_jobs
            if time_now - time_before >= parameter_list["print_out_interval"]: # print out status every time interval (set by default or as input from parameter.dat)
                current_time  = str(datetime.datetime.now()).split('.')[0]
                out.print_jobs("| %s | Queued: %s | Running: %s | Finished: %s |" % 
                               (current_time, queued_jobs, running_jobs, finished_jobs))
                time_before = time_now
#}}}
#{{{ final printout
        current_time  = str(datetime.datetime.now()).split('.')[0]
        out.print_jobs("| %s | Queued: 0 | Running: 0 | Finished: %s |" % 
                       (current_time, max_jobs))
#}}}
#{{{ check if there appear to be active jobs
        folder_path = pjoin(fold.run_folder_path,"cluster","active_jobs")
        onlyfiles = [ f for f in os.listdir(folder_path) if os.path.isfile(pjoin(folder_path,f)) ]
        if onlyfiles:
            out.print_warning("Although run finished there appear to remain still active jobs, see folder: "+folder_path)
#}}}

#}}}
#{{{ def: job_process(self,run_info)
    def job_process(self,run_info):
    # job process specified by folder structure, to be run in specified mode
    # here the execution of the code is actually done        
    # determines how often job is restarted in order to correctly finish ("final result" in execution folder)
      max_nr_of_tries = run_class.max_nr_of_tries # set (hard-coded) in initilisation
      nr_of_tries = 1
      # this is for the final run where all results are collected and combined
      if run_info[0].startswith("infile.") or run_info[0].startswith("infile.distribution"):
#{{{
          results_combination_file = run_info[0]
          results_type = run_info[1] # "result" for total rates or "distribution" for distributions
          try:
              scale_variation_file = run_info[2]
          except:
              scale_variation_file = ""
              pass
          results_path = pjoin(process_dir,run_folder,"result")
          # switch directory to result_path
          os.chdir(results_path)
          # set path of ouput file (standard screen output)
          subprocess_out_path = pjoin(results_path,run_info[0]+"."+results_type+".log")
          # set path of error file (error screen output)
#          subprocess_err_path = pjoin(results_path,run_info[0]+"."+results_type+".err")
          with open(subprocess_out_path,'w+') as subprocess_out:
#              with open(subprocess_err_path,'w+') as subprocess_err:
                  # save start_time to compute difference to finishing time and print into log how long the jobs take
                  start_time = time.time()
                  # determine current_time in convenient format to print it as starting time in log
                  current_time  = str(datetime.datetime.now()).split('.')[0]

                  # also here: supplement with cluster mode
                  if self.runmode == "multicore":
                      env = copy.copy(os.environ)
                      env["LIBC_FATAL_STDERR_"] = "1"
                      if scale_variation_file:
                          if python3:
                              p = subprocess.Popen([fold.exe_path,results_type,results_combination_file,scale_variation_file], stdout=subprocess_out, stderr=subprocess_out, env=env)
                          else:
                              p = subprocess.Popen([fold.exe_path,results_type,results_combination_file,scale_variation_file], stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)
                      else:
                          if python3:
                              p = subprocess.Popen([fold.exe_path,results_type,results_combination_file], stdout=subprocess_out, stderr=subprocess_out, env=env)
                          else:
                              p = subprocess.Popen([fold.exe_path,results_type,results_combination_file], stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)
                      signal.signal(signal.SIGINT,self.control_c_handler_child)
                  elif self.runmode == "cluster":
                      # this submits the job to the cluster, returns the job_id, writes the job_id to a file and saves the batch file
                      dummy = ""
                      # use the same routine as for the usual run jobs so that the batchfile has the same structure
                      time_before_first_submit = time.time()
                      job_id = cluster.cluster_job_submit(results_combination_file,results_type,dummy,subprocess_out_path,subprocess_out_path)
                      signal.signal(signal.SIGINT,self.control_c_handler_child)
                      while job_id == "resubmit":
                          job_id = cluster.cluster_job_submit(results_combination_file,results_type,dummy,subprocess_out_path,subprocess_out_path)
                          signal.signal(signal.SIGINT,self.control_c_handler_child)
                          if time.time() - time_before_first_submit > 600:
                              out.print_error("There seems to be a problem with the submission to the cluster. Job could not be submitted within 10 minutes, while re-submitting every minute. Please stop the code and solve the issue...")
                  stdout = []
                  stderr = []
                  while True:
                      if self.runmode == "multicore" and not python3: # this only works properly with python2
                          reads = [p.stdout.fileno(), p.stderr.fileno()]
                          ret = select.select(reads, [], [])
                  
                          for fd in ret[0]:
                              if fd == p.stdout.fileno():
                                  #try:
                                  #    read = p.stdout.readline().rstrip('\n')
                                  #except:
                                read = p.stdout.readline().decode('utf8').rstrip('\n')
                                  #try:
                                  #    print >>subprocess_out, "%s" % read
                                  #except:
                                subprocess_out.write("%s\n" % read)
                                subprocess_out.flush()
                              if fd == p.stderr.fileno():
                                  #try:
                                  #    read = p.stderr.readline().rstrip('\n')
                                  #except:
                                read = p.stderr.readline().decode('utf8').rstrip('\n')
                                  #try:
                                  #    print >>subprocess_out, "%s" % read
                                  #except:
                                subprocess_out.write("%s\n" % read)
                                subprocess_out.flush()
                      # this somehow (poll) checks wether the job p.subprocess finished, as long as it does not
                      # the script remains in the while loop, once it finished the while loop "break"s
#SD old version
#                      if self.runmode == "multicore" and p.poll() != None: 
#                         break # stops while loop because job finished      
                      if self.runmode == "multicore":
                          # don't use poll, it will utilize an entire CPU at 100% because poll returns immediately
                          try:
                              # it's probably possible to replace the outer loop with a single wait statement without timeout
                              p.wait(1)
                              # stops while loop because job finished
                              break
                          except subprocess.TimeoutExpired:
                              pass 

                      if self.runmode == "cluster" and cluster.cluster_job_finished(job_id):
                          time.sleep(1)
                          if cluster.cluster_job_finished(job_id):
                              time.sleep(1)
                              # if cluster.cluster_job_finished(job_id):
                              #     time.sleep(2)
                              if cluster.cluster_job_finished(job_id):
                                  cluster.remove_job_from_folder(job_id,"active_jobs") # remove job from active jobs
                                  cluster.add_job_id_to_list(job_id,"job_ids_finished.list") # add job to finished job list
                                  break
                      elif self.runmode == "cluster":
                          time.sleep(30)

#}}}
      # this is for the warmup and mainrun, when program runs in multicore or cluster mode
      elif self.runmode == "multicore" or self.runmode == "cluster":
#{{{
          run_path = run_info[0]
# hack until QCD works in EW executable
          process = run_info[1]
          # switch directory to run_path
          os.chdir(run_path)
        
          while nr_of_tries <= max_nr_of_tries:
              # set path of inut file
              subprocess_in_path = pjoin(run_path,"log",process+".in")
              # set path of ouput file (standard screen output)
              subprocess_out_path = pjoin(run_path,"log",process+"_try"+str(nr_of_tries)+".log")
              # set path of error file (error screen output)
#              subprocess_err_path = pjoin(run_path,"log",process+"_try"+str(nr_of_tries)+".err")
              with self.fileopen(subprocess_in_path,'r') as subprocess_in: # only opened in multicore mode
               with self.fileopen(subprocess_out_path,'w+') as subprocess_out: # only opened in multicore mode
#                with self.fileopen(subprocess_err_path,'w+') as subprocess_err: # only opened in multicore mode
                  # save start_time to compute difference to finishing time and print into log how long the jobs take
                  start_time = time.time()
                  finished_check_time   = start_time # needed to do additional check if run correctly finished every two minutes
                  finished_check_time_2 = start_time # needed to redo additional check if run correctly finished after 15 minutes
                  first_check = True
                  # determine current_time in convenient format to print it as starting time in log
                  current_time  = str(datetime.datetime.now()).split('.')[0]
                  if nr_of_tries == 1:
                      self.write_job_log_start(run_path,process,"started at %s ..."%(current_time))

                  if self.runmode == "multicore":
                      env = copy.copy(os.environ)
                      env["LIBC_FATAL_STDERR_"] = "1"
                      if python3:
                          p = subprocess.Popen(fold.exe_path, stdin=subprocess_in, stdout=subprocess_out, stderr=subprocess_out, env=env)
                      else:
                          p = subprocess.Popen(fold.exe_path, stdin=subprocess_in, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)
                      signal.signal(signal.SIGINT,self.control_c_handler_child)
                  elif self.runmode == "cluster":
                      # this submits the job to the cluster, returns the job_id, writes the job_id to a file and saves the batch file
                      time_before_first_submit = time.time()
                      job_id = cluster.cluster_job_submit(run_path,process,subprocess_in_path,subprocess_out_path,subprocess_out_path)
                      signal.signal(signal.SIGINT,self.control_c_handler_child)            
                      while job_id == "resubmit":
                          job_id = cluster.cluster_job_submit(run_path,process,subprocess_in_path,subprocess_out_path,subprocess_out_path)
                          signal.signal(signal.SIGINT,self.control_c_handler_child)
                          if time.time() - time_before_first_submit > 120:
                              out.print_error("There seems to be a problem with the submission to the cluster. Job could not be submitted within 2 minutes, while re-submitting every 15 seconds. Please stop the code and solve the issue...")
                              
                      
                  stdout = []
                  stderr = []
                  checks_done = False
                  while True:
                      if self.runmode == "multicore" and not python3: # this only works properly with python2
                          reads = [p.stdout.fileno(), p.stderr.fileno()]
                          ret = select.select(reads, [], [])
                  
                          for fd in ret[0]:
                              if fd == p.stdout.fileno():
                                  try:
                                      read = p.stdout.readline().rstrip('\n')
                                  except:
                                      read = p.stdout.readline().decode('utf8').rstrip('\n')
                                  try:
                                      print >>subprocess_out, "%s" % read
                                  except:
                                      subprocess_out.write("%s\n" % read)
                                  subprocess_out.flush()
                              if fd == p.stderr.fileno():
                                  #try:
                                  #    read = p.stderr.readline().rstrip('\n')
                                  #except:
                                read = p.stderr.readline().decode('utf8').rstrip('\n')
                                  #try:
                                  #    print >>subprocess_out, "%s" % read
                                  #except:
                                subprocess_out.write("%s\n" % read)
                                subprocess_out.flush()

                      # after 30 seconds do some checks on log file, kill and restart if there is a problem
                      if abs(time.time()-start_time)>60 and not checks_done: # I don't think these checks are still relevant, and only produce problems
                          # BUT: we still need the check_done signal, to set the right starting time
                          # check 1: see wether the log file is full of errors (>1000 errors)
                          # if self.log_full_of_errors(subprocess_out_path):
                          #     if self.runmode == "multicore":
                          #         p.kill()
                          #     elif self.runmode == "cluster":
                          #         cluster.cluster_job_remove(job_id)
                          #     out.print_warning("Job %s produced a bunch of errors, restarting job..."%(run_path+">>"+process))
                          #     break
                          # check 2: see wether at end of log file has specific keywod(eg, "n_original = 2")
                          # if self.log_keyword_end_of_file(subprocess_out_path,"n_original = 2"):
                          #     if self.runmode == "multicore":
                          #         p.kill()
                          #     elif self.runmode == "cluster":
                          #         cluster.cluster_job_remove(job_id)
                          #     out.print_warning("Job %s did not coninue (XXX at end of file), restarting job..."%(run_path+">>"+process))
                          #     break
                          checks_done = True
                      # this somehow (poll) checks wether the job p.subprocess finished, as long as it does not
                      # the script remains in the while loop, once it finished the while loop "break"s
                      #SD Old version
                      #if self.runmode == "multicore" and p.poll() != None:
                      #     break # stops while loop because job finished
                      if self.runmode == "multicore":
                          # don't use poll, it will utilize an entire CPU at 100% because poll returns immediately
                          try:
                              # it's probably possible to replace the outer loop with a single wait statement without timeout
                              p.wait(1)
                              # stops while loop because job finished
                              break
                          except subprocess.TimeoutExpired:
                              pass 
                      if self.runmode == "cluster" and cluster.cluster_job_finished(job_id):
                          time.sleep(1)
                          if cluster.cluster_job_finished(job_id):
                              time.sleep(1)
#                              if cluster.cluster_job_finished(job_id):
#                                  time.sleep(2)
                              if cluster.cluster_job_finished(job_id):
                                  cluster.remove_job_from_folder(job_id,"active_jobs") # remove job from active jobs
                                  cluster.add_job_id_to_list(job_id,"job_ids_finished.list") # add job to finished job list
                                  break
                      elif self.runmode == "cluster":
                          # in cluster runs count the time from when the job has started running (otherwise there is no log file for the checks)
                          if self.runmode == "cluster" and not cluster.cluster_job_running(job_id) and not checks_done:
                              start_time = time.time() # as long as the job is not running reset the time
                          # this is the time in seconds how often the python jobs check wether the cluster job is finished
                          time.sleep(60)
                          # sometime job continues running even though it already finished its output, in this case kill the job and break the loop
                          if abs(time.time()-finished_check_time) > 120: # check every two minutes
                              if self.job_correctly_finished(run_path,process):
                                  # only print if it still not finished after 15 Minutes
                                  if first_check:
                                      finished_check_time_2 = time.time()
                                      first_check = False
#                                      out.print_warning("This is when it was discovered (ID %s) it first %s" % (job_id,str(datetime.datetime.now()).split('.')[0]))
                                  elif abs(time.time()-finished_check_time_2) > 300: # check after 5 Minutes again
#                                      out.print_warning("Run finished, but ID=%s still running on cluster. TIME: %s" % (job_id,str(datetime.datetime.now()).split('.')[0]))
                                      finished_check_time_2 = time.time()
#                                  cluster.cluster_job_remove(job_id)
#                                  break
                                  finished_check_time = time.time()
                              else:
                                  finished_check_time = time.time()
                  # this checks wether finished job has produced correct results ("final result" in execution folder)
                  if self.job_correctly_finished(run_path,process):
                      m, s = divmod(time.time()-start_time, 60)
                      h, m = divmod(m, 60)
                      # write that job successfully finished into log file (with tries and time)
                      self.write_job_log(run_path,process,"try %s successfully finished after %dh:%02dm:%02ds"%(nr_of_tries, h, m, s))
                      # try to remove from list of failed jobs (can happen when job was restarted)
                      try:
                          self.remove_job_failed_log(run_path,process)
                      except: 
                          pass
                      # add job to log of list of succseffully finished jobs
                      self.add_job_success_log(run_path,process)
                      break # stops while loop because finished job did produce correct results
                  # otherwise restart job, increase number of tries and print failed try into log
                  else:
#                      print job_id+" restarted"
#                      self.job_just_restarted_add()
                      m, s = divmod(time.time()-start_time, 60)
                      h, m = divmod(m, 60)
                      self.write_job_log(run_path,process,"try %s failed after %dh:%02dm:%02ds"%(nr_of_tries, h, m, s))
                      # if nr_of_tries > max_nr_of_tries/2: 
#                      exit()
                      #     time.sleep(5)
                      nr_of_tries += 1 # job will be restarted, therefore number of tries increased
                      # write that an error occured in this run
                      out.print_warning("Job%s failed; path: %s, channel: %s. Re-trying with different random seed..." % (" (ID %s)" % job_id if self.runmode == "cluster" else "",run_path,process))
                      # change random seed of run
                      try: # normal runs
                          param_file_path = pjoin(run_path,"log","file_parameter."+process+".dat")
                          parallel_folder_i = int(run_path.rsplit(".",1)[1])
                          run_dirs_in_path = [ f for f in os.listdir(run_path.rsplit('/', 1)[0]) if f.startswith("run.") and os.path.isdir(pjoin(run_path.rsplit('/', 1)[0],f)) ]
                          max_parallel_runs = int(len(run_dirs_in_path)) # result combination now uses always all folders which are there
                          zwahl = int(parameter_list.get("random_seed","0"))+max_parallel_runs*(nr_of_tries-1)+parallel_folder_i
                      except: # grid runs
                          param_file_path = pjoin(run_path,"log","file_parameter."+process+".dat")
                          zwahl = int(parameter_list.get("random_seed","0"))++randint(10,5000)
                      # adding max_parallel_runs makes sure there is no overlapping in random seed with the other runs; 
                      # NOTE (2do:?) there could be a overlapping between extrapolation and main run, but what do you want?
                      inp.input_set_entry(param_file_path,"zwahl",str(zwahl))
                      # save jobs that were restarted to a file which is printed at the end:
                      log.add_to_list("restarted_list.log",subprocess_out_path)
          # in case after all tries job still failed to produce correct results, add information to logs
          if nr_of_tries > max_nr_of_tries:
              current_time  = str(datetime.datetime.now()).split('.')[0]
              self.write_job_log_finish(run_path,process,"... failed %s"%(current_time))
              # try to remove from list of successful jobs (can happen when successful job was restarted)
              try:
                  self.remove_job_success_log(run_path,process)
              except: 
                  pass
              self.add_job_failed_log(run_path,process)
          # if one try succeeded add final line to log
          else:
              current_time  = str(datetime.datetime.now()).split('.')[0]
              self.write_job_log_finish(run_path,process,"...success %s"%(current_time))
      else:
        out.print_error("Runmode \"%s\" is not known, cannot submit processes" % self.runmode)
#}}}
#}}}
#{{{ def: start_job_on_cluster(self,run_info)
    def start_job_on_cluster(self,run_info,nr_of_tries):
    # execution of code done here by submitting jobs to cluster
        # submission for result run (not used as result run is done only locally currently)
        if run_info[0].startswith("infile.") or run_info[0].startswith("infile.distribution"):
#{{{
            results_combination_file = run_info[0]
            results_type = run_info[1] # "result" for total rates or "distribution" for distributions
            results_path = pjoin(process_dir,run_folder,"result")
            os.chdir(results_path) # switch directory to result_path
            subprocess_out_path = pjoin(results_path,run_info[0]+"."+results_type+".log") # set path of ouput file (standard screen output)
            # this submits the job to the cluster, returns the job_id, writes the job_id to a file and saves the batch file
            dummy = ""
            # use the same routine as for the usual run jobs so that the batchfile has the same structure
            time_before_first_submit = time.time()
            job_id = cluster.cluster_job_submit(results_combination_file,results_type,dummy,subprocess_out_path,subprocess_out_path)
            while job_id == "resubmit":
                job_id = cluster.cluster_job_submit(results_combination_file,results_type,dummy,subprocess_out_path,subprocess_out_path)
                if time.time() - time_before_first_submit > 600:
                    out.print_error("There seems to be a problem with the submission to the cluster. Job could not be submitted within 10 minutes, while re-submitting every minute. Please stop the code and solve the issue...")
            start_time = time.time()
#}}}
        # submission for the warmup, pre and mainrun, when program runs in multicore or cluster mode
        elif self.runmode == "multicore" or self.runmode == "cluster":
#{{{
            run_path = run_info[0]
            process = run_info[1]
            os.chdir(run_path) # switch directory to run_path
            subprocess_in_path = pjoin(run_path,"log",process+".in") # path of input file
            subprocess_out_path = pjoin(run_path,"log",process+"_try"+str(nr_of_tries)+".log") # path of ouput file (standard screen output)
            time_before_first_submit = time.time()
            job_id = cluster.cluster_job_submit(run_path,process,subprocess_in_path,subprocess_out_path,subprocess_out_path)
            while job_id == "resubmit":
                job_id = cluster.cluster_job_submit(run_path,process,subprocess_in_path,subprocess_out_path,subprocess_out_path)
                if time.time() - time_before_first_submit > 120:
                    out.print_error("There seems to be a problem with the submission to the cluster. Job could not be submitted within 2 minutes, while re-submitting every 15 seconds. Please stop the code and solve the issue...")
            start_time = time.time()
#}}}
        else:
            out.print_error("Runmode \"%s\" is not known, cannot submit processes" % self.runmode)
        return job_id, start_time
#}}}
#{{{ def: get_parallel_pre_runs_for_contribution(self,run_dir)
    def get_parallel_pre_runs_for_contribution(self,run_dir):
    # this function returns the number of parallel jobs for the extrapolation run
        parallel = self.min_parallel_pre_run # default for ALL contributions
        # now change if specified for specific contribution
        try:
            settings = pre_run_settings[prc.process_name]
        except:
            settings = pre_run_settings["default"]
            pass
        for contribution in settings:
            if contribution in run_dir.rsplit('/',2)[1] and not "%s/LO/" % fold.run_folder_path in run_dir: # exclude LO from making prerun more parallel
                parallel = max(settings[contribution][0],parallel)
                if int(nr_cores) != -1 and nr_cores < parallel: # it makes no sense to parallelize higher than max_number of available cores (note: nr_cores = max_nr_parallel_jobs)
                    run_dir_up = run_dir.rsplit("/",1)[0]
                    if not run_dir_up in self.pre_parallel_printed:
                        if "NNLO" in self.order:
                            out.print_info("max_nr_parallel_jobs (in multicore: cores of machine) from MATRIX_configuration is %s, which is smaller than required parallelization (channel: %s; number of jobs for this channel: %s) for max_time_per_job in parameter.dat. Limiting the parallelization to max_nr_parallel_jobs... (max_time_per_job will not be met)" % (nr_cores,run_dir_up,parallel))
                            self.pre_parallel_printed.append(run_dir_up)
                    parallel = min(parallel,nr_cores)
        return parallel
#}}}
#{{{ def: get_pre_run_min_events_for_contribution(self,run_dir):
    def get_pre_run_min_events_for_contribution(self,run_dir):
    # this function returns the number of overall events for the extrapolation run
        min_events = self.min_events_per_channel # default for ALL contributions
        # now change if specified for specific contribution
        try:
            settings = pre_run_settings[prc.process_name]
        except:
            settings = pre_run_settings["default"]
            pass
        for contribution in settings:
            if contribution in run_dir and not "%s/LO/" % fold.run_folder_path in run_dir:
                min_events = settings[contribution][1]
        return min_events
#}}}
#{{{ def: get_lowest_index_of_run_folder_to_include_inside_path(self,path)
    def get_lowest_index_of_run_folder_to_include_inside_path(self,path,max_parallel_runs):
    # this function determines whether the pre_run is included in result combination and returns integer X of first run.X folder to be included
        # in case the number of events of all extrapolation events is 100 times smaller than the events in a single main run folder exclude them
        start_folder_index = 0
        run_dir_0 = pjoin(path,"run.0")
        pre_events   = self.get_pre_run_min_events_for_contribution(run_dir_0)
        parameter_files = []
        main_dirs = fold.get_dirs_with_identifier(path,"main")
        for main_dir in main_dirs:
            parameter_files += glob.iglob(pjoin(main_dir,"log","file_parameter*"))
        event_sum_main = 0
        for parameter_file in list(parameter_files):
            parameter = {}
            inp.input_read_parameter_dat(parameter_file,parameter)
            event_sum_main += float(parameter.get("n_events_min",0))
        # since we computed the sum of events for this contribution here, save it to the log for the final summary
        if event_sum_main > 0: # make sure to only include contributions where events were run (otherwise we will end up with logs of contributions that were not run)
            log.summary_add_events(event_sum_main,path)
        if event_sum_main/pre_events > 500:
            start_folder_index = max_parallel_runs - len(main_dirs)
        if start_folder_index >= max_parallel_runs:
            start_folder_index = 0 # to avoid that the directory gets removed from the file
            max_parallel_runs = 1 # to avoid that the directory gets removed from the file
        # use pre-defined switch if set
        if "include_pre_in_results" in parameter_list and len(main_dirs)>0:
            if parameter_list["include_pre_in_results"] == "0": # take only main runs into account (not in extrapolation phase=-1)
                start_folder_index = max_parallel_runs - len(main_dirs)
            elif parameter_list["include_pre_in_results"] == "1": # take also all pre runs into account
                start_folder_index = 0
            else:
                out.print_error("Parameter \"include_pre_in_results\" in parameter.dat can only have values \"0\" and \"1\", give value: %s." % parameter_list["include_pre_in_results"])
        return start_folder_index
#}}}
#{{{ def: read_runtimes(self)
    def read_runtimes(self):
    # this function reads out the results of the extrapolation runs and saves 
    # in the class-intern multidimensional dictionary depending on the run_dir+channel:         
        # hard-coded parameters for extrapolation that might be adjusted with experience:
        # minimal number of events per channel
#        self.min_events_per_channel = 50000 # set in class initialization
        # minimal number of parallelizations per channel (at least 2 if one goes wrong)
#        self.min_parallel_per_channel = 1 # set in class initialization
        # arbitrary factor that determines number of printouts
        factor1 = 2
        # arbitrary factor that determines maximal number of events (from minimal number of events)
        factor2 = 2
        # arbitray that reduces the max_time_per_job, for factor_max_time = 1 the jobs take 2-3 times longer than expected
        factor_max_time = 2.5
        # correction factor for estimated runtimes, dependending on contribution (has exactly the same effect as factor_max_time, but chosen specific to the contribution)
        factor_runtime = {}
        # factor_runtime["VT2"] = 2
        # factor_runtime["RVA"] = 2
        # Make sure in continued run you use the runtime.dat of the pre run (not of the main run) in cases
        # where the runtime.dat of the main run has already created (in that case runtime.dat of pre run was 
        # moved to runtime_pre_run.dat
        if continue_run:
            runtime_file_path = pjoin(fold.run_folder_path,"result","runtime_pre_run.dat")
            if not os.path.isfile(runtime_file_path):
                runtime_file_path = pjoin(fold.run_folder_path,"result","runtime.dat")
        else:
            runtime_file_path = pjoin(fold.run_folder_path,"result","runtime.dat")
        parallelization_file_path = pjoin(fold.log_folder_path,"parallelization.log")
        if not os.path.isfile(runtime_file_path):
            out.print_warning("File "+runtime_file_path+" in function read_runtimes does not exist! Trying to get runtimes from existing pre_run...")
            if self.pre_run_complete():
                self.extrapolate_runtimes()
            else:
                out.print_error_no_stop("There is no complete pre run! Please restart from pre run.")
                out.print_error_no_stop("The following pre runs have no \"final result\" in the execution file:")
                out.print_list(run.failed_run_list,"error")
                exit(0)
        with open(runtime_file_path, 'r') as runtime_file:
          with open(parallelization_file_path, 'w') as parallelization_file:
            parallelization_file.write("# folder                 subprocess     parallel    n_event_min    n_event_max           norm           deviation\n")
            for in_line in runtime_file:
                line=in_line.strip() # strip removes all spaces (including tabs and newlines)
                # if any line starts with %, # or is an emtpy line (disregarding spaces) it is a comment line and should be skipped
                if line=="" or line[0]=="%" or line[0]=="#": 
                    continue
                # split line by any number of spaces
                split_line = line.split()
                if(len(split_line) == 7):
                    rel_run_dir = split_line[0]
                    rel_run_dir_out = rel_run_dir
                    run_dir   = pjoin(fold.run_folder_path,rel_run_dir,"run.0")
                    channel   = split_line[1]
                    runtime   = int(split_line[2])
                    n_event   = int(split_line[3])
                    deviation = float(split_line[4])
                    norm      = float(split_line[5])
                    norm_err  = float(split_line[6])
                elif(len(split_line) == 8):
                    rel_run_dir = split_line[0]
                    rel_run_dir_out = rel_run_dir.replace(rel_run_dir.split("/")[0],rel_run_dir.split("/")[0]+".tau")
                    run_dir   = pjoin(fold.run_folder_path,rel_run_dir_out,"run.0")
                    optimizat = split_line[1]
                    channel   = split_line[2]
                    runtime   = int(split_line[3])
                    n_event   = int(split_line[4])
                    deviation = float(split_line[5])
                    norm      = float(split_line[6])
                    norm_err  = float(split_line[7])
                else:
                    out.print_error("Length of line runtime.dat neither 7 nor 8 columns. Something is wrong...")

                if "VT2.QCD" in run_dir and prc.process_name in VT2_use_default_runtime:
                    runtime   = VT2_use_default_runtime[prc.process_name][1]
                    n_events  = VT2_use_default_runtime[prc.process_name][0]
                    deviation = 0.001
                    norm      = ref_NNLO
                    norm_err  = ref_NNLO_err
                elif "%s /NNLO" % fold.run_folder_path in run_dir and "born" in run_dir:
                    ref_NNLO     = norm
                    ref_NNLO_err = norm_err
                
                for contribution in factor_runtime:
                    if contribution in run_dir:
                        runtime = runtime * factor_runtime[contribution]

                self.runtime_table[run_dir][channel]["runtime"] = runtime
                self.runtime_table[run_dir][channel]["n_event"] = n_event
                self.runtime_table[run_dir][channel]["deviation"] = deviation
                self.runtime_table[run_dir][channel]["sigma_normalization"] = norm
                self.runtime_table[run_dir][channel]["sigma_normalization_error"] = norm_err

                max_time_per_job = float(parameter_list["max_time_per_job"])*60*60/factor_max_time
                if rel_run_dir.split("/")[0] == "LO":
                    if rel_run_dir.split("/")[1].startswith("a"):
                        precision = float(parameter_list["precision_NLO_EW"])
                    else:
                        precision = float(parameter_list["precision_LO"])
                elif rel_run_dir.split("/")[0] == "NLO" or rel_run_dir.split(".")[0] == "NLO":
                    if rel_run_dir.split("/")[1] == self.get_coupling_order("LO","NLO") or rel_run_dir.split("/")[1].startswith("a"):
                        precision = float(parameter_list["precision_NLO_EW"])
                    else:
                        precision = float(parameter_list["precision_NLO_QCD"])
                elif rel_run_dir.split("/")[0] == "NNLO" or rel_run_dir.split(".")[0] == "NNLO" or rel_run_dir.split(".")[0] == "NNNLO":
                    if rel_run_dir.split("/")[1] == self.get_coupling_order("LO","NLO") or rel_run_dir.split("/")[1].startswith("a"):
                        precision = float(parameter_list["precision_added_EW"])
                    else:
                        precision = float(parameter_list["precision_NNLO_QCD"])
                else:
                    out.print_error("The run_dir in read_runtimes does not contain LO, NLO or NNLO: run_dir = %s" % run_dir)
                #                   math.ceil rundet auf!
                parallel_jobs = max(math.ceil(runtime/max_time_per_job * (0.001/precision)**2), self.min_parallel_per_channel)
                if int(nr_cores) != -1: # it makes no sense to parallelize higher than max_number of available cores (note: nr_cores = max_nr_parallel_jobs)
                    if nr_cores < parallel_jobs:
                        out.print_info("max_nr_parallel_jobs (in multicore: cores of machine) from MATRIX_configuration is %s, which is smaller than required parallelization (channel: %s; number of jobs for this channel: %s) for max_time_per_job in parameter.dat. Limiting the parallelization to max_nr_parallel_jobs... (max_time_per_job will not be met)" % (nr_cores,run_dir,parallel_jobs))
                    parallel_jobs = min(parallel_jobs,nr_cores)
                if n_event == 0: # this should rarely happen!
                    n_event = 1
                if self.min_events_per_channel > n_event * (0.001/precision)**2:
                    parallel_jobs = max(math.ceil(runtime/max_time_per_job * (0.001/precision)**2 * self.min_events_per_channel/(n_event*(0.001/precision)**2)), self.min_parallel_per_channel)
                    n_step = math.ceil(self.min_events_per_channel/factor1/parallel_jobs)
                else:
                    n_step = math.ceil(n_event/factor1  * (0.001/precision)**2/parallel_jobs)

                n_events_min = n_step * factor1
                n_events_max = n_events_min * factor2
                norm_deviation = deviation * precision/0.001 * math.sqrt(parallel_jobs)

                self.runtime_table[run_dir][channel]["parallel_jobs"] = int(parallel_jobs)
                self.runtime_table[run_dir][channel]["n_step"] = int(n_step)
                self.runtime_table[run_dir][channel]["n_events_min"] = int(n_events_min)
                self.runtime_table[run_dir][channel]["n_events_max"] = int(n_events_max)
                self.runtime_table[run_dir][channel]["sigma_normalization_deviation"] = norm_deviation
                # add parallelization to summary for each contribution (not each run folder or channel; that is already saved below)
                log.summary_add_parallel(parallel_jobs,run_dir.rsplit('/',1)[0])

                try:
                    parallel_jobs += 1
                except TypeError:
                    out.print_error("Number of parallel jobs is no Integer: parallel_jobs = %s." % parallel_jobs)
                try:
                    n_step += 1
                except TypeError:
                    out.print_error("Number of steps per iteration is no Integer n_step = %s." % n_step)

                # save determined parellelization to file
                length = 15
                line_out = rel_run_dir_out+" "*(25-len(rel_run_dir_out))
                line_out += channel+" "*(18-len(channel))
                line_out += " "*(5-len(str(int(parallel_jobs))))+str(int(parallel_jobs))
                line_out += " "*(length-len(str(n_events_min)))+str(n_events_min)
                line_out += " "*(length-len(str(n_events_max)))+str(n_events_max)
                line_out += " "*(length-len(str(norm)))+str(norm)
                line_out += " "*(20-len(str(norm_deviation)))+str(norm_deviation)+"\n"
                parallelization_file.write(line_out)
#}}}
#{{{ def: set_inputs_test_run(self)
    def set_inputs_test_run(self,test_dir):
    # this function sets the default inputs for the grid run
        # set new grid setup parameters
        inp.input_set_entry(pjoin(test_dir,"file_parameter.dat"),"zwahl",parameter_list.get("random_seed","0"))
        inp.input_set_entry(pjoin(test_dir,"file_parameter.dat"),"output_level","DEBUG")
#}}}
#{{{ def: set_inputs_grid_run(self)
    def set_inputs_grid_run(self,grid_dir):
    # this function sets the default inputs for the grid run
        # these values are hard-coded and may be adjust by experience:
        contribution = self.get_contribution(grid_dir)
        switch_IS_MC = 1
        # set new grid setup parameters
        inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"run_mode","grid")
#        inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"MCweight_opt","3") # not needed anymore
# the following are redundant:
        # inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_MC","1")
        # inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_IS_MC",str(switch_IS_MC))
        # inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_IS_tau","1")
        # inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_IS_x1x2","1")
        # if "/CA.QCD/" in grid_dir or "/RCA.QCD/" in grid_dir or "/CT.QCD/" in grid_dir or "/L2CT.QCD/" in grid_dir or "/CT2.QCD/" in grid_dir:
        #     # optimize z1z2 in CA and RCA
        #     inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_IS_z1z2","1")
        # else:
        #     inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_IS_z1z2","0")
        if parameter_list.get("improve_mappings_for_single_V","0") == "1":
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_MC_tau","1")
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_MC_x_dipole","1")
        inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_n_events_opt","2")
        inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"n_events_min","0")
        inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_moment","0")
        inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_distribution","0")
        if not "PT.QCD" == contribution and not "PT2.QCD" == contribution:
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_TSV","0")
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_CV","1")
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"n_scales_CV","1")
        else:
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_CV","0")
        inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"zwahl",parameter_list.get("random_seed","0"))
        if parameter_list.get("reduce_workload",0) == "2":
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"output_level","WARN")
        if "L2RA" == contribution or "L2RT" == contribution:
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"OL stability_mode","21")
        if "L2RA" == contribution:
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"OL stability_kill2","1.e-2")
        if "L2RT" == contribution:
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"OL stability_kill2","1.")
        if self.get_firstfolder(grid_dir).endswith(".tau"):
#            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"user_switch optimization_modifier","3")
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_optimization_modifier","1")
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"selection_optimization_modifier","tau")
            inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"optimization_modifier_exponent","3")
        if prc.process_name in ckm_EW_processes:
            if parameter_list.get("approx_ckm_EW","1") == "2":
                trivial_ckm_in_whole_EW = True
            else:
                trivial_ckm_in_whole_EW = False
            if parameter_list.get("approx_ckm_EW","1") != "0":    
                if "VA.QEW" == contribution or (trivial_ckm_in_whole_EW and ("CA.QEW" == contribution  or "RA.QEW" == contribution)):
                    inp.input_set_entry(pjoin(grid_dir,"file_model.dat"),"CKM_matrix","trivial")
                    inp.input_set_entry(pjoin(grid_dir,"file_parameter.dat"),"switch_amplitude_not_required","1")
#}}}
#{{{ def: set_inputs_pre_run(self)
    def set_inputs_pre_run(self,run_dir_i,parallel_folder_i):
    # this function sets the default inputs for the pre run, that extrapolates the runtimes
        # first: create new run_dir_i by copying the main_run_folder (run.0)
        run_dir_0 = run_dir_i.replace("run.%s" % parallel_folder_i,main_run_folder)
        contribution = self.get_contribution(run_dir_0)
        if not os.path.exists(run_dir_i): # create parallel folder if not exists
            os.makedirs(run_dir_i)
            os.makedirs(pjoin(run_dir_i,"log"))
            shutil.copy(pjoin(run_dir_0,"file_parameter.dat"),run_dir_i)
            for basename in os.listdir(pjoin(run_dir_0,"log")):
                if basename.endswith('.in'):
                    pathname = pjoin(pjoin(run_dir_0,"log"), basename)
                    if os.path.isfile(pathname):
                        shutil.copy2(pathname, pjoin(run_dir_i,"log"))
        # file_parameter.dat is now fully created here: remove previous in order to remove previous settings
        try:
            os.remove(pjoin(run_dir_i,"file_parameter.dat"))
        except:
            pass
        # # set inputs for resummation first, because of type order for the weight path
#{{{ inputs for resummation
        # decide wether NLO or NNLO folder
        if "%s/NLO" % fold.run_folder_path in run_dir_i and parameter_list.get("add_NLL","0") == "1":# NLO folder
            for contribution_mapped in resummation_map_NLO:
                if contribution_mapped in run_dir_i:
                    contribution_map = resummation_map_NLO[contribution_mapped]
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"user_switch do_resummation","1")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_perturbative_order","NLO")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_contribution",contribution_map)
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_correction","QCD")
                    if contribution_mapped == "born":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("LO"))
                    elif contribution_mapped == "VT.QCD":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("NLO"))
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_e",self.get_coupling_order_EW("LO"))
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_interference","0")
                    self.get_coupling_order_EW("LO")
        elif "%s/NNLO" % fold.run_folder_path in run_dir_i and parameter_list.get("add_NNLL","0") == "1":# NNLO folder
            for contribution_mapped in resummation_map_NNLO:
                if contribution_mapped in run_dir_i:
                    contribution_map = resummation_map_NNLO[contribution_mapped]
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"user_switch do_resummation","1")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_perturbative_order","NNLO")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_contribution",contribution_map)
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_correction","QCD")
                    if contribution_mapped == "born":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("LO"))
                    elif contribution_mapped == "VT.QCD":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("NLO"))
                    elif contribution_mapped == "VT2.QCD":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("NNLO"))
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_e",self.get_coupling_order_EW("LO"))
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_interference","0")
                    self.get_coupling_order_EW("LO")
#}}}

        # these values are hard-coded and may be adjust by experience:
        n_events_min = int(math.ceil(self.get_pre_run_min_events_for_contribution(run_dir_0)/self.get_parallel_pre_runs_for_contribution(run_dir_0)/10)*10)
        n_events_max = int(math.ceil(self.get_pre_run_min_events_for_contribution(run_dir_0)/self.get_parallel_pre_runs_for_contribution(run_dir_0)/10)*10)
        n_step = int(math.ceil(self.get_pre_run_min_events_for_contribution(run_dir_0)/self.get_parallel_pre_runs_for_contribution(run_dir_0)/10)*10)
        sigma_normalization = 1
        sigma_normalization_deviation = 0
        # set the grid that has to be used
        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"MCweight_in_directory",os.path.relpath(self.grid_dirs_for_run_dirs[run_dir_0],pjoin(process_dir,run_folder)))
        # set the number of the run folder (zwahl=seed);
        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"zwahl",str(int(parameter_list.get("random_seed","0"))+parallel_folder_i))
        # set new run parameters
        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"n_events_min",str(n_events_min))
        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"n_events_max",str(n_events_max))
        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"n_step",str(n_step))
        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"sigma_normalization",str(sigma_normalization))
        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"sigma_normalization_deviation",str(sigma_normalization_deviation))
        if parameter_list.get("reduce_workload",0) == "2":
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"output_level","WARN")
        if parameter_list.get("improve_mappings_for_single_V","0") == "1":
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"switch_MC_tau","2")
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"switch_MC_x_dipole","2")
        if "RRA.QCD" == contribution:
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"cut_technical","1.e-10")
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"switch_console_output_techcut_RA","0")
        if "L2RA.QCD" == contribution or "L2RT.QCD" == contribution:
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"OL stability_mode","21")
        if "L2RA.QCD" == contribution:
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"OL stability_kill2","1.e-2")
        if "L2RT.QCD" == contribution:
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"OL stability_kill2","1.")
        if prc.process_name in ckm_EW_processes:
            if parameter_list.get("approx_ckm_EW","1") == "2":
                trivial_ckm_in_whole_EW = True
            else:
                trivial_ckm_in_whole_EW = False
            if parameter_list.get("approx_ckm_EW","1") != "0":    
                if "VA.QEW" == contribution or (trivial_ckm_in_whole_EW and ("CA.QEW" == contribution or "RA.QEW" == contribution)):
                    inp.input_set_entry(pjoin(run_dir_i,"file_model.dat"),"CKM_matrix","trivial")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"switch_amplitude_not_required","1")
        if "PT.QCD" == contribution or "PT2.QCD" == contribution:
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"switch_CV","0")
#}}}
#{{{ def: set_inputs_main_run(self)
    def set_inputs_main_run(self,run_dir_i,channel,parallel_folder_i):
    # this function sets the default inputs for the pre run, that extrapolates the runtimes
        # first: create new run_dir_i by copying the main_run_folder (run.0)
        run_dir_0 = run_dir_i.replace("run.%s" % parallel_folder_i,main_run_folder)
        contribution = self.get_contribution(run_dir_0)
        if not os.path.exists(run_dir_i): # create parallel folder if not exists
            os.makedirs(run_dir_i) 
            os.makedirs(pjoin(run_dir_i,"log"))
#            shutil.copy(pjoin(run_dir_0,"file_parameter.dat"),run_dir_i)
            for basename in os.listdir(pjoin(run_dir_0,"log")):
                if basename.endswith('.in'):
                    pathname = pjoin(pjoin(run_dir_0,"log"), basename)
                    if os.path.isfile(pathname):
                        shutil.copy2(pathname, pjoin(run_dir_i,"log"))
#            shutil.copytree(pjoin(run_dir_0,"log"),run_dir_i,symlinks=True) # keep symlinks !!!
#{{{ inputs for resummation
        # decide wether NLO or NNLO folder
        if "%s/NLO" % fold.run_folder_path in run_dir_i and parameter_list.get("add_NLL","0") == "1":# NLO folder
            for contribution_mapped in resummation_map_NLO:
                if contribution_mapped in run_dir_i:
                    contribution_map = resummation_map_NLO[contribution]
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"user_switch do_resummation","1")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_perturbative_order","NLO")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_contribution",contribution_map)
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_correction","QCD")
                    if contribution_mapped == "born":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("LO"))
                    elif contribution_mapped == "VT.QCD":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("NLO"))
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_e",self.get_coupling_order_EW("LO"))
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_interference","0")
                    self.get_coupling_order_EW("LO")
        elif "%s/NNLO" % fold.run_folder_path in run_dir_i and parameter_list.get("add_NNLL","0") == "1":# NNLO folder
            for contribution_mapped in resummation_map_NNLO:
                if contribution_mapped in run_dir_i:
                    contribution_map = resummation_map_NNLO[contribution]
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"user_switch do_resummation","1")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_perturbative_order","NNLO")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_contribution",contribution_map)
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"type_correction","QCD")
                    if contribution_mapped == "born":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("LO"))
                    elif contribution_mapped == "VT.QCD":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("NLO"))
                    elif contribution_mapped == "VT2.QCD":
                        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_s",self.get_coupling_order_QCD("NNLO"))
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_order_alpha_e",self.get_coupling_order_EW("LO"))
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"contribution_interference","0")
                    self.get_coupling_order_EW("LO")
#}}}        
        # set the grid that has to be used
        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"MCweight_in_directory",os.path.relpath(self.grid_dirs_for_run_dirs[run_dir_0],pjoin(process_dir,run_folder)))
        # set the number of the run folder (zwahl=seed);
        inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"zwahl",str(int(parameter_list.get("random_seed","0"))+parallel_folder_i))
        if parameter_list.get("reduce_workload",0) == "2":
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"output_level","WARN")
        if parameter_list.get("improve_mappings_for_single_V","0") == "1":
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"switch_MC_tau","2")
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"switch_MC_x_dipole","2")
        if "L2RA" == contribution or "L2RT" == contribution:
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"OL stability_mode","21")
        if "L2RA" == contribution:
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"OL stability_kill2","1.e-2")
        if "L2RT" == contribution:
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"OL stability_kill2","1.")
        if prc.process_name in ckm_EW_processes:
            if parameter_list.get("approx_ckm_EW","1") == "2":
                trivial_ckm_in_whole_EW = True
            else:
                trivial_ckm_in_whole_EW = False
            if parameter_list.get("approx_ckm_EW","1") != "0":
                if "VA.QEW" == contribution or (trivial_ckm_in_whole_EW and ("CA.QEW" == contribution or "RA.QEW" == contribution)):
                    inp.input_set_entry(pjoin(run_dir_i,"file_model.dat"),"CKM_matrix","trivial")
                    inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"switch_amplitude_not_required","1")
        if "PT.QCD" == contribution or "PT2.QCD" == contribution:
            inp.input_set_entry(pjoin(run_dir_i,"file_parameter.dat"),"switch_CV","0")

        param_file_path = pjoin(run_dir_i,"log","file_parameter."+channel+".dat")
        # create 'channel'_file_parameter.dat for each channel in log folder if it does not exist
        if not os.path.isfile(param_file_path):
            open(param_file_path, 'a').close()
        # set new run parameters
        inp.input_set_entry(param_file_path,"n_events_min",self.runtime_table[run_dir_0][channel]["n_events_min"])
        inp.input_set_entry(param_file_path,"n_events_max",self.runtime_table[run_dir_0][channel]["n_events_max"])
        inp.input_set_entry(param_file_path,"n_step",self.runtime_table[run_dir_0][channel]["n_step"])
        inp.input_set_entry(param_file_path,"sigma_normalization",self.runtime_table[run_dir_0][channel]["sigma_normalization"])
        inp.input_set_entry(param_file_path,"sigma_normalization_deviation",self.runtime_table[run_dir_0][channel]["sigma_normalization_deviation"])
        # set the number of the run folder (zwahl=seed);
        inp.input_set_entry(param_file_path,"zwahl",str(int(parameter_list.get("random_seed","0"))+parallel_folder_i))
#}}}
#{{{ def: set_inputs_result_combination(self)
    def set_inputs_result_combination(self,result_dir):
    # this function sets the default inputs for the result combination
        param_file_path = pjoin(result_dir,"file_parameter.dat")
        inp.input_set_entry(param_file_path,"output_level","INFO")
#}}}
#{{{ def: log_full_of_errors(self,subprocess_out_path)
    def log_full_of_errors(self,subprocess_out_path):
    # this function is for checking wether there are many errors in log file, so that job can be restarted
        outcome = False
        tmp_file = subprocess_out_path+".copy"
        shutil.copy(subprocess_out_path,tmp_file)
        count = 0
        with open(tmp_file) as f:
            for line in f:
                if "ERROR" in line.upper():
                    count += 1
        if count > 10:
            print("count: "+str(count))
        if count > 1000: outcome = True
        os.remove(tmp_file)
        return outcome
#}}}
#{{{ def: log_keyword_end_of_file(self,subprocess_out_path,keyword)
    def log_keyword_end_of_file(self,subprocess_out_path,keyword):
    # this function is for checking wether the last line of log has a specific key word, so that job can be restarted
        outcome = False
        tmp_file = subprocess_out_path+".copy"
        shutil.copy(subprocess_out_path,tmp_file)
        with open(tmp_file) as f:
            for line in f:
                pass
            last = line.strip()
        if last == keyword: outcome = True
#        print("last line of log: "+last)
#        print("keyword: "+keyword)
        os.remove(tmp_file)
        return outcome
#}}}
#{{{ def: job_correctly_finished(self,run_path,process)
    def job_correctly_finished(self,run_path,process):
    # this function checks wether the job in the given folder for the given process was correctly finished
        outcome = False
        # if running on cluster locally on nodes, check if the job created the tarball, then unpack it
        if self.runmode == "cluster" and int(config_list.get("cluster_local_run",0)) > 0:
            contribution = os.path.basename(os.path.dirname(run_path))
            rundir = os.path.basename(run_path)
            tarball = pjoin(run_path,"results_"+contribution+"_"+rundir+"_"+process+".tar")
            if os.path.isfile(tarball):
                try:
                    tar = tarfile.open(tarball)
                    tar.extractall(run_path)
                except:
                    os.remove(tarball)
                    return outcome
                os.remove(tarball)

        # in this file is the indicator wether the job was successfully finished
        file_name = pjoin(run_path,"execution","execution_"+process+".dat")
        if os.path.isfile(file_name):
            with open(file_name, 'r') as finish_file:
                # read in the file into single string and remove leading and trailing spaces (including tabs, enters)
                finish_line = finish_file.readline().strip()
                # the first line in this file has to state "final result" if job was correctly finished
                if finish_line == "final result":
                    outcome = True
        return outcome
#}}}
#{{{ def: jobs_in_failed_list(self)
    def jobs_in_failed_list(self):
        outcome = False
        DIR = pjoin(process_dir,"log",run_folder,"failed")
        if len([name for name in os.listdir(DIR) if os.path.isfile(pjoin(DIR, name))])>0: outcome = True
        return outcome
#}}}
#{{{ def: grid_run_complete(self)
    def grid_run_complete(self):
        outcome = True
        failed_dir = pjoin(process_dir,"log",run_folder,"grid_run","failed")
        success_dir = pjoin(process_dir,"log",run_folder,"grid_run","successful")
        self.expected_nr_of_grid_runs = 0
        for grid_dir in self.grid_dirs: # normal dirs
            self.expected_nr_of_grid_runs += len(self.channels[grid_dir])
        if self.include_loop_induced:
            for grid_dir in self.loop_grid_dirs: # normal dirs
                self.expected_nr_of_grid_runs += len(self.loop_channels[grid_dir])
        if not os.path.isdir(failed_dir) or not os.path.isdir(success_dir):
            self.successful_nr_of_grid_runs = 0
            self.failed_nr_of_grid_runs = 0
            outcome = False
            return outcome
            
        self.successful_nr_of_grid_runs = len([name for name in os.listdir(success_dir) if os.path.isfile(pjoin(success_dir, name))])
        self.failed_nr_of_grid_runs = len([name for name in os.listdir(failed_dir) if os.path.isfile(pjoin(failed_dir, name))])
        if self.expected_nr_of_grid_runs != self.successful_nr_of_grid_runs: outcome = False

        # check if final result is in the grid folders
        for grid_dir in self.grid_dirs:
            for channel in self.channels[grid_dir]:
                if self.phase == 2 or continue_run:
                    if not self.job_correctly_finished(grid_dir,channel):
                        self.failed_run_list.append(pjoin(grid_dir,"log",channel))
                        outcome = False
        if self.include_loop_induced:
            for grid_dir in self.loop_grid_dirs: # loop dirs
                fold.add_dir_identifier(grid_dir,"grid")
                for channel in self.loop_channels[grid_dir]:
                    if not self.job_correctly_finished(grid_dir,channel):
                        self.failed_run_list.append(pjoin(grid_dir,"log",channel))
                        outcome = False

        return outcome
#}}}
#{{{ def: pre_run_complete(self)
    def pre_run_complete(self):
        outcome = True
        # check if final result is in the pre run folders
        for run_dir in self.run_dirs: # normal dirs
            for channel in self.run_channels[run_dir]: # loop through channels
                parallel_runs = self.get_parallel_pre_runs_for_contribution(run_dir)
                for k in range(0,parallel_runs): # for parallel running of same contributions
                    i=k
                    if not self.job_correctly_finished(run_dir.replace(main_run_folder,"run.%s" % i),channel):
                        self.failed_run_list.append(pjoin(run_dir.replace(main_run_folder,"run.%s" % i),"log",channel))
                        outcome = False
        if self.include_loop_induced:
            for run_dir in self.loop_run_dirs: # loop dirs
              for channel in self.loop_channels[self.grid_dirs_for_run_dirs[run_dir]]: # loop through channels
                parallel_runs = self.get_parallel_pre_runs_for_contribution(run_dir)
                for k in range(0,parallel_runs): # for parallel running of same contributions
                    i=k # this is to use run.0-parallel_runs_of_pre for the extrapolation run
                    if not self.job_correctly_finished(run_dir.replace(main_run_folder,"run.%s" % i),channel):
                        self.failed_run_list.append(pjoin(run_dir.replace(main_run_folder,"run.%s" % i),"log",channel))
                        outcome = False
        return outcome
#}}}
#{{{ def: main_run_complete(self)
    def main_run_complete(self):
        outcome = True
        # check if final result is in the main run folders
        for run_dir in self.run_dirs: # normal dirs
            for channel in self.run_channels[run_dir]: # loop through channels
                parallel_runs = self.runtime_table[run_dir][channel]["parallel_jobs"]
                for k in range(0,parallel_runs): # for parallel running of same contributions
                    i=k+self.get_parallel_pre_runs_for_contribution(run_dir) # this is to use run.parallel_runs_of_pre and onwards for the main runs
                    if not self.job_correctly_finished(run_dir.replace(main_run_folder,"run.%s" % i),channel):
                        self.failed_run_list.append(pjoin(run_dir.replace(main_run_folder,"run.%s" % i),"log",channel))
                        outcome = False
        if self.include_loop_induced:
            for run_dir in self.loop_run_dirs: # loop dirs
              for channel in self.loop_channels[self.grid_dirs_for_run_dirs[run_dir]]: # loop through channels
                parallel_runs = self.runtime_table[run_dir][channel]["parallel_jobs"]
                for k in range(0,parallel_runs): # for parallel running of same contributions
                    i=k+self.get_parallel_pre_runs_for_contribution(run_dir) # this is to use run.parallel_runs_of_pre and onwards for the main runs
                    if not self.job_correctly_finished(run_dir.replace(main_run_folder,"run.%s" % i),channel):
                        self.failed_run_list.append(pjoin(run_dir.replace(main_run_folder,"run.%s" % i),"log",channel))
                        outcome = False
        return outcome
#}}}
#{{{ def: write_job_log_start(self,run_path,process,string)
    def write_job_log_start(self,run_path,process,string):
    # this function creates a new log file for the given run_path and process, and writes a 
    # starting line form "path: run_path, process: process >>> string"
        log_folder = pjoin(process_dir,"log",run_folder)
        # use relative path of current run so that printout is not so long
        rel_path = os.path.relpath(run_path,pjoin(process_dir,run_folder))
        log_file = open(pjoin(log_folder,rel_path.replace("/","-")+">>"+process+".log"), 'w')
        try:
            log_file.write("path: %s, process: %s >>> %s\n"%(rel_path,process,string))
        finally:
            log_file.close()
#}}}
#{{{ def: write_job_log(self,run_path,process,string)
    def write_job_log(self,run_path,process,string):
    # this function writes into a (existing) log file and adds one line of the form "process >>> string"
        log_folder = pjoin(process_dir,"log",run_folder)
        # use relative path of current run so that printout is not so long
        rel_path = os.path.relpath(run_path,pjoin(process_dir,run_folder))
        log_file = open(pjoin(log_folder,rel_path.replace("/","-")+">>"+process+".log"), 'a')
        try:
            log_file.write("path: %s, process: %s >>> %s\n"%(rel_path,process,string))
        finally:
            log_file.close()
#}}}
#{{{ def: write_job_log_start(self,run_path,process,string)
    def write_job_log_finish(self,run_path,process,string):
    # this function creates a new log file for the given run_path and process, and writes a 
    # starting line form "path: run_path, process: process >>> string"
        log_folder = pjoin(process_dir,"log",run_folder)
        # use relative path of current run so that printout is not so long
        rel_path = os.path.relpath(run_path,pjoin(process_dir,run_folder))
        log_file = open(pjoin(log_folder,rel_path.replace("/","-")+">>"+process+".log"), 'a')
        try:
            log_file.write("path: %s, process: %s >>> %s\n"%(rel_path,process,string))
            log_file.write("-" * len("path: %s, process: %s >>> %s\n"%(rel_path,process,string))+"\n")
        finally:
            log_file.close()
#}}}
#{{{ def: add_job_success_log(self,run_path,process)
    def add_job_success_log(self,run_path,process):
    # this function adds a job to the list of successful jobs inside the log folder
        success_folder = pjoin(process_dir,"log",run_folder,"successful")
        # use relative path of current run so that printout is not so long
        rel_path = os.path.relpath(run_path,pjoin(process_dir,run_folder))
        success_file = open(pjoin(success_folder,rel_path.replace("/","-")+">>"+process+".success"), 'w')
        try:
            success_file.write("job done")
        finally:
            success_file.close()
#}}}
#{{{ def: add_job_failed_log(self,run_path,process)
    def add_job_failed_log(self,run_path,process):
    # this function adds a job to the list of failed jobs inside the log folder
        failed_folder = pjoin(process_dir,"log",run_folder,"failed")
        # use relative path of current run so that printout is not so long
        rel_path = os.path.relpath(run_path,pjoin(process_dir,run_folder))
        failed_file = open(pjoin(failed_folder,rel_path.replace("/","-")+">>"+process+".failed"), 'w')
        try:
            failed_file.write("job failed")
        finally:
            failed_file.close()
#}}}
#{{{ def: remove_job_success_log(self,run_path,process)
    def remove_job_success_log(self,run_path,process):
    # this function removes a job to the list of successful jobs inside the log folder
        success_folder = pjoin(process_dir,"log",run_folder,"successful")
        rel_path = os.path.relpath(run_path,pjoin(process_dir,run_folder))
        os.remove(pjoin(success_folder,rel_path.replace("/","-")+">>"+process+".success"))
#}}}
#{{{ def: remove_job_failed_log(self,run_path,process)
    def remove_job_failed_log(self,run_path,process):
    # this function removes a job to the list of failed jobs inside the log folder
        failed_folder = pjoin(process_dir,"log",run_folder,"failed")
        rel_path = os.path.relpath(run_path,pjoin(process_dir,run_folder))
        os.remove(pjoin(failed_folder,rel_path.replace("/","-")+">>"+process+".failed"))
#}}}
#{{{ def: read_channel_file(self,file_path)
# all channels for a specific folder are read from the channel file and returned
    def read_channel_file(self,file_path):
        contribution = self.get_contribution(file_path)
        channel={}
        with open(file_path) as f:
            channel = [x.strip('\n').replace("x","~") for x in f.readlines() if not self.exclude_channel(x,contribution)]
        return channel
#}}}
#{{{ def: exclude_channel(self,channel,contribution)
# returns a list which associates each directory with its channels
    def exclude_channel(self,channel,contribution):
        if (contribution == "L2RA.QCD" or contribution == "L2RT.QCD") and parameter_list.get("only_gg_chan",0) == "1" and not channel.startswith("gg"):
            return True
        if "b" in channel and parameter_list.get("flavor_scheme") == "1":
            return True
        if prc.process_name in ckm_processes: # for charged processes with CKM matrix exclude vanishing channels
            Wsplitting = ""
            for quark in ["u","d","c","s","t","b"]:
                if not channel.count(quark) % 2 == 0:
                    Wsplitting = Wsplitting + quark
                reverseWsplitting = Wsplitting[::-1]
                zero_splittings = []
                if "CKM" in model_list:
                    for number in model_list["CKM"]:
                        if float(model_list["CKM"][number]) == 0:
                            zero_splittings.append(model_mappings_to_MUNICH["CKM"][number][2:4])
                elif "VCKMIN" in model_list:
                    zero_splittings = ["ub","cb","td","ts","tb"] # 3rd generation mixing turned off
                    if abs(float(model_list["VCKMIN"][1])) < 0.0000000001:
                        zero_splittings.append("us")
                        zero_splittings.append("cd")
                    if abs(float(model_list["VCKMIN"][1]) - math.pi) < 0.0000000001:
                        zero_splittings.append("ud")
                        zero_splittings.append("cs")
                else:
                    off_diagonal = ["us","ub","cd","cb","td","ts"]
                    zero_splittings = off_diagonal
                if Wsplitting in zero_splittings or reverseWsplitting in zero_splittings:
                    return True
        return False
#}}}
#{{{ def: get_dir_channels(self,path)
# returns a list which associates each directory with its channels
    def get_dir_channels(self,dirs):
        channel={}
        for dir in dirs:
            chans = self.read_channel_file(pjoin(dir.rsplit('/',1)[0],"subprocesslist.dat"))
            channel[dir]=chans
        return channel
#}}}
#{{{ def: get_dirs(self,folder_name,NLO_subtraction,order)
    def get_dirs(self,folder_name,NLO_subtraction,order):
    # new: use hard-coded paths to grid folders you want to be created
        out_dirs = []
        loop_out_dirs = []

        if "LO" in order or (folder_name == "grid" and "NLO" in order) or (folder_name == "grid" and "NNLO" in order and not int(parameter_list["loop_induced"]) < 0): # in grid run we always need LO
            out_dirs.append(pjoin(fold.run_folder_path,"LO",self.get_coupling_order("LO"),"born",folder_name))
            if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                out_dirs.append(pjoin(fold.run_folder_path,"LO","a"+self.get_coupling_order("LO"),"born",folder_name))
        if "NLO" in order or (folder_name == "grid" and "NNLO" in order and not int(parameter_list["loop_induced"]) < 0):
            # QCD part
            if parameter_list.get("run_NLO_QCD","0") == "1" or (folder_name == "grid" and parameter_list.get("run_NNLO_QCD","0") == "1"):
                if "CS" in NLO_subtraction:
                    out_dirs.append(pjoin(fold.run_folder_path,"NLO.CS",self.get_coupling_order("NLO"),"RA.QCD",folder_name))
                    out_dirs.append(pjoin(fold.run_folder_path,"NLO.CS",self.get_coupling_order("NLO"),"CA.QCD",folder_name))
                elif "QT" in NLO_subtraction:
                    out_dirs.append(pjoin(fold.run_folder_path,"NLO.QT",self.get_coupling_order("NLO"),"CT.QCD",folder_name))
                    out_dirs.append(pjoin(fold.run_folder_path,"NLO.QT",self.get_coupling_order("NLO"),"RT.QCD",folder_name))
                    if parameter_list.get("power_corrections") == "1":
                        out_dirs.append(pjoin(fold.run_folder_path,"NLO.QT",self.get_coupling_order("NLO"),"PT.QCD",folder_name))
                else:
                    out.print_error("NLO_subtraction \"%s\"in get_dirs routine does not exist. Stopping the code..." % NLO_subtraction)
            # EW part
            if parameter_list.get("run_NLO_EW","0") == "1" or parameter_list.get("add_NLO_EW","0") == "1":
                out_dirs.append(pjoin(fold.run_folder_path,"NLO.CS",self.get_coupling_order("LO","NLO"),"RA.QEW",folder_name))
                out_dirs.append(pjoin(fold.run_folder_path,"NLO.CS",self.get_coupling_order("LO","NLO"),"CA.QEW",folder_name))
                if parameter_list.get("photon_induced","0") == "1":
                    out_dirs.append(pjoin(fold.run_folder_path,"NLO.CS","a"+self.get_coupling_order("LO","NLO"),"RA.QEW",folder_name))
                    out_dirs.append(pjoin(fold.run_folder_path,"NLO.CS","a"+self.get_coupling_order("LO","NLO"),"CA.QEW",folder_name))
        if "NNLO" in order:
            if not int(parameter_list["loop_induced"]) < 0:
                out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT-CS",self.get_coupling_order("NNLO"),"RRA.QCD",folder_name))
                out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT-CS",self.get_coupling_order("NNLO"),"RCA.QCD",folder_name))
                out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT-CS",self.get_coupling_order("NNLO"),"CT2.QCD",folder_name))
                if parameter_list.get("power_corrections") == "1":
                    out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT-CS",self.get_coupling_order("NNLO"),"PT2.QCD",folder_name))
                if folder_name.startswith("grid") and "CS" in NLO_subtraction: # use RT contribution of QT subtraction only for the grids at NNLO
                    out_dirs.append(pjoin(fold.run_folder_path,"NLO.QT",self.get_coupling_order("NLO"),"RT.QCD",folder_name))
                # add loop-induced only if the contribution exists
            if os.path.exists(pjoin(fold.run_folder_path,"NNLO",self.get_coupling_order("NNLO"),"loop")):
                loop_out_dirs.append(pjoin(fold.run_folder_path,"NNLO",self.get_coupling_order("NNLO"),"loop",folder_name))
                if abs(int(parameter_list["loop_induced"])) == 2:
                    if NLOgg_subtraction == "CS":
                        loop_out_dirs.append(pjoin(fold.run_folder_path,"NNNLO.CS",self.get_coupling_order("NNNLO"),"L2RA.QCD",folder_name))
                        loop_out_dirs.append(pjoin(fold.run_folder_path,"NNNLO.CS",self.get_coupling_order("NNNLO"),"L2CA.QCD",folder_name))
                    elif NLOgg_subtraction == "QT":
                        loop_out_dirs.append(pjoin(fold.run_folder_path,"NNNLO.QT",self.get_coupling_order("NNNLO"),"L2CT.QCD",folder_name))
                        loop_out_dirs.append(pjoin(fold.run_folder_path,"NNNLO.QT",self.get_coupling_order("NNNLO"),"L2RT.QCD",folder_name))
                    else:
                        out.print_error("NLOgg_subtraction \"%s\"in get_dirs routine does not exist. Stopping the code..." % NLO_subtraction)
        if folder_name.startswith("run"):
            if "NLO" in order:
                out_dirs.append(pjoin(fold.run_folder_path,"NLO",self.get_coupling_order("LO"),"born",folder_name))
                # QCD part
                if parameter_list.get("run_NLO_QCD","0") == "1":
                    if "CS" in NLO_subtraction:
                        out_dirs.append(pjoin(fold.run_folder_path,"NLO.CS",self.get_coupling_order("NLO"),"VA.QCD",folder_name))
                    elif "QT" in NLO_subtraction:
                        out_dirs.append(pjoin(fold.run_folder_path,"NLO.QT",self.get_coupling_order("NLO"),"VT.QCD",folder_name))
                    else:
                        out.print_error("NLO_subtraction \"%s\"in get_dirs routine does not exist. Stopping the code..." % NLO_subtraction)
                # EW part
                if parameter_list.get("run_NLO_EW","0") == "1":
                    out_dirs.append(pjoin(fold.run_folder_path,"NLO.CS",self.get_coupling_order("LO","NLO"),"VA.QEW",folder_name))
                    if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                        out_dirs.append(pjoin(fold.run_folder_path,"NLO.CS","a"+self.get_coupling_order("LO","NLO"),"VA.QEW",folder_name))
                if parameter_list.get("run_NLO_QCD","0") == "1" or parameter_list.get("run_NLO_EW","0") == "1":
                    if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                        out_dirs.append(pjoin(fold.run_folder_path,"NLO","a"+self.get_coupling_order("LO"),"born",folder_name))
            if "NNLO" in order:
                if not int(parameter_list["loop_induced"]) < 0:
                    out_dirs.append(pjoin(fold.run_folder_path,"NNLO",self.get_coupling_order("LO"),"born",folder_name))
                    if parameter_list.get("photon_induced","0") == "1" and prc.process_name in LO_photon_induced_processes:
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO","a"+self.get_coupling_order("LO"),"born",folder_name))
                    if "CS" in NLO_subtraction:
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO.CS",self.get_coupling_order("NLO"),"RA.QCD",folder_name))
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO.CS",self.get_coupling_order("NLO"),"CA.QCD",folder_name))
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO.CS",self.get_coupling_order("NLO"),"VA.QCD",folder_name))
                    elif "QT" in NLO_subtraction:
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT",self.get_coupling_order("NLO"),"RT.QCD",folder_name))
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT",self.get_coupling_order("NLO"),"CT.QCD",folder_name))
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT",self.get_coupling_order("NLO"),"VT.QCD",folder_name))
                        if parameter_list.get("power_corrections") == "1":
                            out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT",self.get_coupling_order("NLO"),"PT.QCD",folder_name))
                    else:
                        out.print_error("NLO_subtraction \"%s\"in get_dirs routine does not exist. Stopping the code..." % NLO_subtraction)
                    out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT-CS",self.get_coupling_order("NNLO"),"RVA.QCD",folder_name))
                    out_dirs.append(pjoin(fold.run_folder_path,"NNLO.QT-CS",self.get_coupling_order("NNLO"),"VT2.QCD",folder_name))
                    if parameter_list.get("add_NLO_EW","0") == "1":
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO.CS",self.get_coupling_order("LO","NLO"),"RA.QEW",folder_name))
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO.CS",self.get_coupling_order("LO","NLO"),"CA.QEW",folder_name))
                        out_dirs.append(pjoin(fold.run_folder_path,"NNLO.CS",self.get_coupling_order("LO","NLO"),"VA.QEW",folder_name))
                        if parameter_list.get("photon_induced","0") == "1":
                            out_dirs.append(pjoin(fold.run_folder_path,"NNLO.CS","a"+self.get_coupling_order("LO","NLO"),"RA.QEW",folder_name))
                            out_dirs.append(pjoin(fold.run_folder_path,"NNLO.CS","a"+self.get_coupling_order("LO","NLO"),"CA.QEW",folder_name))
                            if prc.process_name in LO_photon_induced_processes:
                                out_dirs.append(pjoin(fold.run_folder_path,"NNLO.CS","a"+self.get_coupling_order("LO","NLO"),"VA.QEW",folder_name))
                if os.path.exists(pjoin(fold.run_folder_path,"NNLO",self.get_coupling_order("NNLO"),"loop")):
                    if abs(int(parameter_list["loop_induced"])) == 2:
                        if NLOgg_subtraction == "CS":
                            loop_out_dirs.append(pjoin(fold.run_folder_path,"NNNLO.CS",self.get_coupling_order("NNNLO"),"L2VA.QCD",folder_name))
                        elif NLOgg_subtraction == "QT":
                            loop_out_dirs.append(pjoin(fold.run_folder_path,"NNNLO.QT",self.get_coupling_order("NNNLO"),"L2VT.QCD",folder_name))
                        else:
                            out.print_error("NLO_subtraction \"%s\"in get_dirs routine does not exist. Stopping the code..." % NLO_subtraction)
        if int(parameter_list.get("enhance_tails","0")) > 0:
            out_dirs_tmp = copy.copy(out_dirs)
            loop_out_dirs_tmp = copy.copy(loop_out_dirs)
            for directory in out_dirs_tmp:
                folder_old = os.path.dirname(os.path.dirname(os.path.dirname(directory)))
                folder_new = folder_old+".tau"
                contribution = self.get_firstfolder(directory)
                dir_tau = directory.replace("/"+contribution+"/","/"+contribution+".tau/")
                # copy folder
                try:
                    shutil.copytree(folder_old,folder_new,symlinks=True)
                except:
                    pass
                # add respective run path
                out_dirs.append(dir_tau)
            for directory in loop_out_dirs_tmp:
                folder_old = os.path.dirname(os.path.dirname(os.path.dirname(directory)))
                folder_new = folder_old+".tau"
                contribution = self.get_firstfolder(directory)
                dir_tau = directory.replace("/"+contribution+"/","/"+contribution+".tau/")
                # copy folder
                try:
                    shutil.copytree(folder_old,folder_new,symlinks=True)
                except:
                    pass
                # add respective run path
                loop_out_dirs.append(dir_tau)
        return out_dirs, loop_out_dirs
#}}}
#{{{ def: get_named_dirs(self,folder_name,NLO_subtraction,order,switch)
    def get_named_dirs(self,folder_name,NLO_subtraction,order,switch):
    # get all folders that contain the desired folder_name, but only 
    # with the desired NLO subtraction.
    # switch = 1 for grid folders, switch = 2 for main run
        out_dirs = []
        loop_out_dirs = []
        startinglevel = pjoin(process_dir,run_folder).count(os.sep)
        for root, dirnames, filenames in os.walk(pjoin(process_dir,run_folder)):
            level = root.count(os.sep) - startinglevel
            # only keep folders <= order for the warmup (switch=1: grid setup) run
            if switch == 1 and not "NNLO" in order and "/NNLO" in root:
                continue
            if switch == 1 and not "NLO" in order and not "NNLO" in order and "/NLO" in root:
                continue
            # only keep folders == order for cross section computation (switch=2: main run)
            rel_root = "/"+os.path.relpath(root,pjoin(process_dir,run_folder))
            if switch == 2 and not any("/"+n_order in rel_root for n_order in order):
                continue
            # only select folders which use the NLO_subtraction which was set before
            # this is true for both grid and run folders
            if ".QT" in root or ".CS" in root:
                if not NLO_subtraction in root:
                # only if not NNLO or for switch!=1 (not in grid run), because NLO.QT/*/RT.QCD grids required for NNLO RVA.QCD and RCA.QCD
                    if not switch == 1 or not "NNLO" in order:
                        continue 
            # consider grid folder only on specific directory depth (level==3)
            # relative to the process main run folder
            if level==3:
                for folder in fnmatch.filter(dirnames,folder_name):
                    out_dir = pjoin(root,folder)
                    # check if dir is a run_dir or grid_dir
                    # NOTE: is_grid_dir and is_run_dir currently identical
                    no_grid_dir = (switch == 1 and not self.is_grid_dir(out_dir))
                    no_run_dir = (switch == 2 and not self.is_run_dir(out_dir))
                    if no_grid_dir or no_run_dir:
                        out.print_error("Selected grid directory %s does not appear to a run folder and cannot be used for the grid run." % out_dir) 
                    if ("loop" in root):
                        loop_out_dirs.append(out_dir)                    
                    else:
                        out_dirs.append(out_dir)
        return out_dirs, loop_out_dirs
#}}}
#{{{ def: get_named_files(self,folder_name,NLO_subtraction,order,switch)
    def get_named_files(self,folder_path,string,level_in):
    # get all files that contain a given string at a specific level in the folder structure
        out_files = []
        startinglevel = folder_path.count(os.sep)
        for root, dirnames, filenames in os.walk(folder_path):
            level = root.count(os.sep) - startinglevel
            if level == level_in:
                for files in filenames:
                    out_file = pjoin(root,files)
                    if string in out_file:
                        out_files.append(out_file)
        return out_files
#}}}
#{{{ def: is_run_dir(self,path)
    def is_run_dir(self,path):
        if os.path.isfile(pjoin(path,"file_parameter.dat")):
            return True
        else:
            return False
#}}}
#{{{ def: is_grid_dir(self,path)
    def is_grid_dir(self,path):
        # 2do: add additional check wether file_parameter.dat has the right inputs
        if os.path.isfile(pjoin(path,"file_parameter.dat")):
            return True
        else:
            return False
#}}}
#{{{ def: fileopen(self,filename,rw_option)
    def fileopen(self,filename,rw_option):
    # dummy routine to open in/out/err files or not depending on wether multicore or cluster is used
        if self.runmode == "multicore":
            return open(filename, rw_option)
        else:
            return Dummyopen()
#}}}
#{{{ def: job_just_restarted_add(self)
    def job_just_restarted_add(self):
        # this signals that a job has just been restarted by creating the just.restarted file in logs
        log_folder = pjoin(process_dir,"log",run_folder)
        just_restarted_file = pjoin(log_folder,"just.restarted")
        open(just_restarted_file, 'a').close()
#}}}
#{{{ def: job_just_restarted_remove(self)
    def job_just_restarted_remove(self):
        # this removes the just_restarted signal by removing the just.restarted file in logs
        log_folder = pjoin(process_dir,"log",run_folder)
        just_restarted_file = pjoin(log_folder,"just.restarted")
        try:
            os.remove(just_restarted_file)
        except:
            pass
#}}}
#{{{ def: job_just_restarted(self)
    def job_just_restarted(self):
        # this checks wether a job has just been restarted by checking if just.restarted file exists
        log_folder = pjoin(process_dir,"log",run_folder)
        just_restarted_file = pjoin(log_folder,"just.restarted")
        if os.path.isfile(just_restarted_file):
            return True
        else:
            return False
#}}}
#{{{ def: get_coupling_order_QCD(self,order)
    def get_coupling_order_QCD(self,order):
        # this checks wether a job has just been restarted by checking if just.restarted file exists
        coupling_order_LO_QCD   = os.listdir(pjoin(fold.run_folder_path,"LO"))[0].lstrip("a")[:1]
        coupling_order_NLO_QCD  = str(int(coupling_order_LO_QCD) + 1)
        coupling_order_NNLO_QCD = str(int(coupling_order_LO_QCD) + 2)
        coupling_order_NNNLO_QCD = str(int(coupling_order_LO_QCD) + 3)
        if order == "LO":
            return coupling_order_LO_QCD
        if order == "NLO":
            return coupling_order_NLO_QCD
        if order == "NNLO":
            return coupling_order_NNLO_QCD
        if order == "NNNLO":
            return coupling_order_NNNLO_QCD
#}}}
#{{{ def: get_coupling_order_EW(self,order)
    def get_coupling_order_EW(self,order):
        # this checks wether a job has just been restarted by checking if just.restarted file exists
        coupling_order_LO_EW   = os.listdir(pjoin(fold.run_folder_path,"LO"))[0].lstrip("a")[-1:]
        coupling_order_NLO_EW  = str(int(coupling_order_LO_EW) + 1)
        coupling_order_NNLO_EW = str(int(coupling_order_LO_EW) + 2)
        if order == "LO":
            return coupling_order_LO_EW
        if order == "NLO":
            return coupling_order_NLO_EW
        if order == "NNLO":
            return coupling_order_NNLO_EW
#}}}
#{{{ def: get_coupling_order(self,order,order_EW = "LO")
    def get_coupling_order(self,order,order_EW = "LO"):
        # this checks wether a job has just been restarted by checking if just.restarted file exists
        coupling_order = self.get_coupling_order_QCD(order)+self.get_coupling_order_EW(order_EW)
        return coupling_order
#}}}
#### the following are simple fuctions to determine different properties from the path
#{{{ def: get_properties(self,path)
    def get_properties(self,path):
    # determines the coupling strucure (2. folder from run_folder)
        order=subtraction=coupling=contribution=run_dir=""
        split=path.replace(pjoin(process_dir,run_folder)+"/","").split("/")
        try:
            try:
                subtraction=split[0].split(".")[1]
            except:
                pass
            order=split[0]
            coupling=split[1]
            contribution=split[2]
            run_dir=split[3]
        except:
            pass
        return order,subtraction,coupling,contribution,run_dir
#}}}
#{{{ def: get_firstfolder(self,path)
    def get_firstfolder(self,path):
    # determines the coupling strucure (2. folder from run_folder)
        order,subtraction,coupling,contribution,run_dir=self.get_properties(path)
        return order
#}}}
#{{{ def: get_subtraction(self,path)
    def get_subtraction(self,path):
    # determines the coupling strucure (2. folder from run_folder)
        order,subtraction,coupling,contribution,run_dir=self.get_properties(path)
        return subtraction
#}}}
#{{{ def: get_coupling(self,path)
    def get_coupling(self,path):
    # determines the coupling strucure (2. folder from run_folder)
        order,subtraction,coupling,contribution,run_dir=self.get_properties(path)
        return coupling
#}}}
#{{{ def: get_contribution(self,path)
    def get_contribution(self,path):
    # determines the contribution (2. folder from run_folder)
        order,subtraction,coupling,contribution,run_dir=self.get_properties(path)
        return contribution
#}}}
#{{{ def: get_run_dir(self,path)
    def get_run_dir(self,path):
    # determines the coupling strucure (2. folder from run_folder)
        order,subtraction,coupling,contribution,run_dir=self.get_properties(path)
        return run_dir
#}}}
#{{{ def: control_c_handler_child(self,signal,frame)
    def control_c_handler_child(self,signal,frame):
        # this handels the ctrl-c for the subprocesses
        sys.exit(0)
#}}}
#}}}


#####################################
# Main part of the MATRIX execution #
#####################################
#{{{ program banner
config_list={}
fold.exe_path = pjoin(config_list.get("path_to_executable",pjoin(munich_dir,"bin")),prc.process_name)
lib_test=os.popen('ldd '+fold.exe_path).read()
print("")
banner = banner("|","|",67,11)

if lib_test.find("libpineappl")!=-1:
    banner.print_matrix_hawaii()
else:
     banner.print_matrix()

print("")
#}}}
if args.tar_run: args.run_mode = "tar_run"
if args.setup_run: args.run_mode = "setup_run"
if args.delete_run: args.run_mode = "delete_run"
continue_run = args.continue_run
    
if continue_run:
    out.print_warning("You are trying to continue a run; MAKE SURE THE INPUTS ARE CONSISTENT !!!")
#{{{ initialize classes
inp = inputs()       # class for handling the input
#}}}
#{{{ read MATRIX configuration file
config_list={}
inp.input_read_parameter_dat(pjoin("input","MATRIX_configuration"),config_list)
# set default editor
edit_input.editor = config_list.get("default_editor","")
#}}}
#{{{ determine run folder
current_dir = start_dir

#if len(sys.argv)>=2:
#    run_folder = ssys.argv[1]
if args.run_folder != "":
    run_folder = args.run_folder
# remove trailing "/" if any
    if run_folder[-1] == "/":
      run_folder = run_folder[:-1]
    if not run_name.check_run_folder(run_folder):
        out.print_error("Chosen run folder "+run_folder+" is not suitable. Exiting...")
else:
    # determine next run_XX folder
    next_run_folder = "run_%02d" % int(run_name.get_highest_existing_run()+1)    
    # readin folder used for the run until folder suits check
    out.print_read("Type name of folder for this run (has to start with \"run_\"). \"ENTER\" to create and use \"%s\". Press TAB or type \"list\" to show existing runs. Type \"exit\" or \"quit\" to stop. Any other folder will be created." % next_run_folder)
    while True:
        run_folder = run_name.readin_run_folder()
        if run_folder == "quit" or run_folder == "exit":
            exit(0)
        elif run_folder == "list":
            run_name.list_run_folders()
        elif run_name.check_run_folder(run_folder): break
    # if run_folder empty next_run_folder will be used
    if run_folder == "": run_folder = next_run_folder
#}}}
#{{{ create new run folder, or overwrite the old if already exists
default_run_path = pjoin(process_dir,default_run)
if not os.path.exists(default_run_path):
    tar = tarfile.open(default_run_path+".tar")
    tar.extractall()
    tar.close()
# define all the relevant folders for the matrix code
fold.run_folder_path    = pjoin(process_dir,run_folder)                    # this is the main folder with the MUNICH code, where the runs are done
fold.input_folder_path  = pjoin(process_dir,"input",run_folder)           # MATRIX inputs
fold.log_folder_path    = pjoin(process_dir,"log",run_folder)             # MATRIX logs
fold.result_folder_path = pjoin(process_dir,"result",run_folder)          # MATRIX results
fold.default_input_path = pjoin(process_dir,"input",args.input_dir)        # folder of the MATRIX inputs
fold.check_default_input_path() # checks wether default path is suitable (is a folder and contains parameter/model/distribution.dat)
fold.input_file_dir     = pjoin(munich_dir,"run","input_files",prc.process_name) # default folder for the MUNICH inputs to be copied in the main folder (file_parameter/model/distribution.dat)

if os.path.exists(pjoin(default_run_path,"file_parameter.dat")) and os.path.exists(pjoin(default_run_path,"file_model.dat")) and os.path.exists(pjoin(default_run_path,"file_distribution.dat")):
    fold.input_file_dir = default_run_path
# set paths for classes that have no access to the fold instance
out.run_folder = run_folder # needed for log-file printout
edit_input.input_folder = fold.input_folder_path
# test if code in run_folder is already running
if log.code_running():
    out.print_error("An instance of MATRIX appears to be already running in this folder (%s). If that is not the case, remove file %s and retry the run." % (fold.run_folder_path,pjoin(process_dir,"log",run_folder,"main.running")))

# if argument chosen to change name of run, do it here and stop
if args.new_name:
    if not run_name.check_run_folder(args.new_name):
        out.print_error("Cannot change name of run to \"%s\", which is no suitable name for a run folder. Exiting..." % args.new_name)
    if os.path.exists(pjoin(process_dir,args.new_name)):
        out.print_error("Cannot change name of run to \"%s\", because run folder %s already exists. Exiting..." % (args.new_name, pjoin(process_dir,args.new_name)))
    if os.path.exists(fold.run_folder_path):
        fold.rename_run_to(args.new_name)
        exit(0)
    else:
        out.print_error("Cannot change name of run folder %s, which does not exists. Exiting..." % fold.run_folder_path)
# if argument chosen to copy from existing run, do it here and stop
if args.existing_run:
    if not os.path.exists(pjoin(process_dir,args.existing_run)):
        out.print_error("Cannot copy run from \"%s\", because run folder %s does not exist. Exiting..." % (args.existing_run, pjoin(process_dir,args.existing_run)))
    if not os.path.exists(fold.run_folder_path):
        fold.copy_run_from(args.existing_run)
        exit(0)
    else:
        out.print_error("Cannot copy tun to run folder \"%s\", which already exists. Exiting..." % fold.run_folder_path)
# if full run remove the old folder
if os.path.exists(fold.run_folder_path):
    #if not len(sys.argv)>=3 or not sys.argv[2] in run_modes:
    if args.run_mode == "" or not args.run_mode in run_modes:
        out.print_warning("Run folder selected: %s; Previous run in this folder will be overwritten; abort script NOW if that is not wanted." % fold.run_folder_path)
    #elif len(sys.argv)>=3 and sys.argv[2] in ["run","run_grid","setup_run"]:
    elif args.run_mode in ["run","run_grid_and_pre","run_without_pre","run_grid","setup_run"]:
        out.print_warning("Run folder selected: %s; Previous run in this folder will be overwritten." % fold.run_folder_path)

if not os.path.exists(fold.input_folder_path):
    shutil.copytree(fold.default_input_path,fold.input_folder_path,symlinks=True)
# overwrite (remove+add) input folder when given frome a different default location
elif not args.input_dir == default_input and os.path.exists(fold.input_folder_path):
    shutil.rmtree(fold.input_folder_path)
    shutil.copytree(fold.default_input_path,fold.input_folder_path,symlinks=True)
try:
    os.remove(pjoin(fold.input_folder_path,"runtime.dat"))
except:
    pass
# create results folder
if not os.path.exists(fold.result_folder_path):
   os.makedirs(fold.result_folder_path)

#}}}
#{{{ call command line to choose inputs or start run in chosen run_mode

#if len(sys.argv)>=3:
if args.run_mode != "":
    if args.run_mode in run_modes:
        run_mode = args.run_mode
    else:
        out.print_error("Run mode \"%s\" is not known."%args.run_mode)
else:
    if __name__ == '__main__':
        edit_input.prompt="|============>> "
        edit_input.cmdloop()
        run_mode = edit_input.run_mode

# create log folder if first time
try:
    os.makedirs(pjoin(process_dir,"log"))
except:
    pass
sys.stdout = output_saver(pjoin(process_dir,"log",run_folder+".log")) # must be here because autocompletion does not work otherwise
#}}}
# if run should be removed, delete the input/logs/results and stop the run
if run_mode == "delete_run":
    fold.remove_run()
    exit(0)
# if run should be tarred, tar also the input/log/result folder and stop the run
elif run_mode == "tar_run":
    if os.path.exists(fold.run_folder_path):
        fold.tar_run()
        exit(0)
    else:
        out.print_error("Cannot create .tar archive of run folder %s, that does not exist. Exiting..." % fold.run_folder_path)
#{{{ adjust folder structure according to run_mode

# otherwise create/delete some folders according to run mode
# do this only if the previous log was not saved
removed = False
if run_mode in ["run","run_without_pre","setup_run"] and not continue_run:
    if os.path.exists(fold.run_folder_path):
        shutil.rmtree(fold.run_folder_path)
        removed = True
        out.print_info("Old Run folder overwritten: %s." % fold.run_folder_path)
    
if not os.path.exists(fold.run_folder_path):
    shutil.copytree(default_run_path,fold.run_folder_path,symlinks=True)
    shutil.copy(pjoin(fold.input_file_dir,"file_parameter.dat"),fold.run_folder_path)
    shutil.copy(pjoin(fold.input_file_dir,"file_model.dat"),fold.run_folder_path)
    shutil.copy(pjoin(fold.input_file_dir,"file_distribution.dat"),fold.run_folder_path)
    if not removed:
        out.print_info("New Run folder created: %s." % fold.run_folder_path)
#}}}

# remove later >>>>
# for now change name of folde L2I to loop
try:
    folder = glob.glob(pjoin(fold.run_folder_path,"NNLO","*","L2I"))[0]
    shutil.move(folder,folder.replace("/L2I","/loop"))
except:
    pass
# <<<< remove later

#{{{ wrap all inputs from MATRIX to MUNICH

parameter_list    = {}
model_list        = multidim_dict(2) # multidimensonal dictionary
distribution_list = multidim_dict(2) # multidimensonal dictionary
# read parameter.dat file
inp.input_read_parameter_dat(pjoin(fold.input_folder_path,"parameter.dat"),parameter_list)
# check the parameters just read
#if not run_mode in ["run_results"]:
inp.input_check_parameter_consistencies_from_list(pjoin(fold.run_folder_path,"file_parameter.dat"),parameter_list)
# 2do: not needed separately?
#    inp.input_user_cuts_default_and_consistency(pjoin(fold.run_folder_path,"file_parameter.dat"),parameter_list)
# write file_parameter.dat
inp.input_set_file_parameter_from_list(pjoin(fold.run_folder_path,"file_parameter.dat"),parameter_list)

# read model.dat file
inp.input_read_SLHA(pjoin(fold.input_folder_path,"model.dat"),model_list)
# write file_model.dat
inp.input_set_file_model_from_SLHA(pjoin(fold.run_folder_path,"file_model.dat"),model_list)
# read distribution file and check for unique identifiers (distributionname)
inp.input_read_and_check_distribution_dat(pjoin(fold.input_folder_path,"distribution.dat"),distribution_list)

# read distribution.dat (by simply writing the whole file into content)
content = inp.input_read_distribution_dat(pjoin(fold.input_folder_path,"distribution.dat"))
# copy the distribution file first, not to append several times
shutil.copy(pjoin(fold.input_file_dir,"file_distribution.dat"),fold.run_folder_path)
# write file_distribution.dat (simply appinding distribution.dat from content)
inp.input_set_file_distribution_dat(pjoin(fold.run_folder_path,"file_distribution.dat"),content)

#copy file with double differential distributions input
if os.path.exists(pjoin(fold.input_folder_path,"dddistribution.dat")):
    shutil.copy(pjoin(fold.input_folder_path,"dddistribution.dat"), pjoin(fold.run_folder_path,"file_dddistribution.dat"))

# save the result and log files if specified in the input
if parameter_list["save_previous_result"] == "1" and not run_mode in ["run_gnuplot"]:
    res.save_previous()
if parameter_list["save_previous_log"] == "1":
    if not run_mode in ["run_results","run_gnuplot"]: # makes no sense in results run where you don't reproduce new logs
        log.save_previous(run_mode)
    try:
        os.makedirs(pjoin(fold.log_folder_path,"successful"))
    except:
        pass
    try:
        os.makedirs(pjoin(fold.log_folder_path,"failed"))
    except:
        pass
# save the inputs in the result folder AFTER the previous run was saved
if not run_mode in ["run_results","run_gnuplot"]: # makes no sense in results run where you might have changed the actual inputs
    res.save_input_with_result()

#}}}
#{{{ adjust folder structure according to run_mode

# otherwise create/delete some folders according to run mode
# do this only if the previous log was not saved
if parameter_list["save_previous_log"] == "0":
    if run_mode in ["run","run_grid_and_pre","run_grid","setup_run","run_without_pre"] :
        if os.path.exists(fold.log_folder_path):
            shutil.rmtree(fold.log_folder_path)
        os.makedirs(fold.log_folder_path)
        os.makedirs(pjoin(fold.log_folder_path,"successful"))
        os.makedirs(pjoin(fold.log_folder_path,"failed"))
    elif run_mode in ["run_results","run_gnuplot"]:
        pass
    else:
        if run_mode in ["run_pre","run_pre_and_main"]:
            try:
                shutil.rmtree(pjoin(fold.log_folder_path,"pre_run"))
            except:
                pass
        if run_mode in ["run_main","run_pre_and_main","run_main_without_pre"]:
            try:
                shutil.rmtree(pjoin(fold.log_folder_path,"main_run"))
            except:
                pass
        try:
            for the_file in os.listdir(fold.log_folder_path):
                file_path = pjoin(fold.log_folder_path, the_file)
                try:
                    if os.path.isfile(file_path):
                        os.unlink(file_path)
                except Exception as e:
                    print(e)
        except:
            pass
        try:
            shutil.rmtree(pjoin(fold.log_folder_path,"successful"))
        except:
            pass
        try:
            shutil.rmtree(pjoin(fold.log_folder_path,"failed"))
        except:
            pass
        os.makedirs(pjoin(fold.log_folder_path,"successful"))
        os.makedirs(pjoin(fold.log_folder_path,"failed"))

if run_mode in ["run_without_pre","run_main_without_pre"]:
    out.print_warning("You have chosen to run without doing a dedicated runtime extrapolation (pre run) for this run. A pre-generated runtime.dat file is used, which has been created on a different machine and might not fit to the present setup. Be careful regarding the desired precision, it might not be met without a dedicated runtime extrapolation for this run.")
    if parameter_list.get("include_pre_in_results") == "1":
        out.print_error("You have chosen to run without pre run. Cannot include pre run in result combination. Change include_pre_in_results=1 in paramter.dat file and restart. Exiting...")
    else:
        parameter_list["include_pre_in_results"] = "0"
#}}}
# add first log: main code is running (no second instance will be able to start)
log.code_running_add() # that must be after log folder might be deleted
#{{{ handle and set inputs from parameter.dat file
# resummation settings
if parameter_list.get("add_NLL","0") == "1" or parameter_list.get("add_NNLL","0") == "1":
     # change born and VT parallelization, since much slower with resummation
    default_settings = pre_run_settings["default"]
    default_settings["born"] = [50,50000]
    default_settings["VT.QCD"] = [50,50000]
    pre_run_settings["default"] = default_settings
# determines the orders set to be run
order = []
if int(parameter_list["run_LO"]) == 1:
    order.append("LO")
if int(parameter_list.get("run_NLO_QCD","0")) == 1 or int(parameter_list.get("run_NLO_EW","0")) == 1:
    order.append("NLO")
if int(parameter_list.get("run_NNLO_QCD","0")) == 1 or int(parameter_list.get("add_NLO_EW","0")) == 1:
    order.append("NNLO")
if not order:
    out.print_error("No order has been set to be run.")
# switch for loop-induced contribution
if int(parameter_list["loop_induced"]) == 0:
    include_loop_induced = False # switch to turn of loop induced folders
elif int(parameter_list["loop_induced"]) == 1 or int(parameter_list["loop_induced"]) == 2 or int(parameter_list["loop_induced"]) == -1 or int(parameter_list["loop_induced"]) == -2:
    include_loop_induced = True # switch to turn of loop induced folders
else:
    out.print_error("Input \"loop_induced\" in parameter.dat can only be 0, 1, 2, -1 or -2, but it was set to "+parameter_list["loop_induced"])
# switch for NLO subtraction method
if int(parameter_list["NLO_subtraction_method"]) == 0: # use both !!! 2do: non-functionable for results and runtimes !!!
    NLO_subtraction = ["CS","QT"]
    out.print_error_no_stop("Simultaneous computation of CS and QT subtraction at NLO not supported at the moment.")
    out.print_error("Input \"NLO_subtraction\" in parameter.dat can only be 1 or 2, but it was set to "+parameter_list["NLO_subtraction_method"])
elif int(parameter_list["NLO_subtraction_method"]) == 1: # use CS
    NLO_subtraction = ["CS"]
elif int(parameter_list["NLO_subtraction_method"]) == 2: # use QT
    NLO_subtraction = ["QT"]
else:
    out.print_error("Input \"NLO_subtraction\" in parameter.dat can only be 1 or 2, but it was set to "+parameter_list["NLO_subtraction_method"])
#}}}
#{{{ set inputs from MATRIX_configuration file
# default values:
nr_cores     = multiprocessing.cpu_count()
nr_nodes     = -1 # (-1) means no limit
runmode      = "multicore"
max_restarts = 1 # set maximal number of restarts in warmup and main run

# default inputs:
if not "parallel_job_limit" in config_list:
    config_list["parallel_job_limit"] = 5000 # run at most 5000 parallel jobs without user interaction
if not "max_jobs_in_cluster_queue" in config_list:
    config_list["max_jobs_in_cluster_queue"] = -1 # no limit on the jobs in the cluster queue

# for lhapdf we need all orders <= highest order
if "NNLO" in order:
    order_lhapdf = ["LO","NLO","NNLO"]
elif "NLO" in order:
    order_lhapdf = ["LO","NLO"]
elif "LO" in order:
    order_lhapdf = ["LO"]

# initialize lhapdf class, prints version
pdf = lhapdf(config_list,parameter_list["LHAPDF_LO"],parameter_list["LHAPDF_NLO"],parameter_list["LHAPDF_NNLO"],order_lhapdf) # class for handling the pdf sets
# check if pdf any pdf set is missing
if pdf.read_access_pdf_sets_path and pdf.get_missing_sets(): # returns list with sets that are missing
    pdf.download_pdf_sets(pdf.get_missing_sets()) 

# stop here after making sure that PDF sets are available
if run_mode == "setup_run":
    out.print_info("Chosen to only set up the run folder. Exiting...")
    exit(0)

# set exe_path to folder class
fold.exe_path = pjoin(config_list.get("path_to_executable",pjoin(munich_dir,"bin")),prc.process_name)
if not config_list.get("path_to_executable","/").startswith("/"):
    out.print_error("path_to_exectuable %s in MATRIX_configuration MUST be a full path starting with \"/\". Exiting..." % fold.exe_path)
if not os.path.exists(fold.exe_path):
    out.print_error("Executable %s does not exist. Was the process correctly compiled?" % fold.exe_path)
# remove the symlink in the run folder
try:
    os.remove(pjoin(fold.run_folder_path,prc.process_name))
except:
    pass
# create new symlink in the run folder
try:
    os.symlink(fold.exe_path,pjoin(fold.run_folder_path,prc.process_name))
except:
    pass


# overwrite values that have been set
if "mode" in config_list:
    if int(config_list["mode"]) == 0:
        runmode = "multicore"
    elif int(config_list["mode"]) == 1:
        runmode = "cluster"
        #create cluster folder in cluster runs
        cluster_folder_path = pjoin(fold.run_folder_path,"cluster")
        # do not do this in result run
        if not run_mode in ["run_results","run_gnuplot"]:
            if os.path.exists(cluster_folder_path):
                shutil.rmtree(pjoin(cluster_folder_path))
            # the batch_file and the running/pending/finished lists should be removed in order to avoid confusion 
            # with old job ids, therefore we renew the whole cluster folder every run
            os.makedirs(cluster_folder_path)
            os.makedirs(pjoin(cluster_folder_path,"batch_files"))
            os.makedirs(pjoin(cluster_folder_path,"active_jobs"))
            try:
                cluster_name = config_list["cluster_name"] 
            except:
                out.print_error("Cluster mode (mode=1) chosen, but no cluster_name specified in MATRIX configuration file.")
            if int(config_list.get("cluster_local_run",0)) > 0 and not "cluster_local_scratch_path" in config_list:
                out.print_error("You are trying to run locally on cluster nodes (\"cluster_local_run = 1\"), but \"cluster_local_scratch_path\" not specified in MATRIX_configuration. Set \"cluster_local_run = 0\" or specify \"cluster_local_scratch_path\". Exiting...")
    else:
        out.print_error("Variable mode in MATRIX configuration file can only be 0 or 1")
if "max_nr_parallel_jobs" in config_list:
    nr_cores = int(config_list["max_nr_parallel_jobs"])
    nr_nodes = int(config_list["max_nr_parallel_jobs"])
if "max_restarts" in config_list:
    max_restarts = int(config_list["max_restarts"])
if runmode == "cluster":
    nr_cores = nr_nodes # use same variable (nr_cores) for cores and nodes
#}}}
#{{{ hard-coded parameters
# inputs that have to be clear/set before job running
set_parallel_runs = 0 # no parallel runs (0) 2do: implement variable number of parallel runs depending on precision; copy main_run_folder
grid_folder = "grid"  # one could make these arrays 
main_run_folder = "run.0" # in order to request more folders
#}}}
#{{{ assigning grids to subprocesses
# manual dictionary which connects level 3 folders with required grids, needs to be changed 
# if, eg, K+P terms should get different phase-space, or when QED is considered as well

# MATRIX v1 assignment:
# grid_assignment = {}
# grid_assignment["VA.QCD"]="born"
# grid_assignment["VT.QCD"]="born" # for QT subraction
# grid_assignment["CT.QCD"]="born" # for QT subraction
# grid_assignment["CT2.QCD"]="born"
# grid_assignment["RVA.QCD"]="RT.QCD"
# grid_assignment["VT2.QCD"]="born"
# grid_assignment["L2VA.QCD"]="loop"
# grid_assignment["L2VT.QCD"]="loop" # for QT subraction
# grid_assignment["L2CT.QCD"]="loop" # for QT subraction
# grid_assignment["VA.QEW"]="born"

# MATRIX v2 assignment:
grid_assignment = {}
grid_assignment["VA.QCD"]="born"
grid_assignment["VT.QCD"]="CT.QCD" # for QT subraction
grid_assignment["RVA.QCD"]="RT.QCD"
grid_assignment["VT2.QCD"]="CT2.QCD"
grid_assignment["L2VA.QCD"]="loop"
grid_assignment["L2VT.QCD"]="L2CT.QCD" # for QT subraction
grid_assignment["VA.QEW"]="born"

channel_assignment = copy.copy(grid_assignment)
channel_assignment["PT.QCD"]  = "CT.QCD"
channel_assignment["PT2.QCD"] = "CT2.QCD"
#}}}

#{{{ 2do !!!

# 2do, missing: check for errors and exceptions while running, are the grids correctly  !!!
#               produced? has something gone wrong? sanity checks! need input for that! !!!

#2do: finish matrix run_log class folder_structure, cluster_log, results

# 2do: add some sanity checks to make sure all data is there

# input/run_folder/*files* have to be checked when creating the folder
# create new inputs when not existing
# warn when running without input folder
#
# - write function to cleanup single folder
# - write function to cleanup all folders
# - how should program behave, continue runs, replace everything, switch inbetween?
#
# - check from time to time wether process is still alive !!!
#

#}}}

# define some local functions so that we can factorize the run execution a bit more
#{{{ def: check_parallel()
def check_parallel():
    # this routine checks wether the number of parallel jobs is too large
    if log.total_parallel >= 100000:
        out.print_error("You are trying to run %s parallel jobs. This is a fail-safe which prevents you from running more than 100000 jobs. Please increase the max_time_per_job or the required precision in the parameter.dat file and try again. Exiting..." % log.total_parallel)
    elif int(log.total_parallel) > int(config_list["parallel_job_limit"]):
        out.print_warning("You are trying to run %s parallel jobs. This exceeds the parallel_job_limit of %s in the MATRIX_configuration file." % (int(log.total_parallel),int(config_list["parallel_job_limit"])))
        out.print_warning("Do you want to continue with the main run anyway?")
        out.print_read("Press \"ENTER\" to continue or enter any text to stop running.")
        # read user input
        try:
            input2 = raw_input("|============>> ")
        except:
            input2 = input("|============>> ")
        # abort script if not pressed ENTER
        if input2.strip() == "":
            out.print_info("Increase the parallel_job_limit in the MATRIX_configuration file to avoid this warning in later runs.")
            out.print_info("Continuing despite the large number of parallel runs...")
        else:
            out.print_error_no_stop("To reduce the number of parallel jobs, please increase the max_time_per_job or the required precision in the parameter.dat file and try again.")
            out.print_error("Stopping the code...")
#}}}
#{{{ def: print_restarted_runs()
def print_restarted_runs():
    # this routine checks wethere there are restarted runs and prints them out
    if log.list_exists("restarted_list.log"):
        out.print_warning("The following runs had to be restarted with different random seed (see log-file why original runs failed):")
        out.print_list(pjoin(fold.log_folder_path,"restarted_list.log"),"warning")
#}}}
#{{{ def: rerun_warmup()
def rerun_warmup(maximal_reruns):
    # this routine reruns the warmup in case there are jobs that failed
    reruns = 1 # init reruns to be one
    while run.jobs_in_failed_list() and reruns <= maximal_reruns:
        log.clear_list("restarted_list.log") # clear the list of restarted jobs during previous run
        run.warmup(2) # second phase of warmup: runs that needed to be redone
        print_restarted_runs() # if there are any, print out the runs that were restarted with different random seed
        if run.errors_flag: out.print_error("Exception error while re-running warmup (%s time). Stopping the code..."%reruns)
        reruns+=1
#}}}
#{{{ def: check_warmup()
def check_warmup():
    # this routine checks if there are still failed grid runs, prints warnings and waits for user input
    if run.jobs_in_failed_list():    
        out.print_warning("The following warmup runs (grid setup) have not correctly finished (see log-file):")
        # list the runs that failed
        out.print_failed_runs()
        out.print_warning("Jobs in the main run that require the corresponding grids will also fail.")
        out.print_warning("Do you want to continue with the main run anyway?")
        out.print_read("Press \"ENTER\" to continue or enter any text to stop running.")
        # read user input
        try:
            input2 = raw_input("|============>> ")
        except:
            input2 = input("|============>> ")
        # abort script if not pressed ENTER
        if input2.strip() == "":
            out.print_info("continuing despite some failed grid runs...")
        else:
            out.print_error("Stopping the code...")
    else:
        out.print_info("All runs successfully finished.")
#}}}
#{{{ def: check_grid_log()
def check_grid_log():
    # this routine checks in the logs wether the grid run has successfully finished and start a dialog if not
    if not run.grid_run_complete():
        if run.failed_run_list:
            out.print_warning("The following runs have no \"final result\" in the execution file:")
            out.print_list(run.failed_run_list,"warning")
        # dialog to abort or to run anyway (eg, if you have the grid run complete but the log files are missing)
        out.print_warning("Number of successful grid runs is not as expected (see grid_run folder in log folder %s)." % fold.log_folder_path)
        out.print_warning("Expected number of successful grid runs: %s" % run.expected_nr_of_grid_runs)
        out.print_warning("Number of successful grid runs: %s" % run.successful_nr_of_grid_runs)
        out.print_warning("Number of failed grid runs: %s" % run.failed_nr_of_grid_runs)
        if run.successful_nr_of_grid_runs < run.expected_nr_of_grid_runs and not continue_run:
            out.print_warning("Jobs in the main run that require the corresponding grids will also fail.")
            out.print_warning("Do you want to continue with the main run anyway?")
            out.print_read("Press \"ENTER\" to continue or enter any text to stop running.")
            # read user input
            try:
                input2 = raw_input("|============>> ")
            except:
                input2 = input("|============>> ")
            # abort script if not pressed ENTER
            if input2.strip() == "":
                out.print_info("continuing despite some failed grid runs...")
            else:
                out.print_error("Stopping the code...")
        elif run.successful_nr_of_grid_runs > run.expected_nr_of_grid_runs:
            out.print_warning("Apparently there are more grid runs than expected. Make sure things are consistent. Continuing...")
#}}}
#{{{ def: rerun_pre_run()
def rerun_pre_run(maximal_reruns):
    # this routine reruns the pre runs in case there are there are jobs that failed
    reruns = 1 # init reruns to be one
    while run.jobs_in_failed_list() and reruns <= maximal_reruns:
        log.clear_list("restarted_list.log") # clear the list of restarted jobs during previous run
        run.main_run(-2) # second phase of pre run: runs that needed to be redone
        print_restarted_runs() # if there are any, print out the runs that were restarted with different random seed
        if run.errors_flag: out.print_warning("Exception error while re-running extrapolation processes(%s time)." % reruns)
        reruns+=1
#}}}
#{{{ def: check_pre_run()
def check_pre_run():
    # this routine checks if there are still failed pre runs, prints an error and stops or continues with success message
    if run.pre_run_complete():
            out.print_info("All runs successfully finished.")
    else:
        if run.jobs_in_failed_list():
            out.print_error_no_stop("Parts of the runtime extrapolation (pre run) failed. The following runs have not correctly finished (see log-file):")
            out.print_failed_runs() # list the runs that failed
            exit(0)
        else:
            out.print_error_no_stop("Some parts of the runtime extrapolation (pre run) did not finish correctly. The following runs have no \"final result\" in the execution file:")
            out.print_list(run.failed_run_list,"error")
            exit(0)
#}}}
#{{{ def: rerun_main_run()
def rerun_main_run(maximal_reruns):
    # this routine reruns the main runs in case there are there are jobs that failed
    reruns = 1 # init reruns to be one
    while run.jobs_in_failed_list() and reruns <= maximal_reruns:
        log.clear_list("restarted_list.log") # clear the list of restarted jobs during previous run
        run.main_run(2) # second phase of main run: runs that needed to be redone
        print_restarted_runs() # if there are any, print out the runs that were restarted with different random seed
        if run.errors_flag: out.print_warning("Exception error while re-running main processes(%s time)." % restarts)
        reruns+=1
#}}}
#{{{ def: check_main_run()
def check_main_run():
    # this routine checks if there are still failed main runs, prints an error and stops or continues with success message
    if run.main_run_complete():
            out.print_info("All runs successfully finished.")
    else:
        if run.jobs_in_failed_list():
            out.print_error_no_stop("Parts of the cross section computation (main run) failed. The following runs have not correctly finished (see log-file):")
            out.print_failed_runs() # list the runs that failed
            exit(0)
        else:
            out.print_error_no_stop("Some parts of the cross section computation (main run) did not finish correctly. The following runs have no \"final result\" in the execution file:")
            out.print_list(run.failed_run_list,"error")
            exit(0)
#}}}
#{{{ def: run_gnuplot()
def run_gnuplot():
    # this routine calls the gnuplot class to automatically plot all distributions
    out.print_info("Plotting results with gnuplot...")
    try:
        if (int(parameter_list["loop_induced"])) > 0:
            first_distribution_path = glob.glob(pjoin(fold.result_folder_path,max(order, key=len)+"-run/distributions*"))[0]
        elif (int(parameter_list["loop_induced"])) <= 0:
            first_distribution_path = glob.glob(pjoin(fold.result_folder_path,max(order, key=len)+"-run/distributions*"))[0]
        all_plots = glob.glob(pjoin(first_distribution_path,"*.dat"))
  #      print all_plots , 'all_plots'
    except:
        all_plots = ""
    if not all_plots: out.print_error_no_stop("Cannot find any distributions in %s. Continuing anyways..." % pjoin(fold.result_folder_path,max(order, key=len)+"-run/distributions/*.dat"))
    gnu = gnuplot(fold.result_folder_path,True)
    gnu.clean_gnuplot_folder()
#    gnu.clean_gnuplot_folder()  # should be already empty
    for plot in all_plots:
        gnu = gnuplot(fold.result_folder_path,True)

        plot_LO = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/LO-run/") +"__LO/" + plot.rsplit("__")[1].rsplit("/")[1] + "__LO.dat"
        plot_NLO = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NLO-run/") +"__NLO_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__NLO_QCD.dat"
        plot_NLO_EW = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NLO-run/") +"__NLO_EW/" + plot.rsplit("__")[1].rsplit("/")[1] + "__NLO_EW.dat"
        plot_NNLOqq = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__NNLOqq_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__NNLOqq_QCD.dat"
        plot_loopNLOgg = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__loopNLOgg_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__loopNLOgg_QCD.dat"
        plot_loopLOgg = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__loopLOgg_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__loopLOgg_QCD.dat"
        plot_NNLO = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__NNLO_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__NNLO_QCD.dat"
        plot_nNNLO = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__nNNLO_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__nNNLO_QCD.dat"
        plot_NNLO_QCDpNLO_EW = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__NNLO_QCD+NLO_EW/" + plot.rsplit("__")[1].rsplit("/")[1] + "__NNLO_QCD+NLO_EW.dat"
        plot_NNLO_QCDxNLO_EW = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__NNLO_QCDxNLO_EW/" + plot.rsplit("__")[1].rsplit("/")[1] + "__NNLO_QCDxNLO_EW.dat"
        plot_nNNLO_QCDpNLO_EW = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__nNNLO_QCD+NLO_EW/" + plot.rsplit("__")[1].rsplit("/")[1] + "__nNNLO_QCD+NLO_EW.dat"
        plot_nNNLO_QCDxNLO_EW = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__nNNLO_QCDxNLO_EW/" + plot.rsplit("__")[1].rsplit("/")[1] + "__nNNLO_QCDxNLO_EW.dat"

        counter = 0
        if int(parameter_list.get("run_LO","0")) == 1:
            try:
                gnu.add_curve(plot_LO,{"label" : "LO_{QCD}"})
                counter += 1
            except:
                pass
        if int(parameter_list.get("run_NLO_QCD","0")) == 1:
            try:
                gnu.add_curve(plot_NLO,{"label" : "NLO_{QCD}"})
                counter += 1
            except:
                pass
        if int(parameter_list.get("run_NLO_EW","0")) == 1 and not (int(parameter_list.get("add_NLO_EW","0")) == 1 and int(parameter_list.get("run_NNLO_QCD","0")) == 1):
            try:
                gnu.add_curve(plot_NLO_EW,{"label" : "NLO_{EW}"})
                counter += 1
            except:
                pass
        if int(parameter_list.get("run_NNLO_QCD","0")) == 1 and int(parameter_list["loop_induced"]) >= 0:
            try:
                gnu.add_curve(plot_NNLO,{"label" : "NNLO_{QCD}"})
                counter += 1
        # if int(parameter_list.get("run_NNLO_QCD","0")) == 1 and (int(parameter_list["loop_induced"])) > 0:
        #     gnu.add_curve(plot_NNLOqq)
            except:
                pass
        if int(parameter_list.get("run_NNLO_QCD","0")) == 1 and int(parameter_list["loop_induced"]) < 0:
            try:
                gnu.add_curve(plot_loopLOgg,{"label" : "ggLO"})
                counter += 1
            except:
                pass
        if int(parameter_list.get("run_NNLO_QCD","0")) == 1 and int(parameter_list["loop_induced"]) < -1:
            try:
                gnu.add_curve(plot_loopNLOgg,{"label" : "ggNLO_{QCD}"})
                counter += 1
            except:
                pass
        if int(parameter_list.get("run_NNLO_QCD","0")) == 1 and int(parameter_list["loop_induced"]) > 1:
            try:
                gnu.add_curve(plot_nNNLO,{"label" : "nNNLO_{QCD}"})
                counter += 1
            except:
                pass
        if int(parameter_list.get("add_NLO_EW","0")) == 1:
            if int(parameter_list.get("run_NNLO_QCD","0")) == 1:
                if int(parameter_list["loop_induced"]) > 1:
                    try:
                        gnu.add_curve(plot_nNNLO_QCDpNLO_EW,{"label" : "nNNLO_{QCD}+NLO_{EW}"})
                        gnu.add_curve(plot_nNNLO_QCDxNLO_EW,{"label" : "nNNLO_{QCD}xNLO_{EW}"})
                        counter += 2
                    except:
                        pass
                else:
                    try:
                        gnu.add_curve(plot_NNLO_QCDpNLO_EW,{"label" : "NNLO_{QCD}+NLO_{EW}"})
                        gnu.add_curve(plot_NNLO_QCDxNLO_EW,{"label" : "NNLO_{QCD}xNLO_{EW}"})
                        counter += 2
                    except:
                        pass
        if counter > 2:
            gnu.set_plot_properties("normalization",3) # use NNLO for normalization
        else:
            gnu.set_plot_properties("normalization",counter) # use NNLO for normalization

        if inp.result_method == "TSV":
            gnu.set_plot_properties("new_matrix_output_style",True) # use NNLO for normalization
        # if "LO" in order:
        #     gnu.add_curve(plot_LO)
        # plot_NLO = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NLO-run/") +"__NLO_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__NLO_QCD.dat"
        # if "NLO" in order:
        #     gnu.add_curve(plot_NLO)
        # plot_NNLO_LO_gg = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__NNLO_LOgg_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__NNLO_LOgg_QCD.dat"
        # if "NNLO" in order and (int(parameter_list["loop_induced"])) > 0:
        #     gnu.add_curve(plot_NNLO_LO_gg)
        # plot_loopNLOgg = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__loopNLOgg_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__loopNLOgg_QCD.dat"
        # plot_loopLOgg = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__loopLOgg_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__loopLOgg_QCD.dat"
        # if "NNLO" in order and (int(parameter_list["loop_induced"])) < 0:
        #     gnu.add_curve(plot_loopLOgg)
        # plot_nNNLO = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__nNNLO_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__nNNLO_QCD.dat"
        # if "NNLO" in order and (int(parameter_list["loop_induced"])) > 1:
        #     gnu.add_curve(plot_loopNLOgg)
        #     gnu.add_curve(plot_nNNLO)
        # plot_NNLO = plot.rsplit("__")[0].replace("/"+max(order, key=len)+"-run/","/NNLO-run/") +"__nNNLO_QCD/" + plot.rsplit("__")[1].rsplit("/")[1] + "__NNLO_QCD.dat"
        # if "NNLO" in order and (int(parameter_list["loop_induced"])) == 0:
        #     gnu.add_curve(plot_NNLO)
        if gnu.get_name().startswith("total_rate"):# or gnu.get_name().startswith("n_jet"): # these plots are always done per default, treat them as special case
            continue
        elif gnu.get_name().startswith("n_jet"): # for njets, treat it as special case and combine it with total rate in "-1" bin
            gnu.set_plot_properties("logscale_y",False)
            gnu.set_plot_properties("ylabel","{/Symbol s}")
            gnu.set_plot_properties("xlabel","")
            gnu.set_plot_properties("xtics_ratio","(\"total rate\" -0.5,\"0-jet\" 0.5,\"1-jet\" 1.5,\"2-jet\" 2.5)")
            gnu.set_plot_properties("norm_label","WRONG total rate (within same order) [%]")
            gnu.set_plot_properties("xmin",-1)
            gnu.set_plot_properties("ymin_ratio",0)
            gnu.set_plot_properties("ymax_ratio",1)
            gnu.set_plot_properties("ytics_ratio","(\"0\" 0,\"20\" 0.2,\"40\" 0.4,\"60\" 0.6,\"80\" 0.8,\"100\" 1)")
        elif "_log_" in plot:
            gnu.set_plot_properties("logscale_x",True)
            
        elif gnu.get_name().startswith("pTveto"): # treat this later as special case inside the code (with distributiontype)
            continue
        # first you have to add all curves, then specify plot properties !!!
        # either give title directly
        #    gnu.set_plot_properties("title","this is the title in upper right corner")
        # or you set process, collider AND energy, and it is automatically created

        if parameter_list["coll_choice"]=="1":
            collider = "LHC"
        elif parameter_list["coll_choice"]=="2":
            collider = "Tevatron"
        else:
            out.print_error("collider_choice in parameter_list in routine run_gnuplot is neither 1 nor 2.")
        energy = float(parameter_list["E"])*2/1000
        process = prc.get_nice_process_name()

        gnu.set_plot_properties("process",process)
        gnu.set_plot_properties("collider",collider)
        gnu.set_plot_properties("energy","%s TeV" % energy)
        #    gnu.set_plot_properties("reference","1111.1111")
        amplitude_list = "OpenLoops"
        if int(parameter_list.get("run_NNLO_QCD","0")) == 1:
            if prc.process_name in ["ppzz02","ppwxw02","ppeeexex04","ppemexmx04","ppeexnenex04","ppeexnmnmx04","ppemxnmnex04","ppemexnmx04","ppeexmxnm04","ppeeexnex04","ppeexexne04"] and (int(parameter_list["loop_induced"]) >= 0 or int(parameter_list["loop_induced"]) == -2):
                amplitude_list += "+VVamp"
            elif prc.process_name in ["ppeexa03","ppnenexa03","ppexnea03","ppenexa03"]:
                amplitude_list += "+arXiv:1112.1531"
            elif prc.process_name == "ppaa02":
                amplitude_list += "+hep-ph/0201274"
            elif prc.process_name == "pphh22":
                amplitude_list += "+arXiv:1305.5206"
            # elif prc.process_name in ["ppz01","ppw01","ppwx01","ppeex02","ppnenex02","ppexne02nockm","ppenex02nockm","ppexne02","ppenex02"]:
            #     amplitude_list += "+Matsuura:1988sm"
            # elif prc.process_name == "pph21":
            #     amplitude_list += "+hep-ph/0007289"
        gnu.set_plot_properties("amplitude_list",amplitude_list)

        gnu.plot()
        # try:
        #     gnu.plot()
        # except:
        #     pass
    time.sleep(3)
    # combine the pdfs in gnuplot folder in one single pdf file
    # get all pdfs in gnuplot folder
    all_pdfs = sorted(glob.glob(pjoin(fold.result_folder_path,"gnuplot/*.pdf")))
    command = "pdfunite"
    if which(command):
       if all_plots and all_pdfs:
           # Appending all pdfs
           for pdf in all_pdfs:
               command += " \"%s\"" % pdf
               # Writing all the collected pages to a file
           combined_pdf_file = pjoin(fold.result_folder_path,"gnuplot","all_plots.pdf")
           command += " \"%s\"" % combined_pdf_file
           out.print_info("Combining all pdf files into single file \"all_plots.pdf\"...")
           print(subprocess.Popen(command, shell=True, stdout=subprocess.PIPE).stdout.read().decode('utf-8'))
    else:
        out.print_warning("Command \"pdfunite\" does not exist on this system. Skipping combination of *.pdf files...")
#}}}


##############################
# Here start the actual runs #
##############################

if not run_mode in ["run_results","run_gnuplot"]:
#### initialize cluster class
    if runmode == "cluster":
        cluster = get_cluster_class_from_name[cluster_name](config_list,verbose)
#### initialize run instance
run = run_class(runmode,grid_folder,main_run_folder,NLO_subtraction,order,set_parallel_runs,grid_assignment,include_loop_induced,config_list)
if run_mode in ["run","run_grid_and_pre","run_grid","run_without_pre"]:
#### run warmup to set up grids
    run.clear_warmup() # clear previous runs in grid dirs
    run.warmup(1) # run warmup
    print_restarted_runs() # if there are any, print out the runs that were restarted with different random seed
    if run.errors_flag: out.print_warning("Exception error in python jobs while running warmup.") # check if there were exception errors
    rerun_warmup(max_restarts) # if there are jobs that failed
    check_warmup() # if there are still failed grid runs, print warnings and wait for user input
    log.move_to_folder(pjoin(fold.log_folder_path,"grid_run")) # move all log files into a new created grid_run folder inside the log folder
if run_mode in ["run","run_grid_and_pre","run_pre","run_pre_and_main"]:
#### extrapolation run (pre run)
    check_grid_log() # check logs if grid_run has been done 
    log.clear_list("restarted_list.log") # remove previous items from list with restarted jobs
    if run_mode in ["run_pre","run_pre_and_main"]: run.clear_pre_run() # clear pre run folders of previous runs (already be clean in other runmodes)
    run.main_run(-1) # start pre run
    print_restarted_runs() # if there are any, print out the runs that were restarted with different random seed
    if run.errors_flag: out.print_warning("Exception error while doing extrapolation runs.") # check if there were exception errors
    rerun_pre_run(max_restarts) # if there are jobs that failed
    check_pre_run() # if there are still failed pre runs, print error and stop the code
    log.move_to_folder(pjoin(fold.log_folder_path,"pre_run")) # move all log files into a new created pre_run folder inside the log folder
    run.extrapolate_runtimes() # extrapolation of runtimes by combining pre run result 
    try:
        run.print_pre_run()
    except:
        pass
    run.read_runtimes() # read in output of extrapolation run; read it already here to save the information
    check_parallel() # check wether the parallelization is not too high
if run_mode in ["run_without_pre","run_main_without_pre"]:
    shutil.copy(pjoin(fold.default_input_path,"runtime.dat"),pjoin(fold.run_folder_path,"result")) # copy pre-generated runtime.dat file
    run.read_runtimes() # read in output of extrapolation run when running main alone (no information from before)
    check_parallel() # check wether the parallelization is not too high
    run.clear_main_run() # clear main run folders of previous runs (already be clean in other runmodes)
if run_mode in ["run","run_main","run_pre_and_main","run_without_pre","run_main_without_pre"]:
#### cross section run (main run)
    #
    # 2do: check logs if pre_run has been done IN THIS CASE YOU SHOULD EXCLUDE ALL PRE RUNS FROM RESULTS
    # 2do: check wether runtimes file exists THIS IS ENOUGH, RIGHT?
    # 2do: introduce an equivalent to check_grid_log(): check_pre_run_log()
    #      if not run.pre_run_complete(): #and not run_mode == "run": why should this not also be asked in general run?
    #      dialog to abort or to run anyway (eg, if you have the grid run complete but the log files are missing)
    if run_mode == "run_main":
        run.read_runtimes() # read in output of extrapolation run when running main alone (no information from before)
        check_parallel() # check wether the parallelization is not too high
        run.clear_main_run() # clear main run folders of previous runs (already be clean in other runmodes)
    log.clear_list("restarted_list.log") # remove previous items from list with restarted jobs
    run.main_run(1) # start main run
    print_restarted_runs() # if there are any, print out the runs that were restarted with different random seed
    if run.errors_flag: out.print_warning("Exception error while running main processes.") # check if there were exception errors
    rerun_main_run(max_restarts) # if there are jobs that failed
    check_main_run() # if there are still failed main runs, print error and stop the code
    log.move_to_folder(pjoin(fold.log_folder_path,"main_run")) # move all log files into a new created main_run folder inside the log folder
if run_mode in ["run","run_pre_and_main","run_main","run_results","run_without_pre","run_main_without_pre"]:
#### collect and combine results
    run.clear_results() # remove previous results (if there are any)
    citation_list_run = cite.get_citation_list_run(order,NLO_subtraction)
    citation_list_process = cite.get_citation_list_process(parameter_list)
    citation_list_amplitudes = cite.get_citation_list_amplitudes(parameter_list)
    citation_list_standard = cite.get_citation_list_standard(parameter_list)
    cite.write_citations(pjoin(fold.result_folder_path,"CITATIONS.bib"),parameter_list,citation_list_run,citation_list_process,citation_list_standard=citation_list_standard,citation_list_amplitudes=citation_list_amplitudes) # write citations to file
    run.combine_results() # combine results and distributions and copy them to result folder
    out_distributions = ""
    if int(parameter_list["switch_distribution"]) == 1:
        out_distributions = " (including the distributions)" # print wether there are distributions
        run_gnuplot() # generate gnuplot output
    run.print_results_onscreen_and_to_summary_file() # write results on the screen and into summary file
    out.print_result("All results%s can be found in:" % out_distributions)
    out.print_result(fold.result_folder_path)
elif run_mode == "run_gnuplot":
    try:
        os.makedirs(pjoin(fold.result_folder_path,"gnuplot"))
    except:
        shutil.rmtree(pjoin(fold.result_folder_path,"gnuplot"))
        os.makedirs(pjoin(fold.result_folder_path,"gnuplot"))
    run_gnuplot() # generate gnuplot output
